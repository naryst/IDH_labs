{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "96992524-ec7d-484c-99d5-f1e71bd72a06",
      "metadata": {
        "id": "96992524-ec7d-484c-99d5-f1e71bd72a06"
      },
      "source": [
        "# Introduction to Computer Vision. Lab 03: Parametric Image Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccbe035a-7c3d-4fe6-8bc2-09ac158e3240",
      "metadata": {
        "id": "ccbe035a-7c3d-4fe6-8bc2-09ac158e3240"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this lesson, we will explore the parametric approach for image classification using the CIFAR10 dataset. The parametric approach involves using a function with parameters to classify images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef3144e-4e02-4caa-88af-63041987b4da",
      "metadata": {
        "id": "4ef3144e-4e02-4caa-88af-63041987b4da"
      },
      "source": [
        "### What is a Parametric Image Classifier?\n",
        "\n",
        "A parametric image classifier uses a parameterized function to map input images to output labels. The parameters are learned from the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16ae124-4081-47d6-8f62-356834a783ce",
      "metadata": {
        "id": "f16ae124-4081-47d6-8f62-356834a783ce"
      },
      "source": [
        "## Notations Used In This Course\n",
        "\n",
        "- $C$ is the total number of labels.\n",
        "- $x$ denotes an image we want to classify (either it's a matrix or a vector (vectorization of the matrix)).\n",
        "- $y^T = [y_1, y_2, ..., y_C]$ is the true label vector. It is an all-zero vector and has value 1 only at the position of the true label.\n",
        "- $\\hat{y}^T = [\\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_C]$ is the decision label vector. It is a vector with numbers between zero and one.\n",
        "- $\\{x_i, y_i\\}_{i=1}^N$ is the training dataset comprised of $N$ image and true label vector pairs.\n",
        "- $\\{x_i^t, y_i^t\\}_{i=1}^M$ is the test dataset comprised of $M$ image and true label vector pairs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3691eede-674f-41fa-a5bf-79a1b06df635",
      "metadata": {
        "id": "3691eede-674f-41fa-a5bf-79a1b06df635"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Implement the parametric approach for image classification, with $f(x,W) = Wx$ on the CIFAR10 dataset, where $W$ is found by brute force.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc6583c-9e23-4bf4-b2f9-94f26f7da54e",
      "metadata": {
        "id": "bfc6583c-9e23-4bf4-b2f9-94f26f7da54e"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Flatten the images\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_train_onehot = encoder.fit_transform(y_train)\n",
        "y_test_onehot = encoder.transform(y_test)\n",
        "\n",
        "# Initialize W using random values\n",
        "num_classes = y_train_onehot.shape[1]\n",
        "num_features = X_train_flat.shape[1]\n",
        "W = np.random.randn(num_classes, num_features)\n",
        "\n",
        "# Define the softmax function\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "# Define the function to compute the loss\n",
        "def compute_loss(X, y, W):\n",
        "    z = X.dot(W.T)\n",
        "    y_hat = softmax(z)\n",
        "    loss = -np.mean(np.sum(y * np.log(y_hat + 1e-8), axis=1))\n",
        "    return loss\n",
        "\n",
        "# Brute force search for W\n",
        "best_loss = float('inf')\n",
        "best_W = None\n",
        "\n",
        "for i in range(1000):  # Limited to 1000 iterations for simplicity\n",
        "    W = np.random.randn(num_classes, num_features)\n",
        "    loss = compute_loss(X_train_flat, y_train_onehot, W)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        best_W = W\n",
        "\n",
        "print(f'Best loss: {best_loss}')\n",
        "\n",
        "# Evaluate on test set\n",
        "z_test = X_test_flat.dot(best_W.T)\n",
        "y_test_pred = np.argmax(softmax(z_test), axis=1)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Assert statement to check the correctness of the solution\n",
        "assert accuracy > 0.1, \"Accuracy is too low, check your implementation.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db654c0f-44b8-4d22-b5e0-8193b399dab9",
      "metadata": {
        "id": "db654c0f-44b8-4d22-b5e0-8193b399dab9"
      },
      "source": [
        "## Theory: Parametric Approach to Image Classifier\n",
        "\n",
        "The parametric approach of binary image classification:\n",
        "- $x$ is the input image to our algorithm.\n",
        "- $f(x, W)$ is our algorithm.\n",
        "- $g^T = [\\hat{g}_1, \\hat{g}_2]$ is the output of our algorithm $f(x, W)$.\n",
        "- $\\hat{y}^T = [\\hat{y}_1, \\hat{y}_2]$ is our decision for the labels, where $\\hat{y}^T = [1, 0]$ is cat and $\\hat{y}^T = [0, 1]$ is mouse.\n",
        "- $y^T = [y_1, y_2]$ is the true label vector, where $y^T = [1, 0]$ is cat and $y^T = [0, 1]$ is mouse.\n",
        "- Finally, $W$ is a matrix of parameters that we want to adjust (also called 'learn') so that our image classification decision $\\hat{y}$ is as close as possible to the true label $y$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d302352-13a0-4a41-ae3f-54bc88be671e",
      "metadata": {
        "id": "7d302352-13a0-4a41-ae3f-54bc88be671e"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "Implement a function to compute the accuracy of the classifier and evaluate the model on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb6e8a2-05a2-4393-88b7-e29aa74f5d31",
      "metadata": {
        "id": "0bb6e8a2-05a2-4393-88b7-e29aa74f5d31"
      },
      "outputs": [],
      "source": [
        "# Define a function to compute accuracy\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "# Compute the accuracy on the test set\n",
        "test_accuracy = compute_accuracy(y_test.ravel(), y_test_pred)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Assert statement to verify accuracy is computed correctly\n",
        "assert test_accuracy == accuracy, \"Computed accuracy does not match expected accuracy.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b082ec1a-aec7-42b4-b5d6-86d80dbab3d7",
      "metadata": {
        "id": "b082ec1a-aec7-42b4-b5d6-86d80dbab3d7"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this lesson, we explored the parametric approach for image classification using the CIFAR10 dataset. We implemented the classifier by brute-forcing the parameter matrix $W$ and evaluated its performance. This approach serves as a foundational concept in understanding more complex parametric models in machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb6de378-0829-48a1-8a49-7da76bed8099",
      "metadata": {
        "id": "bb6de378-0829-48a1-8a49-7da76bed8099"
      },
      "source": [
        "## Additional Resources\n",
        "\n",
        "For further reading and more complex image processing techniques, consider exploring the following resources:\n",
        "\n",
        "- [OpenCV Documentation](https://docs.opencv.org/)\n",
        "- [scikit-image Documentation](https://scikit-image.org/docs/stable/)\n",
        "- [Computer Vision: Algorithms and Applications](https://szeliski.org/Book/)\n",
        "\n",
        "Feel free to search for more information and examples online to enhance your understanding of computer vision.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}