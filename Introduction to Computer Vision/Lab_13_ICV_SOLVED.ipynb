{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbS9pyQtQC8t"
      },
      "source": [
        "# **Introduction to Computer Vision. Lab 13. Introduction to Artificial Intelligence**"
      ],
      "id": "WbS9pyQtQC8t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Theory:**\n",
        "\n",
        "**Multi-Class Object Detection and Localization:**\n",
        "- Multi-class object detection and localization involve identifying multiple objects of different classes within an image and determining their precise locations.\n",
        "- This task extends single object detection by incorporating the ability to handle multiple instances of different classes simultaneously.\n",
        "\n",
        "**Convolutional Neural Networks (CNNs):**\n",
        "- CNNs are highly effective for image-related tasks due to their ability to capture spatial hierarchies through convolutional layers.\n",
        "- For multi-class object detection and localization, CNN architectures are modified to include outputs for both class probabilities and bounding box coordinates.\n",
        "\n",
        "**Modifications to CNN Architecture:**\n",
        "1. **Output Layer Adjustments:**\n",
        "   - The output layer should predict class probabilities for each object in the image and bounding box coordinates \\((x, y, w, h)\\).\n",
        "   - This can be achieved by having separate outputs for classification and bounding box regression.\n",
        "\n",
        "2. **Loss Function:**\n",
        "   - A custom loss function that combines classification loss (e.g., categorical cross-entropy) and localization loss (e.g., mean squared error) is used to train the model.\n",
        "   - The classification loss ensures accurate class predictions, while the localization loss ensures precise bounding box predictions.\n",
        "\n",
        "**Dataset Requirements:**\n",
        "- The dataset should contain images with multiple instances of objects from different classes.\n",
        "- Each image should be annotated with bounding boxes and class labels for all objects present.\n",
        "\n",
        "**Training and Evaluation:**\n",
        "- The model is trained on a dataset with annotated bounding boxes and class labels.\n",
        "- Evaluation metrics include the accuracy of object classification and the precision of bounding box predictions, often measured using metrics like Intersection over Union (IoU).\n",
        "\n"
      ],
      "metadata": {
        "id": "kmFcuJObs6dY"
      },
      "id": "kmFcuJObs6dY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4z8cSxAQC8w"
      },
      "source": [
        "## **Excercise 1: Use your already built convolutional neural network to perform multi-class object detection and localization**\n",
        "\n",
        "---\n",
        "- Specifically, when you have an image with the same class more than once present in the image, or you have two or more classes present in the image, you need to detect and localize these classes.\n",
        "\n",
        "\n",
        "- To this end, you need to modify your previous algorithm such that it can detect two or more objects of the same class in an image and localize them, and it can also detect two or more objects of different classes in an image, and localize them. You also need to find yourself an appropriate data set from the net, that contains at least one class, but that class is present more than once in the images. A good choice would be pedestrians for example.\n",
        "\n",
        "\n",
        "- You need to show a performance that is significantly better than a random gues"
      ],
      "id": "Y4z8cSxAQC8w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQvp8g5FQC8x"
      },
      "source": [
        "### Multi-Class Object Detection and Localization using Convolutional Neural Network"
      ],
      "id": "uQvp8g5FQC8x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eaobk7tKQC8y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "def load_dataset(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    bboxes = []\n",
        "    annotations_path = os.path.join(data_dir, 'annotations.json')\n",
        "    with open(annotations_path, 'r') as f:\n",
        "        annotations = json.load(f)\n",
        "    for ann in annotations['annotations']:\n",
        "        img_path = os.path.join(data_dir, 'images', ann['file_name'])\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.resize(image, (128, 128)) / 255.0\n",
        "        label = ann['category_id']\n",
        "        bbox = ann['bbox']\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "        bboxes.append(bbox)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    bboxes = np.array(bboxes)\n",
        "    return images, labels, bboxes\n",
        "\n",
        "# Load dataset\n",
        "data_dir = 'path_to_your_dataset'\n",
        "X, y_labels, y_bboxes = load_dataset(data_dir)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(y_labels))\n",
        "y_labels_one_hot = tf.keras.utils.to_categorical(y_labels, num_classes=num_classes)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_labels_train, y_labels_test, y_bboxes_train, y_bboxes_test = train_test_split(\n",
        "    X, y_labels_one_hot, y_bboxes, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model for multi-class object detection and localization\n",
        "def build_detection_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_classes + 4, activation='linear'))  # num_classes for classification + 4 for bbox\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "input_shape = (128, 128, 3)\n",
        "model = build_detection_model(input_shape, num_classes)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=['categorical_crossentropy', 'mean_squared_error'])\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    classification_loss = tf.keras.losses.categorical_crossentropy(y_true[:, :num_classes], y_pred[:, :num_classes])\n",
        "    localization_loss = tf.keras.losses.mean_squared_error(y_true[:, num_classes:], y_pred[:, num_classes:])\n",
        "    return classification_loss + localization_loss\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss)\n",
        "model.fit(X_train, np.hstack((y_labels_train, y_bboxes_train)), epochs=epochs, batch_size=batch_size, validation_data=(X_test, np.hstack((y_labels_test, y_bboxes_test))))\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, np.hstack((y_labels_test, y_bboxes_test)))\n",
        "print(f'Loss: {loss}')\n",
        "\n",
        "# Predict on test images\n",
        "predictions = model.predict(X_test)\n",
        "y_pred_labels = predictions[:, :num_classes]\n",
        "y_pred_bboxes = predictions[:, num_classes:]\n",
        "\n",
        "# Function to draw bounding box on image\n",
        "def draw_bbox(image, bbox):\n",
        "    x, y, w, h = bbox\n",
        "    x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)\n",
        "    return cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "# Visualize predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "    image = X_test[i].copy()\n",
        "    true_bbox = y_bboxes_test[i]\n",
        "    pred_bbox = y_pred_bboxes[i]\n",
        "    image_true = draw_bbox(image.copy(), true_bbox)\n",
        "    image_pred = draw_bbox(image.copy(), pred_bbox)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('True Bounding Box')\n",
        "    plt.imshow(image_true)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Predicted Bounding Box')\n",
        "    plt.imshow(image_pred)\n",
        "    plt.show()"
      ],
      "id": "Eaobk7tKQC8y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF44qnumQC82"
      },
      "source": [
        "# **Conclusion:**\n",
        "\n",
        "Using a CNN for multi-class object detection and localization involves extending the network to predict class probabilities and bounding box coordinates for multiple objects. By training the model with a combined loss function, it learns to accurately detect and localize multiple objects in images.\n"
      ],
      "id": "dF44qnumQC82"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}