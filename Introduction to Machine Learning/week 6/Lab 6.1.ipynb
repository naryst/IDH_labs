{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "## Lesson 6 Support Vector Machines\n",
    "## Introduction\n",
    "\n",
    "In this lab work, we will familiarize ourselves with the classification algorithm using support vector machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "It is often necessary to classify data in machine learning algorithms. Each data object is represented as a vector (a point) in p-dimensional space (a sequence of numbers). Each of these points belongs to only one of two classes. We are interested in whether we can divide the points by a hyperplane of dimension \"p-1\". This is a typical case of linear separability. There can be many such hyperplanes. Therefore, it is natural to believe that maximizing the gap between classes contributes to more confident classification. That is, can we find a hyperplane such that the distance from it to the nearest point is maximized. This would mean that the distance between the two closest points lying on opposite sides of the hyperplane is maximized. If such a hyperplane exists, we will be most interested in it, it is called the optimal separating hyperplane, and the linear classifier corresponding to it is called the optimal separating classifier.\n",
    "\n",
    "\n",
    "### Performing the Classification\n",
    "To do so you will need:\n",
    "- Obtain data from competition\n",
    "- Create a Jupyter notebook which will produce a file for submission\n",
    "- Submit it to the competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In the practical part of the assignment, we compared the distributions of the outputs of the solver function (probability estimation) of SVM and LogReg. Usually the histogram for LogReg has heavier tails than the histogram for SVM. What can this be due to?* \n",
    "\n",
    "1. It cannot be explained in any way, just an empirical fact.\n",
    "2. It is a matter of the functionals the models are trained on. SVM just needs to make the indentation equal to 1, while LogReg maximizes the indentation\n",
    "3. Because SVM is bad at estimating probabilities, while LogReg is good at estimating probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Choose the correct statement about SVM and Logreg*: \n",
    "\n",
    "1. A calibrated SVM always estimates probabilities better than LogReg\n",
    "2.\tSVM will have slightly higher accuracy on average than LogReg\n",
    "3- You can't say it will be better by any metric. It's just that one model estimates probability and the other does not\n",
    "4. SVM is trained faster than LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required Libraries\n",
    "\n",
    "First we need to import necessary libraries:\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) - For data analysis and manipulation\n",
    "\n",
    "[Numpy](https://numpy.org/) - To deal with matrices\n",
    "\n",
    "[Matplotlib](https://matplotlib.org/) - Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. Matplotlib makes easy things easy and hard things possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:50:44.981235Z",
     "start_time": "2024-07-01T05:50:44.974798Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaing Data\n",
    "Preparing data for machine learning involves several steps such as data collection, cleaning the data from noise and outliers, transforming the data into a suitable format, normalizing or standardizing values, and creating and selecting features (feature engineering) to improve the quality of the model. This process is important to ensure the accuracy and reliability of machine learning models because data quality directly affects their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:58:03.146023Z",
     "start_time": "2024-07-01T05:58:02.489941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EngineVersion</th>\n",
       "      <th>AppVersion</th>\n",
       "      <th>AvSigVersion</th>\n",
       "      <th>RtpStateBitfield</th>\n",
       "      <th>IsSxsPassiveMode</th>\n",
       "      <th>AVProductStatesIdentifier</th>\n",
       "      <th>AVProductsInstalled</th>\n",
       "      <th>AVProductsEnabled</th>\n",
       "      <th>HasTpm</th>\n",
       "      <th>CountryIdentifier</th>\n",
       "      <th>...</th>\n",
       "      <th>Platform_windows8</th>\n",
       "      <th>Processor_x64</th>\n",
       "      <th>Processor_x86</th>\n",
       "      <th>Census_DeviceFamily_Windows.Server</th>\n",
       "      <th>Census_OSArchitecture_arm64</th>\n",
       "      <th>Census_OSArchitecture_x86</th>\n",
       "      <th>Census_GenuineStateName_IS_GENUINE</th>\n",
       "      <th>Census_GenuineStateName_OFFLINE</th>\n",
       "      <th>Census_GenuineStateName_UNKNOWN</th>\n",
       "      <th>HasDetections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552153</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.587952</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.448751</td>\n",
       "      <td>0.528931</td>\n",
       "      <td>0.484434</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552153</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552153</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493175</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.505721</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EngineVersion  AppVersion  AvSigVersion  RtpStateBitfield  \\\n",
       "0       0.552153    0.530941      0.587952               7.0   \n",
       "1       0.448751    0.528931      0.484434               7.0   \n",
       "2       0.552153    0.530941      0.557522               7.0   \n",
       "3       0.552153    0.530941      0.482759               7.0   \n",
       "4       0.493175    0.530941      0.505721               7.0   \n",
       "\n",
       "   IsSxsPassiveMode  AVProductStatesIdentifier  AVProductsInstalled  \\\n",
       "0                 0                    53447.0                  1.0   \n",
       "1                 0                    53447.0                  1.0   \n",
       "2                 0                    53447.0                  1.0   \n",
       "3                 0                    53447.0                  1.0   \n",
       "4                 0                    53447.0                  1.0   \n",
       "\n",
       "   AVProductsEnabled  HasTpm  CountryIdentifier  ...  Platform_windows8  \\\n",
       "0                1.0       1                 29  ...                  0   \n",
       "1                1.0       1                 93  ...                  0   \n",
       "2                1.0       1                 86  ...                  0   \n",
       "3                1.0       1                 97  ...                  0   \n",
       "4                1.0       1                164  ...                  0   \n",
       "\n",
       "   Processor_x64  Processor_x86  Census_DeviceFamily_Windows.Server  \\\n",
       "0              1              0                                   0   \n",
       "1              1              0                                   0   \n",
       "2              1              0                                   0   \n",
       "3              1              0                                   0   \n",
       "4              1              0                                   0   \n",
       "\n",
       "   Census_OSArchitecture_arm64  Census_OSArchitecture_x86  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   Census_GenuineStateName_IS_GENUINE  Census_GenuineStateName_OFFLINE  \\\n",
       "0                                   1                                0   \n",
       "1                                   0                                1   \n",
       "2                                   1                                0   \n",
       "3                                   1                                0   \n",
       "4                                   1                                0   \n",
       "\n",
       "   Census_GenuineStateName_UNKNOWN  HasDetections  \n",
       "0                                0              0  \n",
       "1                                0              0  \n",
       "2                                0              0  \n",
       "3                                0              0  \n",
       "4                                0              0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('processed_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Partitioning the sample into train and test parts is an important step in the process of developing and evaluating machine learning models. The main reasons for this are:\n",
    "\n",
    "1) To evaluate model performance: Splitting the data allows us to use one part of the data (the training part) to train the model and the other part (the test part) to evaluate its performance. This helps in understanding how the model will perform on new, previously unseen data.\n",
    "\n",
    "2) Prevent overfitting: If a model is trained and evaluated on the same data, there is a risk of overfitting, where the model adapts too well to the training data and loses the ability to generalize to new data. Data partitioning helps to identify such problems.\n",
    "\n",
    "3) Objective model comparison: The test dataset serves as a benchmark to objectively compare different models or hyperparameters. This allows you to select the model that shows the best performance on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:58:27.751085Z",
     "start_time": "2024-07-01T05:58:27.700028Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('HasDetections', axis=1)\n",
    "y = data['HasDetections']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "Create two pipelines for machine learning models: Logistic Regression and Linear SVM, including data preprocessing with MinMaxScaler. Train and evaluate the models.\n",
    "Use functions from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:58:34.616508Z",
     "start_time": "2024-07-01T05:58:34.550990Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Build the ROC for both models, calculate the AUC. Of course, train on the traine and measure on the test.\n",
    "\n",
    "Notice! The classical `SVM' implementation, as in the lectures, does not provide any probability estimation. To transform the outputs into probabilities, we used a sigmoid function in practice. Here we suggest that you transform the outputs of `decision_function` into probabilities in a proportional way.\n",
    "\n",
    "For example, you have trained `SVM` and on test data the model produced the following `decision_function` outputs:\n",
    "\n",
    "(-10, -5, 0, +2, +10, +15)\n",
    "\n",
    "For each number, we need to make a transformation into an expression of the form `P(y = +1 | x)`.\n",
    "\n",
    "On the one hand, a negative sign of a number will signal to us that `P(y = +1 | x) < 0.5`.\n",
    "\n",
    "Then a positive one would signal that `P(y = +1 | x) > 0.5`. \n",
    "\n",
    "On the other hand, for those objects that the model is most confident about, we will put marginal probabilities. For the example above:\n",
    "\n",
    "`P(y = +1 | -10) = 0`, `P(y = +1 | +15) = 1`. For all intermediate objects, we apply the proportional transformation. For example:\n",
    "\n",
    "$$\n",
    "P(y = +1 | -5) = \\frac{|-5|}{|-10|} \\cdot 0.5\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(y = +1 | +2) = \\frac{|+2|}{|+15|} \\cdot 0.5 + 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use function **fit()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:10.749466Z",
     "start_time": "2024-07-01T05:58:41.563538Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import **roc_curve** and **RocCurveDisplay**\n",
    "\n",
    "**roc_curve** - A ROC curve is constructed by plotting the ratio of True Positive Rate (TPR) against the ratio of False Positive Rate (FPR) at various probability thresholds. The roc_curve function returns the FPR, TPR, and probability thresholds used to construct the curve.\n",
    "\n",
    "**RocCurveDisplay** - This class simplifies the process of creating and displaying a ROC curve, making it easy to plot and interpret model performance graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:42.350409Z",
     "start_time": "2024-07-01T05:59:42.341767Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1\n",
    "\n",
    "1) Train a Logistic Regression model using a training sample.\n",
    "Using the trained model, predict the probabilities of positive class for the test sample.\n",
    "2) Calculate the TPR (True Positive Rate) and FPR (False Positive Rate) values for different classification thresholds using roc_curve function.\n",
    "3) Construct a ROC curve using the calculated TPR and FPR values and display it using the RocCurveDisplay function.\n",
    "4) Interpret the resulting ROC curve, explaining the value of the area under the curve (AUC) and how it reflects the quality of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:43.488734Z",
     "start_time": "2024-07-01T05:59:43.209753Z"
    }
   },
   "outputs": [],
   "source": [
    "## Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2\n",
    "\n",
    "1) Train an SVM model using a training sample.\n",
    "2) Using the trained model, predict the values of the decision function for the test sample.\n",
    "3) Find the minimum and maximum values among the predicted decision function values.\n",
    "4) Convert the SVM predictions to probabilities using the specified formula:\n",
    "- For negative values, convert them to a range of 0 to 0.5.\n",
    "- For positive values, convert them to a range of 0.5 to 1.\n",
    "5) Explain the logic behind converting decision function values to probabilities and how this might affect the interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:48.395378Z",
     "start_time": "2024-07-01T05:59:48.330065Z"
    }
   },
   "outputs": [],
   "source": [
    "## Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.3\n",
    "\n",
    "1) Calculate False Positive Rate (FPR), True Positive Rate (TPR) and thresholds for the ROC curve based on predicted preds_svm probabilities and true y_test labels.\n",
    "2) Ð¡reate a RocCurveDisplay object and call the plot() method to display the ROC curve based on the calculated FPR (False Positive Rate) and TPR (True Positive Rate) values stored in the fpr2 and tpr2 variables, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:50.640110Z",
     "start_time": "2024-07-01T05:59:50.551021Z"
    }
   },
   "outputs": [],
   "source": [
    "## Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.4\n",
    "Derive the AUC values for the two machine learning models (logistic regression and SVM) based on their respective ROC curves, which were pre-calculated and stored in variables fpr1, tpr1 for logistic regression and fpr2, tpr2 for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:53.511385Z",
     "start_time": "2024-07-01T05:59:53.503433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg auc = 0.689145259958147\n",
      "SVM auc = 0.6877916838949342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc \n",
    "\n",
    "### Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5\n",
    "\n",
    "Build calibration curves for both models. You cannot use the from_estimator method for svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T05:59:58.337557Z",
     "start_time": "2024-07-01T05:59:58.252981Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "### Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T06:00:03.882760Z",
     "start_time": "2024-07-01T06:00:03.811937Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "### Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.6\n",
    "Calibrate the probabilities for the SVM model using the CalibratedClassifierCV method and obtain the adjusted probabilities for the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T06:01:20.779644Z",
     "start_time": "2024-07-01T06:00:07.942693Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "### Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.7\n",
    "\n",
    "Visualize the calibration curve and compare it with the ideal diagonal line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Type your code here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "908564da9541f9d26d1af86ee6b322ed44d6c94bc2ca2345fbed60c52c45f160"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
