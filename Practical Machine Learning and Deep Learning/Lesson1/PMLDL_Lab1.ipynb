{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Machine Learning and Deep Learning\n",
        "## Lesson 1. Basic Machine Learning Application\n",
        "\n",
        "## Introduction\n",
        "\n",
        "\n",
        "The task of our first lesson is to understand the flow of machine learning task. This includes going through the theory and following a set of instructions to complete the code."
      ],
      "metadata": {
        "id": "QO6K_3cuUdTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "In this lab, we would be performing a basic classification on Iris Dataset.\n",
        "\n",
        "\n",
        "### About Iris Dataset\n",
        "The famous Iris dataset is a widely used dataset in machine learning and deep learning. It consists of 150 samples from three species of iris flowers (Iris setosa, Iris versicolor, and Iris virginica), with 50 samples from each species. Each sample includes four features: the lengths and widths of the sepals and petals, measured in centimeters. The dataset is often used for testing algorithms for classification and pattern recognition due to its simplicity and well-defined structure.\n",
        "\n",
        "\n",
        "### Performing the Classification\n",
        "To do so you will need:\n",
        "- Obtain data from competition\n",
        "- Create a Jupyter notebook which will produce a file for submission\n",
        "- Submit it to the competition"
      ],
      "metadata": {
        "id": "QAQm8GaOUdTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required Libraries\n",
        "\n",
        "First we need to import necessary libraries:\n",
        "\n",
        "[Pandas](https://pandas.pydata.org/) - For data analysis and manipulation\n",
        "\n",
        "[Numpy](https://numpy.org/) - To deal with matrices\n",
        "\n",
        "[Warnings](https://docs.python.org/3/library/warnings.html) - To curb warnings to ensure smooth workflow"
      ],
      "metadata": {
        "id": "k7BqE5OpWSTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-08-24T10:30:50.197169Z",
          "iopub.execute_input": "2023-08-24T10:30:50.197503Z",
          "iopub.status.idle": "2023-08-24T10:30:50.206615Z",
          "shell.execute_reply.started": "2023-08-24T10:30:50.197480Z",
          "shell.execute_reply": "2023-08-24T10:30:50.205233Z"
        },
        "trusted": true,
        "id": "_fjQ2NJZUdTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparaing Data\n",
        "Data in Machine Learning and Deep Learning is usally consisting of `train` and `test` splits. Sometimes there's a `validation` split as well.\n",
        "\n",
        "The main purpose of the train-test split is to assess how well a machine learning model generalizes to unseen data. By splitting the dataset, we can train the model on one subset of the data (the training set) and test its performance on another subset (the test set).\n",
        "\n",
        "\n",
        "Train test split usually serves two purposes:\n",
        "1.   **Avoiding Overfitting**: By using a separate test set, we ensure that the modelâ€™s performance is not overly optimistic, as it has not seen the test data during training. This helps to avoid overfitting, where the model performs well on the training data but poorly on unseen data\n",
        "\n",
        "2.   **Model Validation**: It provides a straightforward way to validate the model, giving insights into how it might perform in real-world scenarios\n",
        "\n",
        "\n",
        "Here your goal is to train any appropriate ML model on `train` split and run inference on `test` split.\n",
        "\n"
      ],
      "metadata": {
        "id": "AGdeC7XuUdTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "train_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-24T10:30:50.213069Z",
          "iopub.execute_input": "2023-08-24T10:30:50.213378Z",
          "iopub.status.idle": "2023-08-24T10:30:50.235074Z",
          "shell.execute_reply.started": "2023-08-24T10:30:50.213330Z",
          "shell.execute_reply": "2023-08-24T10:30:50.233716Z"
        },
        "trusted": true,
        "id": "vJGLZ7a0UdTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "In this section, we will preprocess the data. The main steps are to prepare:\n",
        "\n",
        "\n",
        "1.   Training data - which is feature data mainly\n",
        "2.   Labels - It explain what label does the features refer to\n",
        "\n",
        "The target variable y in the Iris dataset consists of categorical values representing different species of iris flowers (e.g., 'setosa', 'versicolor', 'virginica'). Many machine learning algorithms require numerical input, so these categorical labels need to be converted into numerical form. A common approach is to use label encoding, where each category is assigned a unique integer.\n",
        "\n",
        "---\n",
        "\n",
        "EXERCISE 1:\n",
        "\n",
        "Use [label encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to encode the target variables before fitting the model.\n",
        "\n",
        "Step 1: Import the Label Encoder\n",
        "```\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "```\n",
        "Step 2: Use the Encoder to encode values\n",
        "\n",
        "```\n",
        "preproc =  LabelEncoder()\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "tqPHwrK1UdTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y = train_data['species']\n",
        "\n",
        "preproc = ...\n",
        "y = preproc.fit_transform(y)\n",
        "\n",
        "X = train_data.drop('species', axis=1).values\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "sNLvqJi1UdTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert all(label in y for label in [0, 1, 2])\n",
        "print(\"Success\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ8UWtog1Oh1",
        "outputId": "aab4d253-1199-4c4b-ecd7-4c3bc2560b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the Model\n",
        "\n",
        "It is a process of training a model on a dataset to learn the underlying patterns and relationships within the data. This involves adjusting the model's parameters so that its predictions closely match the actual target values. During fitting, the model uses algorithms to minimize the error between its predictions and the true outcomes by optimizing a loss function. The result is a trained model that can make accurate predictions on new, unseen data.\n",
        "\n",
        "Implement any appropriate ML model you like.\n",
        "\n",
        "Since, we have a classification problem we can use any model from the following:\n",
        "\n",
        "\n",
        "*  Decision Trees\n",
        "*  k-Nearest Neighbors (k-NN)\n",
        "*  Support Vector Machines (SVM)\n",
        "*  Logistic Regression\n",
        "*  Neural Networks\n",
        "*  Random Forests\n",
        "\n",
        "\n",
        "---\n",
        "EXERCISE 2:\n",
        "\n",
        "Create a model from the list above using sklearn\n",
        "\n",
        "For example:\n",
        "\n",
        "\n",
        "Step 1: Import the module\n",
        "```\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "```\n",
        "Step 2: Use the model\n",
        "\n",
        "```\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "9Pf49GQ3UdTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = ...\n",
        "model.fit(X, y)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "uFkPmZaPUdTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "The primary goal of inference is to predict the output for new data. For example, in the context of the Iris dataset, inference might involve predicting the species of an iris flower based on its features (sepal length, sepal width, petal length, and petal width).\n",
        "\n",
        "Now that our model is trained on Iris flowers features, we would like to predict the specia based on features (sepal length, sepal width, petal length, and petal width)\n",
        "\n",
        "Run your trained model on `test` split\n"
      ],
      "metadata": {
        "id": "IoEwaiAaUdTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "NpeF-cP7-tF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "EXCERCISE 3:\n",
        "\n",
        "Prepare test features and labels like we did for training data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "amTn9eRx_U3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = ...\n",
        "y_test = ...\n",
        "y_test = preproc.transform(y_test)\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9vGbWSR6UdTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model predictions\n",
        "Save model predictions to `submission.csv` and submit to competition"
      ],
      "metadata": {
        "id": "Sm5L---ZUdTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = pd.DataFrame(columns=['id', 'species'])\n",
        "preds['id'] = test_data.index\n",
        "preds['species'] = preproc.inverse_transform(predictions)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NW1hP98YUdTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "EXCERCISE 4:\n",
        "\n",
        "Save the results to a file namely \"results.csv\" and keep without index\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ss3BXX6yoQdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds..."
      ],
      "metadata": {
        "trusted": true,
        "id": "BcUzRDalUdTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}