{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed04ebc7",
      "metadata": {
        "id": "ed04ebc7"
      },
      "source": [
        "# Practical Machine Learning and Deep Learning\n",
        "\n",
        "# Lesson 7\n",
        "\n",
        "# Semantic Segmentation\n",
        "\n",
        "Semantic segmentation in machine learning is a process where each pixel in an image is classified into a predefined category. Unlike image classification, which assigns a single label to an entire image, semantic segmentation provides a pixel-level understanding, segmenting different objects and regions within the image.\n",
        "\n",
        "### EMaterial Segmentation Dataset\n",
        "\n",
        "Referring to the material segmentation dataset comprising 3817 images gathered from the Virginia Department of Transportation (VDOT) Bridge Inspection Reports, semantic segmentation would involve:\n",
        "\n",
        "1. **Pixel-Level Annotation**:\n",
        "   - Each pixel in the bridge inspection images would be labeled with a specific material category, such as concrete, steel, asphalt, or other materials found in bridge structures.\n",
        "\n",
        "2. **Training a Model**:\n",
        "   - A neural network, often a Convolutional Neural Network (CNN) architecture designed for segmentation tasks (e.g., U-Net, SegNet, or DeepLab), would be trained on this annotated dataset. The model learns to associate pixel patterns with specific material categories.\n",
        "\n",
        "3. **Inference**:\n",
        "   - After training, the model can take a new image as input and output a segmentation map where each pixel is assigned a material category label. This allows for detailed analysis of the materials present in the bridge structure.\n",
        "\n",
        "### Key Steps in Semantic Segmentation\n",
        "\n",
        "1. **Dataset Preparation**:\n",
        "   - The dataset (in this case, the 3817 VDOT images) needs to be annotated at the pixel level, where each pixel is labeled according to the material it represents.\n",
        "\n",
        "2. **Model Architecture**:\n",
        "   - Choose a suitable segmentation model architecture. Popular choices include U-Net, which is effective for biomedical image segmentation but also applicable to other fields, and DeepLab, known for its ability to capture multi-scale contextual information.\n",
        "\n",
        "3. **Training**:\n",
        "   - Train the chosen model on the annotated dataset. This involves feeding the images and their corresponding pixel-level labels into the model, allowing it to learn the patterns associated with each material category.\n",
        "\n",
        "4. **Evaluation**:\n",
        "   - Evaluate the model’s performance using metrics such as Intersection over Union (IoU), pixel accuracy, and mean average precision to ensure it accurately segments materials in new images.\n",
        "\n",
        "5. **Application**:\n",
        "   - Once trained, the model can be used for automated inspection and analysis of bridge materials in new images, assisting in tasks like detecting material defects, monitoring wear and tear, and planning maintenance activities.\n",
        "\n",
        "### Importance in Real-World Applications\n",
        "\n",
        "Semantic segmentation in the context of the VDOT Bridge Inspection Reports can significantly enhance the efficiency and accuracy of bridge maintenance and inspection processes. By automating the material classification task, engineers can quickly identify and analyze the materials used in bridge construction and their condition, leading to better-informed decisions regarding repairs and maintenance, ultimately improving infrastructure safety and longevity.\n",
        "\n",
        "### Example\n",
        "\n",
        "Here we can see an example of semantic segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8jiEg_xvHBst",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8jiEg_xvHBst",
        "outputId": "ac97ce1d-9a54-494f-8c4f-9e2e423fad1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m1,792\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │      \u001b[38;5;34m9,438,208\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m524,544\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m131,200\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m65\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,031,745</span> (118.38 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,031,745\u001b[0m (118.38 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,031,745</span> (118.38 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,031,745\u001b[0m (118.38 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# U-Net\n",
        "def unet_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder (восстановление изображения)\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "#Model parameters\n",
        "input_shape = (128, 128, 3)\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "#Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Output\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aUQ05C_LZaVN",
      "metadata": {
        "id": "aUQ05C_LZaVN"
      },
      "source": [
        "# Downloading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1wqmVTAFSLlN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wqmVTAFSLlN",
        "outputId": "e09e6005-b5d9-427a-b5c7-4d0c4d125b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-08-15 06:37:39--  https://data.lib.vt.edu/ndownloader/articles/16624648/versions/1\n",
            "Resolving data.lib.vt.edu (data.lib.vt.edu)... 34.254.0.68, 52.208.156.232, 2a05:d018:1f4:d000:8d70:679a:ce19:b623, ...\n",
            "Connecting to data.lib.vt.edu (data.lib.vt.edu)|34.254.0.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1942794171 (1.8G) [application/zip]\n",
            "Saving to: ‘1’\n",
            "\n",
            "1                   100%[===================>]   1.81G  19.3MB/s    in 1m 40s  \n",
            "\n",
            "2024-08-15 06:39:20 (18.6 MB/s) - ‘1’ saved [1942794171/1942794171]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## if you do not have .zip file in your folder, you can download it from data lib\n",
        "## https://disk.yandex.ru/d/HDeiMRQ5_pi92g\n",
        "!wget https://data.lib.vt.edu/ndownloader/articles/16624648/versions/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bk6Qn2SyIb",
      "metadata": {
        "id": "46bk6Qn2SyIb"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"1\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZcYfDSX5S_NI",
      "metadata": {
        "id": "ZcYfDSX5S_NI"
      },
      "outputs": [],
      "source": [
        "zip_ref = zipfile.ZipFile(\"Material Detection.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a7261c",
      "metadata": {
        "id": "a6a7261c"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886b3110",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-07T13:27:29.214183Z",
          "iopub.status.busy": "2023-10-07T13:27:29.213878Z",
          "iopub.status.idle": "2023-10-07T13:27:35.042355Z",
          "shell.execute_reply": "2023-10-07T13:27:35.041431Z"
        },
        "id": "886b3110",
        "papermill": {
          "duration": 5.837416,
          "end_time": "2023-10-07T13:27:35.044441",
          "exception": false,
          "start_time": "2023-10-07T13:27:29.207025",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# necessary imports\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SOgIVHaKg6Ql",
      "metadata": {
        "id": "SOgIVHaKg6Ql"
      },
      "source": [
        "## Create Mappings and Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9f6505",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:27:35.055271Z",
          "iopub.status.busy": "2023-10-07T13:27:35.054891Z",
          "iopub.status.idle": "2023-10-07T13:27:35.060476Z",
          "shell.execute_reply": "2023-10-07T13:27:35.059552Z"
        },
        "id": "ce9f6505",
        "papermill": {
          "duration": 0.012731,
          "end_time": "2023-10-07T13:27:35.062165",
          "exception": false,
          "start_time": "2023-10-07T13:27:35.049434",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# necessary constants\n",
        "CLASS_MAPPING = {\n",
        "    0: \"background\",\n",
        "    1: \"steel\",\n",
        "    2: \"concrete\",  # segment concrete\n",
        "    3: \"metal deck\",\n",
        "}\n",
        "COLOR_MAPPING = {\n",
        "    0: (0, 0, 0),\n",
        "    1: (0, 0, 128),\n",
        "    2: (0, 128, 0),\n",
        "    3: (0, 128, 128),\n",
        "}\n",
        "\n",
        "\n",
        "color2label = {v: k for k, v in COLOR_MAPPING.items()}\n",
        "IMG_SIZE = 256\n",
        "MAX_PIXEL_VALUE = 255\n",
        "NORMALIZATION_MEAN = [0.485, 0.456, 0.406]\n",
        "NORMALIZATION_STD = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a385abb",
      "metadata": {
        "id": "2a385abb"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d6caa7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:27:35.081193Z",
          "iopub.status.busy": "2023-10-07T13:27:35.080660Z",
          "iopub.status.idle": "2023-10-07T13:27:35.084633Z",
          "shell.execute_reply": "2023-10-07T13:27:35.083824Z"
        },
        "id": "f1d6caa7",
        "papermill": {
          "duration": 0.010826,
          "end_time": "2023-10-07T13:27:35.086249",
          "exception": false,
          "start_time": "2023-10-07T13:27:35.075423",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_dir = \"Material Detection/original/Train\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155dd7da",
      "metadata": {
        "id": "155dd7da"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "For the following lab we will use [Albumentations](https://albumentations.ai/) for the data transforms. Albumentations allows image and mask transformation at the same time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0004184d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:27:35.096399Z",
          "iopub.status.busy": "2023-10-07T13:27:35.096112Z",
          "iopub.status.idle": "2023-10-07T13:27:35.100739Z",
          "shell.execute_reply": "2023-10-07T13:27:35.099760Z"
        },
        "id": "0004184d",
        "papermill": {
          "duration": 0.01164,
          "end_time": "2023-10-07T13:27:35.102422",
          "exception": false,
          "start_time": "2023-10-07T13:27:35.090782",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ToFloat(max_value=MAX_PIXEL_VALUE),\n",
        "        A.Normalize(\n",
        "            mean=NORMALIZATION_MEAN, std=NORMALIZATION_STD, max_pixel_value=1.0\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O16OunxQLI_2",
      "metadata": {
        "id": "O16OunxQLI_2"
      },
      "source": [
        "### Exercise 1\n",
        "#### Objective:\n",
        "The goal of this assignment is to use the provided SegmentationDataset class to load and preprocess a dataset of images and corresponding masks. You will ensure the dataset is properly structured, load the images and masks into memory.\n",
        "\n",
        "- Data Loading:\n",
        "\n",
        "Implement the data loading process by calling the SegmentationDataset class methods that load images and masks into memory. Ensure that both images and masks are resized to the specified IMG_SIZE.\n",
        "Convert multiclass masks to binary masks focusing on the 'concrete' class as described in the class method _read_masks.\n",
        "\n",
        "- Data Access:\n",
        "\n",
        "Access individual data samples using the getitem method. Ensure that the returned image and mask are transformed according to the provided transformations and that they are correctly formatted as tensors.\n",
        "Check the length of the dataset using the len method to ensure all images and masks have been correctly loaded."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55420452",
      "metadata": {
        "id": "55420452"
      },
      "source": [
        "## Segmentation Dataset Class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XXuoTBg8hn2m",
      "metadata": {
        "id": "XXuoTBg8hn2m"
      },
      "source": [
        "The SegmentationDataset class handles loading and preprocessing of image and mask data from a specified directory structure for a material segmentation task. It ensures that both images and masks are correctly paired, loaded into memory, and transformed appropriately for training a machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc79db42",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:27:35.113196Z",
          "iopub.status.busy": "2023-10-07T13:27:35.112683Z",
          "iopub.status.idle": "2023-10-07T13:27:35.122756Z",
          "shell.execute_reply": "2023-10-07T13:27:35.121968Z"
        },
        "id": "fc79db42",
        "papermill": {
          "duration": 0.017614,
          "end_time": "2023-10-07T13:27:35.124404",
          "exception": false,
          "start_time": "2023-10-07T13:27:35.106790",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_path, transform):\n",
        "        \"\"\"\n",
        "        Material segmentation dataset\n",
        "\n",
        "        :param root_path: path to train split, which contains images and masks\n",
        "        :param transform: transforms for dataset\n",
        "\n",
        "        \"\"\"\n",
        "       # type your code\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # type your code\n",
        "\n",
        "        return\n",
        "\n",
        "    def __len__(self):\n",
        "      # type your code\n",
        "\n",
        "       return\n",
        "\n",
        "    def _get_filenames(self, path):\n",
        "      # type your code\n",
        "\n",
        "        return\n",
        "    def _read_imgs(self):\n",
        "        \"\"\"\n",
        "        Load images into memory\n",
        "        \"\"\"\n",
        "        # type your code\n",
        "\n",
        "\n",
        "    def _read_masks(self):\n",
        "        \"\"\"\n",
        "        Load masks into memory and convert multiclass mask\n",
        "        into binary masks for 'concrete' class\n",
        "        \"\"\"\n",
        "        # type your code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec223d8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-07T13:27:35.134350Z",
          "iopub.status.busy": "2023-10-07T13:27:35.134086Z",
          "iopub.status.idle": "2023-10-07T13:31:22.160713Z",
          "shell.execute_reply": "2023-10-07T13:31:22.159616Z"
        },
        "id": "ec223d8a",
        "outputId": "766b03f9-9ddb-47d1-ab1b-379bc9f0b5c1",
        "papermill": {
          "duration": 227.033733,
          "end_time": "2023-10-07T13:31:22.162614",
          "exception": false,
          "start_time": "2023-10-07T13:27:35.128881",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3436/3436 [00:54<00:00, 63.57it/s] \n",
            "100%|██████████| 3436/3436 [01:06<00:00, 51.70it/s] \n"
          ]
        }
      ],
      "source": [
        "dataset = SegmentationDataset(Path(train_dir), transform=transforms)\n",
        "\n",
        "# splitting dataset into train and validation\n",
        "split_proportion = 0.9\n",
        "size = int(len(dataset) * split_proportion)\n",
        "train_dataset, val_dataset = random_split(dataset, [size, len(dataset) - size])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j1tDK7GKh3eB",
      "metadata": {
        "id": "j1tDK7GKh3eB"
      },
      "source": [
        "## Create Dataloaders\n",
        "\n",
        "We have discussed Dataloaders briefly in previous lesson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb37489",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:22.280471Z",
          "iopub.status.busy": "2023-10-07T13:31:22.280130Z",
          "iopub.status.idle": "2023-10-07T13:31:22.285041Z",
          "shell.execute_reply": "2023-10-07T13:31:22.284099Z"
        },
        "id": "ccb37489",
        "papermill": {
          "duration": 0.066689,
          "end_time": "2023-10-07T13:31:22.286693",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.220004",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# create dataloaders\n",
        "batch_size = 8\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67fa582",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:22.404405Z",
          "iopub.status.busy": "2023-10-07T13:31:22.403697Z",
          "iopub.status.idle": "2023-10-07T13:31:22.410306Z",
          "shell.execute_reply": "2023-10-07T13:31:22.409469Z"
        },
        "id": "e67fa582",
        "outputId": "bfe9b882-5ac4-48e2-9ddb-45093bf44951",
        "papermill": {
          "duration": 0.067957,
          "end_time": "2023-10-07T13:31:22.411920",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.343963",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3092, 344)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the sizes of train and validation splits\n",
        "len(train_dataset), len(val_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4741be0e",
      "metadata": {
        "id": "4741be0e",
        "papermill": {
          "duration": 0.057458,
          "end_time": "2023-10-07T13:31:22.526247",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.468789",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Model\n",
        "\n",
        "U-Net is an architecture for semantic segmentation. It consists of a contracting path and an expansive path. The contracting path follows the typical architecture of a convolutional network. Every step in the expansive path consists of an upsampling of the feature map, a concatenation with the correspondingly cropped feature map from the contracting path, and convolutions.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "![Alt text](https://media.geeksforgeeks.org/wp-content/uploads/20220614121231/Group14.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf1663d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:22.642826Z",
          "iopub.status.busy": "2023-10-07T13:31:22.642485Z",
          "iopub.status.idle": "2023-10-07T13:31:22.654263Z",
          "shell.execute_reply": "2023-10-07T13:31:22.653449Z"
        },
        "id": "ecf1663d",
        "papermill": {
          "duration": 0.073333,
          "end_time": "2023-10-07T13:31:22.656033",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.582700",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    Block with two convolutional blocks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        \"\"\"\n",
        "        Double convolution\n",
        "\n",
        "        :param in_channels: number of in channels for first conv layer\n",
        "        :param out_channels: number of out channels for last conv layer\n",
        "        :param mid_channels: number of out channels for first conv layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "\n",
        "        # write model that contains 2 conv layer with batch normalization and relu activation function\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"\n",
        "    Block for down path\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Down block\n",
        "\n",
        "        :param in_channels: number of in channels for double conv block\n",
        "        :param out_channels: number of out channels for double conv block\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # write model which contains pooling and double conv block\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2), DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"\n",
        "    Block for up path\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Down block\n",
        "\n",
        "        :param in_channels: number of in channels for transpose convolution\n",
        "        :param out_channels: number of out channels for double conv block\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(\n",
        "            in_channels, in_channels // 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Final convolution block\n",
        "\n",
        "        :param in_channels: number of in channels for conv layer\n",
        "        :param out_channels: number of out channels for conv layer\n",
        "        \"\"\"\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0o1oMqX_ROQZ",
      "metadata": {
        "id": "0o1oMqX_ROQZ"
      },
      "source": [
        "### Exercise 2\n",
        "#### Objective:\n",
        "In this assignment, you will implement a U-Net model using the provided UNet class and use it for semantic segmentation tasks. Your tasks include initializing the model, passing data through the model, and ensuring that it produces the expected output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff61cb3d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:22.772420Z",
          "iopub.status.busy": "2023-10-07T13:31:22.772059Z",
          "iopub.status.idle": "2023-10-07T13:31:22.779557Z",
          "shell.execute_reply": "2023-10-07T13:31:22.778584Z"
        },
        "id": "ff61cb3d",
        "papermill": {
          "duration": 0.066714,
          "end_time": "2023-10-07T13:31:22.781223",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.714509",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    UNet model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        # type your code\n",
        "\n",
        "    def forward(self, x):\n",
        "       # type your code\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8955c6d2",
      "metadata": {
        "id": "8955c6d2",
        "papermill": {
          "duration": 0.057194,
          "end_time": "2023-10-07T13:31:22.895712",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.838518",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Loss\n",
        "\n",
        "As the loss we will use combination of Cross Entropy Loss and Dice Loss\n",
        "\n",
        "### Dice loss\n",
        "\n",
        "Dice loss is based on [Sørensen-Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient). It measures the overlap between the predicted and target segmentation masks. Dice loss provides a differentiable and smooth measure of segmentation accuracy.\n",
        "\n",
        "$$\n",
        "DiceLoss\\left( y, \\overline{p} \\right) = 1 - \\dfrac{\\left(  2y\\overline{p} + 1 \\right)} {\\left( y+\\overline{p } + 1 \\right)}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mhg0YTcgRf5N",
      "metadata": {
        "id": "mhg0YTcgRf5N"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "#### Objective:\n",
        "In this assignment, you will work with the provided DiceLoss class to calculate the dice loss for semantic segmentation tasks. Dice loss is a common metric used to evaluate the overlap between the predicted segmentation masks and the ground truth masks. Your tasks include initializing the loss function, applying it to model predictions, and ensuring it computes the correct loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ac95081",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:23.012904Z",
          "iopub.status.busy": "2023-10-07T13:31:23.012000Z",
          "iopub.status.idle": "2023-10-07T13:31:23.018409Z",
          "shell.execute_reply": "2023-10-07T13:31:23.017558Z"
        },
        "id": "4ac95081",
        "papermill": {
          "duration": 0.067488,
          "end_time": "2023-10-07T13:31:23.020091",
          "exception": false,
          "start_time": "2023-10-07T13:31:22.952603",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Dice loss\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, eps=1e-6):\n",
        "        \"\"\"\n",
        "        Calculation of dice loss\n",
        "\n",
        "        :param inputs: model predictions\n",
        "        :param targets: target values\n",
        "        :param eps: stability factor, defaults to 1e-6\n",
        "        :return: loss value\n",
        "        \"\"\"\n",
        "        # implement dice loss\n",
        "       # type your code\n",
        "\n",
        "\n",
        "        return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2422224f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:23.136231Z",
          "iopub.status.busy": "2023-10-07T13:31:23.135585Z",
          "iopub.status.idle": "2023-10-07T13:31:23.467229Z",
          "shell.execute_reply": "2023-10-07T13:31:23.466297Z"
        },
        "id": "2422224f",
        "papermill": {
          "duration": 0.392312,
          "end_time": "2023-10-07T13:31:23.469276",
          "exception": false,
          "start_time": "2023-10-07T13:31:23.076964",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = UNet(n_channels=3, n_classes=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8dd8f6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:23.765147Z",
          "iopub.status.busy": "2023-10-07T13:31:23.764829Z",
          "iopub.status.idle": "2023-10-07T13:31:23.770034Z",
          "shell.execute_reply": "2023-10-07T13:31:23.769079Z"
        },
        "id": "df8dd8f6",
        "papermill": {
          "duration": 0.06535,
          "end_time": "2023-10-07T13:31:23.771784",
          "exception": false,
          "start_time": "2023-10-07T13:31:23.706434",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        ")\n",
        "criterion1 = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "criterion2 = DiceLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AEJkHGMsSGOq",
      "metadata": {
        "id": "AEJkHGMsSGOq"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "\n",
        "#### Model Preparation:\n",
        "\n",
        "- Ensure that your segmentation model (e.g., U-Net) is properly initialized and transferred to the specified device (CPU or GPU) for training.\n",
        "- Initialize two loss criteria (e.g., criterion1 could be cross-entropy loss and criterion2 could be dice loss) that will be used to calculate the combined loss during training and validation.\n",
        "- Set up the optimizer for updating the model parameters.\n",
        "\n",
        "#### Training Loop Execution:\n",
        "\n",
        "- Use the train_model function to start the training process. This function will iterate through the specified number of epochs, calculating the loss for each batch in the training dataset, and updating the model parameters using backpropagation.\n",
        "- The function also includes a validation loop to evaluate the model's performance on the validation dataset after each epoch.\n",
        "\n",
        "#### Monitoring Training Progress:\n",
        "\n",
        "- The training progress is monitored using the tqdm progress bar, which provides real-time updates on the number of images processed and the loss for each batch during both training and validation phases.\n",
        "- The epoch_loss variable accumulates the loss over all batches in an epoch, giving an indication of the overall training loss.\n",
        "\n",
        "####Validation Phase:\n",
        "\n",
        "- After each epoch, the model is set to evaluation mode (model.eval()), and the validation loop is executed without gradient computation (torch.no_grad()). This phase calculates the validation loss on the validation dataset to assess the model's generalization performance.\n",
        "\n",
        "#### Evaluate Results:\n",
        "\n",
        "- At the end of training, analyze the loss values printed during training and validation. A successful training process typically shows a decreasing trend in both training and validation loss.\n",
        "\n",
        "#### Expected Outcome:\n",
        "- Model Training: The segmentation model should be trained over the specified number of epochs, with training and validation loss values computed and displayed after each epoch.\n",
        "- Loss Monitoring: Both training and validation loss should ideally decrease over time, indicating that the model is learning effectively and generalizing well to the validation data.\n",
        "- Model Evaluation: The final output should provide insights into the model's performance and help determine if further tuning or additional epochs are needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0430b524",
      "metadata": {
        "id": "0430b524"
      },
      "source": [
        "## Training\n",
        "The function `train_model` will train our segmentation model and validate its performance over a specified number of epochs (default is 10). During each epoch, the model will be set to training mode, and it will process batches of images and corresponding masks from the training dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba86758",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:23.887041Z",
          "iopub.status.busy": "2023-10-07T13:31:23.886719Z",
          "iopub.status.idle": "2023-10-07T13:31:23.895396Z",
          "shell.execute_reply": "2023-10-07T13:31:23.894426Z"
        },
        "id": "7ba86758",
        "papermill": {
          "duration": 0.068273,
          "end_time": "2023-10-07T13:31:23.897118",
          "exception": false,
          "start_time": "2023-10-07T13:31:23.828845",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, device, optimizer, epochs=10):\n",
        "    \"\"\"\n",
        "    Train a segmentation model and validate its performance.\n",
        "\n",
        "    :param model: The model to be trained.\n",
        "    :param train_loader: DataLoader for the training dataset.\n",
        "    :param val_loader: DataLoader for the validation dataset.\n",
        "    :param device: Device to run the training on (CPU or GPU).\n",
        "    :param optimizer: Optimizer to use for training.\n",
        "    :param epochs: Number of epochs to train the model.\n",
        "    \"\"\"\n",
        "  # type your code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06081954",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-07T13:31:24.012547Z",
          "iopub.status.busy": "2023-10-07T13:31:24.011741Z",
          "iopub.status.idle": "2023-10-07T13:46:47.314070Z",
          "shell.execute_reply": "2023-10-07T13:46:47.313119Z"
        },
        "id": "06081954",
        "outputId": "01ac2d74-3840-4dbb-b072-08825b10d8f7",
        "papermill": {
          "duration": 923.362327,
          "end_time": "2023-10-07T13:46:47.315915",
          "exception": false,
          "start_time": "2023-10-07T13:31:23.953588",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 3092/3092 [02:55<00:00, 17.62img/s, loss (batch)=0.601]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.92img/s, loss (batch)=0.697]\n",
            "Epoch 2/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.34img/s, loss (batch)=1.01]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 47.15img/s, loss (batch)=0.553]\n",
            "Epoch 3/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.33img/s, loss (batch)=0.622]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 47.14img/s, loss (batch)=0.563]\n",
            "Epoch 4/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.32img/s, loss (batch)=1.17]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.55img/s, loss (batch)=0.439]\n",
            "Epoch 5/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.31img/s, loss (batch)=0.392]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.76img/s, loss (batch)=0.464]\n",
            "Epoch 6/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.32img/s, loss (batch)=0.56]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.69img/s, loss (batch)=0.319]\n",
            "Epoch 7/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.33img/s, loss (batch)=0.36]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.64img/s, loss (batch)=0.551]\n",
            "Epoch 8/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.33img/s, loss (batch)=0.571]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.55img/s, loss (batch)=0.408]\n",
            "Epoch 9/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.33img/s, loss (batch)=0.411]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 46.68img/s, loss (batch)=0.287]\n",
            "Epoch 10/10: 100%|██████████| 3092/3092 [02:58<00:00, 17.31img/s, loss (batch)=0.599]\n",
            "Validation: 100%|██████████| 344/344 [00:07<00:00, 47.08img/s, loss (batch)=0.262]\n"
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, val_loader, \"cuda\", optimizer, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdWoy24DkMyz",
      "metadata": {
        "id": "fdWoy24DkMyz"
      },
      "source": [
        "## Let's save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a4f0996",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:48.179084Z",
          "iopub.status.busy": "2023-10-07T13:46:48.178749Z",
          "iopub.status.idle": "2023-10-07T13:46:48.418017Z",
          "shell.execute_reply": "2023-10-07T13:46:48.417002Z"
        },
        "id": "3a4f0996",
        "papermill": {
          "duration": 0.673409,
          "end_time": "2023-10-07T13:46:48.420307",
          "exception": false,
          "start_time": "2023-10-07T13:46:47.746898",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"best.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "025a9d39",
      "metadata": {
        "id": "025a9d39"
      },
      "source": [
        "## Predict\n",
        "\n",
        "For prediction, we will first follow some transformation steps that we performed earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25bd7dbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:49.324026Z",
          "iopub.status.busy": "2023-10-07T13:46:49.323673Z",
          "iopub.status.idle": "2023-10-07T13:46:49.329256Z",
          "shell.execute_reply": "2023-10-07T13:46:49.328224Z"
        },
        "id": "25bd7dbd",
        "papermill": {
          "duration": 0.428466,
          "end_time": "2023-10-07T13:46:49.330985",
          "exception": false,
          "start_time": "2023-10-07T13:46:48.902519",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_mask(mask, color_mapping=COLOR_MAPPING):\n",
        "    color_mask = np.zeros((*mask.shape[::-1], 3), dtype=np.uint8)\n",
        "    for i in range(mask.shape[1]):\n",
        "        for j in range(mask.shape[0]):\n",
        "            color_mask[i, j] = color_mapping[mask[j, i]]\n",
        "    color_mask = cv2.cvtColor(color_mask, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(color_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6753bc0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:50.947902Z",
          "iopub.status.busy": "2023-10-07T13:46:50.947492Z",
          "iopub.status.idle": "2023-10-07T13:46:50.952929Z",
          "shell.execute_reply": "2023-10-07T13:46:50.952119Z"
        },
        "id": "c6753bc0",
        "papermill": {
          "duration": 0.923852,
          "end_time": "2023-10-07T13:46:50.956965",
          "exception": false,
          "start_time": "2023-10-07T13:46:50.033113",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=0),\n",
        "        A.ToFloat(max_value=MAX_PIXEL_VALUE),\n",
        "        A.Normalize(\n",
        "            mean=NORMALIZATION_MEAN, std=NORMALIZATION_STD, max_pixel_value=1.0\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917ddca5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:51.881164Z",
          "iopub.status.busy": "2023-10-07T13:46:51.880843Z",
          "iopub.status.idle": "2023-10-07T13:46:51.886505Z",
          "shell.execute_reply": "2023-10-07T13:46:51.885542Z"
        },
        "id": "917ddca5",
        "papermill": {
          "duration": 0.480101,
          "end_time": "2023-10-07T13:46:51.888203",
          "exception": false,
          "start_time": "2023-10-07T13:46:51.408102",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "RESULTS_SHAPE = (64, 64)\n",
        "\n",
        "\n",
        "def predict(model, img, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Model inference on image\n",
        "\n",
        "    :param model: model\n",
        "    :param img: image\n",
        "    :param device: device for computation, defaults to \"cpu\"\n",
        "    :return: mask\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    tensor_img = test_transforms(image=img)[\"image\"]\n",
        "    tensor_img = tensor_img.to(device=device, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor_img)\n",
        "        mask = output.argmax(dim=1)\n",
        "    mask = mask.detach().cpu().numpy()[0].astype(np.uint8)\n",
        "    mask = cv2.resize(mask, RESULTS_SHAPE, interpolation=cv2.INTER_NEAREST)\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a86db70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:52.726832Z",
          "iopub.status.busy": "2023-10-07T13:46:52.726496Z",
          "iopub.status.idle": "2023-10-07T13:46:54.609005Z",
          "shell.execute_reply": "2023-10-07T13:46:54.608094Z"
        },
        "id": "6a86db70",
        "outputId": "9c3e96c8-316b-47ea-d1a5-c7798a15aeab",
        "papermill": {
          "duration": 2.3107,
          "end_time": "2023-10-07T13:46:54.611124",
          "exception": false,
          "start_time": "2023-10-07T13:46:52.300424",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = cv2.imread(\n",
        "    \"Material Detection/original/Test/images/0.jpeg\"\n",
        ")\n",
        "mask = predict(model, img)\n",
        "plot_mask(mask)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efeb8ede",
      "metadata": {
        "id": "efeb8ede"
      },
      "source": [
        "## Results\n",
        "\n",
        "Run-Length encoding (RLE)\n",
        "\n",
        "The Run-Length encoding function performs run-length encoding on a binary mask array by first identifying the indices of the foreground pixels. It then iterates through these indices, grouping consecutive pixels into runs. For each run, it records the start position and the length of the run, resulting in a list of start positions and lengths. This method efficiently compresses the mask data by only storing information about the runs of foreground pixels, rather than every individual pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a462d68f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:55.504500Z",
          "iopub.status.busy": "2023-10-07T13:46:55.504077Z",
          "iopub.status.idle": "2023-10-07T13:46:55.510952Z",
          "shell.execute_reply": "2023-10-07T13:46:55.509860Z"
        },
        "id": "a462d68f",
        "papermill": {
          "duration": 0.427417,
          "end_time": "2023-10-07T13:46:55.512683",
          "exception": false,
          "start_time": "2023-10-07T13:46:55.085266",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def rle_encode(x, fg_val=1):\n",
        "    dots = np.where(x.T.flatten() == fg_val)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if b > prev + 1:\n",
        "            run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "\n",
        "def list_to_string(x):\n",
        "    if x:  # non-empty list\n",
        "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
        "    else:\n",
        "        s = \"-\"\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a55d89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:56.403393Z",
          "iopub.status.busy": "2023-10-07T13:46:56.402858Z",
          "iopub.status.idle": "2023-10-07T13:46:56.794714Z",
          "shell.execute_reply": "2023-10-07T13:46:56.793745Z"
        },
        "id": "49a55d89",
        "outputId": "8deb2bf1-0d5b-4040-d9b6-2d76b796be6c",
        "papermill": {
          "duration": 0.863982,
          "end_time": "2023-10-07T13:46:56.796465",
          "exception": false,
          "start_time": "2023-10-07T13:46:55.932483",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = UNet(n_channels=3, n_classes=2)\n",
        "model.load_state_dict(torch.load(\"best.pt\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c593e54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-07T13:46:57.635240Z",
          "iopub.status.busy": "2023-10-07T13:46:57.634874Z",
          "iopub.status.idle": "2023-10-07T13:47:17.501173Z",
          "shell.execute_reply": "2023-10-07T13:47:17.500236Z"
        },
        "id": "6c593e54",
        "outputId": "6ad6ffe4-fd01-4bfa-9bbd-da6d6b85a4bf",
        "papermill": {
          "duration": 20.292345,
          "end_time": "2023-10-07T13:47:17.502955",
          "exception": false,
          "start_time": "2023-10-07T13:46:57.210610",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 381/381 [00:18<00:00, 20.18it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns=[\"id\", \"pixels\"])\n",
        "test_dir = \"/content/Material Detection/original/Test/images/\"\n",
        "for i, f in tqdm(enumerate(os.listdir(test_dir)), total=len(os.listdir(test_dir))):\n",
        "    img = cv2.imread(test_dir + f)\n",
        "    mask = predict(model, img, device=\"cuda\")\n",
        "    pred = list_to_string(rle_encode(mask))\n",
        "    df.loc[i] = [f[:-5], pred]\n",
        "df.to_csv(\"results.csv\", index=None)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1195.259307,
      "end_time": "2023-10-07T13:47:21.458888",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-10-07T13:27:26.199581",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
