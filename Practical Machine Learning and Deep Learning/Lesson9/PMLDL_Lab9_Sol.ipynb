{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Machine Learning and Deep Learning\n",
        "\n",
        "# Lab 9\n",
        "\n",
        "# Graph Classification Task\n",
        "\n",
        "\n",
        "In this lesson you will implement graph classifier using a graph neural network (GNN).\n",
        "\n",
        "Graph classification is an important problem with applications across many fields, such as bioinformatics, chemoinformatics, social network analysis, urban computing, and cybersecurity. Applying graph neural networks to this problem has been a popular approach recently. This can be seen in the following research references:\n",
        "\n",
        "[Ying et al., 2018](https://arxiv.org/abs/1806.08804),\n",
        "[Cangea et al., 2018](https://arxiv.org/abs/1811.01287),\n",
        "[Knyazev et al., 2018](https://arxiv.org/abs/1811.09595),\n",
        "[Bianchi et al., 2019](https://arxiv.org/abs/1901.01343),\n",
        "[Liao et al., 2019](https://arxiv.org/abs/1901.01484),\n",
        "[Gao et al., 2019](https://openreview.net/forum?id=HJePRoAct7)\n"
      ],
      "metadata": {
        "id": "D1EPPRUWvcNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "For working with graphs we will use library `dgl`. It offer a lot of methods and useful structures for working with graph structures alongside the `pytorch` support."
      ],
      "metadata": {
        "id": "AcmGCC19vcNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.1.2"
      ],
      "metadata": {
        "id": "H5OxLk8X4yv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl -q"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:36.380649Z",
          "iopub.execute_input": "2023-10-31T16:54:36.381091Z",
          "iopub.status.idle": "2023-10-31T16:54:47.785129Z",
          "shell.execute_reply.started": "2023-10-31T16:54:36.381043Z",
          "shell.execute_reply": "2023-10-31T16:54:47.783521Z"
        },
        "trusted": true,
        "id": "sA1wuxynvcNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data reading and preprocessing\n",
        "\n",
        "First, let's create dataset class for our task. This is the same dataset as for any other classification tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## EXERCISE 1:\n",
        "Create the following functions:\n",
        "* `__getitem__` should return sample and its label. Label is single integer and sample type is `dgl.DGLGraph`\n",
        "* `__len__` returns length of the of the set\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Gi767KzfvcNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, List\n",
        "import os\n",
        "os.environ['DGLBACKEND'] = 'pytorch'\n",
        "import pandas as pd\n",
        "from dgl import DGLGraph, graph as graph_constructor\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class GraphClassificationDataset(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_path = csv_path\n",
        "        self._read_data()\n",
        "\n",
        "    def _read_data(self) -> Tuple[List[DGLGraph], List[int]]:\n",
        "        self.graph_ids = []\n",
        "        self.graphs = []\n",
        "        self.labels = []\n",
        "        df = pd.read_csv(self.data_path, header=0, index_col='graph_id')\n",
        "\n",
        "        for graph_id, sample in df.iterrows():\n",
        "            graph = self._create_graph(\n",
        "                num_nodes=sample.num_nodes,\n",
        "                num_edges=sample.num_edges,\n",
        "                edges_from=list(map(int, sample.edges_from.split(' '))),\n",
        "                edges_to=list(map(int, sample.edges_from.split(' '))),\n",
        "            )\n",
        "\n",
        "            self.graph_ids.append(graph_id)\n",
        "            self.graphs.append(graph)\n",
        "            try:\n",
        "                self.labels.append(sample.label)\n",
        "            except:\n",
        "                self.labels.append(graph_id) # just to get it later\n",
        "\n",
        "    def _create_graph(self, num_nodes: int, num_edges: int, edges_from: List[int], edges_to: List[int]) -> DGLGraph:\n",
        "        assert len(edges_from) == num_edges, 'Something is wrong with edges_from'\n",
        "        assert len(edges_to) == num_edges, 'Something is wrong with edges_to'\n",
        "\n",
        "        graph = graph_constructor(\n",
        "            num_nodes=num_nodes,\n",
        "            data=(edges_from, edges_to),\n",
        "        )\n",
        "        return graph\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[DGLGraph, int]:\n",
        "        return self.graphs[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:47.787900Z",
          "iopub.execute_input": "2023-10-31T16:54:47.788358Z",
          "iopub.status.idle": "2023-10-31T16:54:47.803397Z",
          "shell.execute_reply.started": "2023-10-31T16:54:47.788313Z",
          "shell.execute_reply": "2023-10-31T16:54:47.801931Z"
        },
        "trusted": true,
        "id": "zrWER4VjvcNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_raw = GraphClassificationDataset('graph_classification_train.csv')\n",
        "test_dataset = GraphClassificationDataset('graph_classification_test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:47.805306Z",
          "iopub.execute_input": "2023-10-31T16:54:47.805810Z",
          "iopub.status.idle": "2023-10-31T16:54:48.417818Z",
          "shell.execute_reply.started": "2023-10-31T16:54:47.805726Z",
          "shell.execute_reply": "2023-10-31T16:54:48.416701Z"
        },
        "trusted": true,
        "id": "xWrp6N6UvcNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(train_set_raw)==800\n",
        "assert len(test_dataset)==200\n",
        "print(\"Test cases passed\")"
      ],
      "metadata": {
        "id": "SuzJnl_aNED4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Set percentage of data to use as a training subset\n",
        "train_ratio = 0.8\n",
        "\n",
        "train_size = int(train_ratio * len(train_set_raw))\n",
        "val_size = len(train_set_raw) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_set_raw, (train_size, val_size))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.420448Z",
          "iopub.execute_input": "2023-10-31T16:54:48.420783Z",
          "iopub.status.idle": "2023-10-31T16:54:48.426562Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.420754Z",
          "shell.execute_reply": "2023-10-31T16:54:48.425456Z"
        },
        "trusted": true,
        "id": "c0LiA20VvcNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoaders\n",
        "\n",
        "To train neural networks efficiently, a common practice is to batch\n",
        "multiple samples together to form a mini-batch. Batching fixed-shaped tensor\n",
        "inputs is common. For example, batching two images of size 28 x 28\n",
        "gives a tensor of shape 2 x 28 x 28. By contrast, batching graph inputs\n",
        "has two challenges:\n",
        "\n",
        "* Graphs are sparse.\n",
        "* Graphs can have various length. For example, number of nodes and edges.\n",
        "\n",
        "To address this, DGL provides a :func:`dgl.batch` API. It leverages the idea that\n",
        "a batch of graphs can be viewed as a large graph that has many disjointed\n",
        "connected components. Below is a visualization that gives the general idea.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/batch/batch.png)"
      ],
      "metadata": {
        "id": "g5_OJOfZvcNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "\n",
        "from dgl import batch as construct_graph_batch\n",
        "\n",
        "def collate_graph_batch(samples: List[Tuple[DGLGraph, int]]) -> Tuple[Tensor, Tensor]:\n",
        "    graphs, labels = map(list, zip(*samples))\n",
        "    batched_graph = construct_graph_batch(graphs)\n",
        "    return batched_graph, Tensor(labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.427863Z",
          "iopub.execute_input": "2023-10-31T16:54:48.428233Z",
          "iopub.status.idle": "2023-10-31T16:54:48.444348Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.428195Z",
          "shell.execute_reply": "2023-10-31T16:54:48.443197Z"
        },
        "trusted": true,
        "id": "QG1Obb7uvcNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 8\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_graph_batch, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_graph_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_graph_batch)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.446351Z",
          "iopub.execute_input": "2023-10-31T16:54:48.446686Z",
          "iopub.status.idle": "2023-10-31T16:54:48.456488Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.446659Z",
          "shell.execute_reply": "2023-10-31T16:54:48.455272Z"
        },
        "trusted": true,
        "id": "BWadYGj_vcNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model implementation\n",
        "\n",
        "Graph classification proceeds as follows.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/batch/graph_classifier.png)\n",
        "\n",
        "\n",
        "From a batch of graphs, perform message passing and graph convolution for nodes to communicate with others. After message passing, compute a tensor for graph representation from node (and edge) attributes. This step might  be called readout or aggregation. Finally, the graph  representations are fed into a classifier $g$ to predict the graph labels.\n",
        "\n",
        "Graph convolution layer can be found in the ``dgl.nn.<backend>`` submodule.\n",
        "\n",
        "In this lab the easiest choice is `GraphConv`. [Docs](https://docs.dgl.ai/en/1.1.x/generated/dgl.nn.pytorch.conv.GraphConv.html#dgl.nn.pytorch.conv.GraphConv).\n"
      ],
      "metadata": {
        "id": "BZDfRGwMvcNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import dgl\n",
        "from dgl.nn.pytorch import GraphConv\n",
        "\n",
        "class GraphClassifier(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        input_dim = 1\n",
        "        # NOTE: for educational purposes here we use 1 as input dimension.\n",
        "        # However, in production feature vector is the information about the node.\n",
        "        # For example, in social networks the feature vector could represent the user\n",
        "        # (e.g. its choices of movies)\n",
        "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.head = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, graphs):\n",
        "        # Use node degree as the initial node feature. For undirected graphs, the in-degree\n",
        "        # is the same as the out_degree.\n",
        "        h = graphs.in_degrees().view(-1, 1).float()\n",
        "\n",
        "        # Perform graph convolution and activation function.\n",
        "        h = self.conv1(graphs, h)\n",
        "        h = self.relu1(h)\n",
        "        h = self.conv2(graphs, h)\n",
        "        h = self.relu2(h)\n",
        "\n",
        "        graphs.ndata['h'] = h\n",
        "        # Calculate graph representation by averaging all the node representations.\n",
        "        hg = dgl.mean_nodes(graphs, 'h')\n",
        "        return self.head(hg)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.458223Z",
          "iopub.execute_input": "2023-10-31T16:54:48.458600Z",
          "iopub.status.idle": "2023-10-31T16:54:48.470798Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.458567Z",
          "shell.execute_reply": "2023-10-31T16:54:48.469605Z"
        },
        "trusted": true,
        "id": "-1-4lHHJvcNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## EXERCISE 2:\n",
        "Set the device type\n",
        "\n",
        "*   If cuda is available, set torch device to cuda\n",
        "*   If cuda is unavailable, set torch device to cpu\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "m43xT9-_vcNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_DIM = 256\n",
        "\n",
        "# Select the where to perform\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# Create an instance of the model and pass its weights to the device\n",
        "model = GraphClassifier(HIDDEN_DIM, NUM_CLASSES).to(device)\n",
        "# Set the loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# Set the opimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) # Using Karpathy's learning rate constant"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.473016Z",
          "iopub.execute_input": "2023-10-31T16:54:48.473856Z",
          "iopub.status.idle": "2023-10-31T16:54:48.489003Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.473822Z",
          "shell.execute_reply": "2023-10-31T16:54:48.487779Z"
        },
        "trusted": true,
        "id": "8XtLli4IvcNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are utility functions to calculate and show metrics:"
      ],
      "metadata": {
        "id": "hgovIIT_vcNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "    if metric_fn != accuracy_score:\n",
        "        return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "    else:\n",
        "        return metric_fn(true_y, pred_y)\n",
        "\n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.490536Z",
          "iopub.execute_input": "2023-10-31T16:54:48.490936Z",
          "iopub.status.idle": "2023-10-31T16:54:48.499237Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.490904Z",
          "shell.execute_reply": "2023-10-31T16:54:48.497864Z"
        },
        "trusted": true,
        "id": "yiUVRFpmvcNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 60\n",
        "\n",
        "losses = []\n",
        "batches = len(train_dataloader)\n",
        "val_batches = len(val_dataloader)\n",
        "\n",
        "# loop for every epoch (training + evaluation)\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    # progress bar\n",
        "    progress = tqdm(enumerate(train_dataloader), desc=\"Loss: \", total=batches)\n",
        "\n",
        "    # ----------------- TRAINING  --------------------\n",
        "    # set model to training\n",
        "    model.train()\n",
        "\n",
        "    for i, (graphs, labels) in progress:\n",
        "\n",
        "        graphs = graphs.to(device)\n",
        "        labels = labels.to(device).long()\n",
        "\n",
        "        # training step for single batch\n",
        "        model.zero_grad()\n",
        "        outputs = model(graphs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update running training loss\n",
        "        current_loss = loss.item()\n",
        "        total_loss += current_loss * BATCH_SIZE\n",
        "\n",
        "        # updating progress bar\n",
        "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "\n",
        "    # releasing unceseccary memory in GPU\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ----------------- VALIDATION  -----------------\n",
        "    val_losses = 0\n",
        "    precision, recall, f1, accuracy = [], [], [], []\n",
        "\n",
        "    # set model to evaluating (testing)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (graphs, labels) in enumerate(val_dataloader):\n",
        "            graphs = graphs.to(device)\n",
        "            labels = labels.to(device).long()\n",
        "\n",
        "            outputs = model(graphs)\n",
        "\n",
        "            # update running validation loss\n",
        "            val_losses += loss_function(outputs, labels) * BATCH_SIZE\n",
        "\n",
        "            predicted_classes = torch.max(outputs, 1)[1]\n",
        "\n",
        "            # calculate P/R/F1/A metrics for batch\n",
        "            for acc, metric in zip((precision, recall, f1, accuracy),\n",
        "                                   (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "                acc.append(\n",
        "                    calculate_metric(metric, labels.cpu(), predicted_classes.cpu())\n",
        "                )\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
        "    print_scores(precision, recall, f1, accuracy, val_batches)\n",
        "    losses.append(total_loss/batches)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:54:48.502374Z",
          "iopub.execute_input": "2023-10-31T16:54:48.502699Z",
          "iopub.status.idle": "2023-10-31T16:55:02.989997Z",
          "shell.execute_reply.started": "2023-10-31T16:54:48.502673Z",
          "shell.execute_reply": "2023-10-31T16:55:02.988805Z"
        },
        "trusted": true,
        "id": "Tw0aML6FvcNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "Produce labels on the testing graphs\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## EXERCISE 3:\n",
        "1. Pass graphs to model for generating output\n",
        "2. Use [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html) to select maximum value from outputs generated in previous step\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nEOSGj0evcNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, (graphs, graph_ids) in enumerate(test_dataloader):\n",
        "\n",
        "        graphs = graphs.to(device)\n",
        "        outputs = model(graphs)\n",
        "\n",
        "        predicted = torch.max(outputs, 1)[1]\n",
        "        predictions.extend(predicted.tolist())"
      ],
      "metadata": {
        "id": "7gYqF8LQad_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert list(outputs.shape)==[8,8]\n",
        "assert len(predictions)==200\n",
        "print(\"Test cases passed\")"
      ],
      "metadata": {
        "id": "O2ENgUq5af5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the results file\n",
        "results = pd.DataFrame(columns=['graph_id', 'label'])\n",
        "results['graph_id'] = test_dataset.graph_ids\n",
        "results['label'] = predictions\n",
        "results.to_csv('results.csv', index=None)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-31T16:55:03.043329Z",
          "iopub.execute_input": "2023-10-31T16:55:03.043739Z",
          "iopub.status.idle": "2023-10-31T16:55:03.053188Z",
          "shell.execute_reply.started": "2023-10-31T16:55:03.043709Z",
          "shell.execute_reply": "2023-10-31T16:55:03.052256Z"
        },
        "trusted": true,
        "id": "uJu3MizNvcNx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}