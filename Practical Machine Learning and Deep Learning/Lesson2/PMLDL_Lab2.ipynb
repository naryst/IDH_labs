{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "qMvtTHcOmnSD"
   },
   "source": [
    "# Practical Machine Learning and Deep Learning\n",
    "## Lesson 2: Tools and Processes for Machine Learning and Data Analysis\n",
    "\n",
    "### Introduction\n",
    "\n",
    "We will learn the basic tools and processes needed to analyze data and create machine learning models. An introduction to important tools such as programming languages, libraries, and development environments will help us prepare for practical data analysis tasks. We will also review the steps of data preparation, model training, and model evaluation to understand how these processes integrate to solve real-world machine learning problems.\n",
    "\n",
    "### Goal\n",
    "Your goal is to familiarize yourself with tools for data processing, model training and inference, and ways to log model metrics\n",
    "\n",
    "## Submission\n",
    "Your goal is to implement small neural network to classify images and generate `submission.csv` for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cu4Oce1PmnSH"
   },
   "source": [
    "## Libraries\n",
    "\n",
    "### Frameworks\n",
    "\n",
    "#### PyTorch\n",
    "- PyTorch is an open-source machine learning library primarily developed by Facebook's AI Research lab. It is widely used for deep learning tasks.\n",
    "\n",
    "#### TensorFlow\n",
    "- TensorFlow is an open-source machine learning framework developed by Google. It's designed for building and training deep neural networks.\n",
    "\n",
    "### Logging\n",
    "\n",
    "\n",
    "##### Tensorboard\n",
    "\n",
    "   - TensorBoard is a visualization tool provided by TensorFlow for monitoring and visualizing the training process and model performance during machine learning experiments.\n",
    "\n",
    "\n",
    "##### WandB (Weights & Biases)\n",
    "\n",
    "   - Weights & Biases is a platform that provides tools for tracking, visualizing, and optimizing machine learning experiments\n",
    "\n",
    "##### ClearML\n",
    "   - ClearML is an open-source machine learning platform designed to automate and streamline the end-to-end machine learning workflow, including data management, model training, and deployment.\n",
    "\n",
    "\n",
    "### Data Preprocessing\n",
    "   Data preprocessing involves cleaning, transforming, and organizing raw data to make it suitable for analysis or machine learning. This step is essential for improving data quality and model performance.\n",
    "\n",
    "##### Pandas\n",
    " - Pandas is an open-source data manipulation and analysis library for Python. It provides data structures like DataFrames and Series, making it easy to work with structured data.\n",
    "\n",
    "##### Matplotlib\n",
    "- Matplotlib is a Python library for creating static, animated, and interactive visualizations in various formats. It's commonly used for data visualization and plotting.\n",
    "\n",
    "##### Torchvision\n",
    "- Torchvision is a PyTorch library that offers datasets, transformations, and models for computer vision tasks.\n",
    "\n",
    "##### Torchtext\n",
    "- Torchtext is a PyTorch library that offers datasets, transformations, and models for natural language processing tasks.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCXK8lyPoqIA"
   },
   "source": [
    "## Importing required Libraries\n",
    "\n",
    "First we need to import necessary libraries:\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) - For data analysis and manipulation\n",
    "\n",
    "[Numpy](https://numpy.org/) - To deal with matrices\n",
    "\n",
    "[Torch](https://pytorch.org/) - For buliding a neural network\n",
    "\n",
    "[Warnings](https://docs.python.org/3/library/warnings.html) - To curb warnings to ensure smooth workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:14.607460Z",
     "iopub.status.busy": "2023-09-02T11:15:14.606755Z",
     "iopub.status.idle": "2023-09-02T11:15:14.643395Z",
     "shell.execute_reply": "2023-09-02T11:15:14.641788Z",
     "shell.execute_reply.started": "2023-09-02T11:15:14.607399Z"
    },
    "id": "FN_lFIzOmnSH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# We will use tensorboard as logging tool.\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:14.649741Z",
     "iopub.status.busy": "2023-09-02T11:15:14.647016Z",
     "iopub.status.idle": "2023-09-02T11:15:14.681450Z",
     "shell.execute_reply": "2023-09-02T11:15:14.679853Z",
     "shell.execute_reply.started": "2023-09-02T11:15:14.649677Z"
    },
    "id": "a0C6wRRImnSJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Link to TensorBoard documentation\n",
    "tensorboard_url = \"https://www.tensorflow.org/tensorboard/get_started\"\n",
    "print(f\"For more details on TensorBoard, visit {tensorboard_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbreBEJoqLV7"
   },
   "source": [
    "## About the Data:\n",
    "\n",
    "\n",
    "Each image in the [dataset](https://www.kaggle.com/competitions/pmldl-week-2-tools-and-processes/data) is 28x28. Each pixel has a single pixel-value in grayscale. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set has 785 columns:\n",
    "- The first column is the digit that was drawn by the user.\n",
    "- The rest of the columns contain the pixel-values of the associated image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSD5Yp6KmnSJ"
   },
   "source": [
    "## Data preprocessing\n",
    "we should use both datasets (mnist_train.csv and mnist_test.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:26.613712Z",
     "iopub.status.busy": "2023-09-02T11:15:26.613022Z",
     "iopub.status.idle": "2023-09-02T11:15:32.930009Z",
     "shell.execute_reply": "2023-09-02T11:15:32.928854Z",
     "shell.execute_reply.started": "2023-09-02T11:15:26.613677Z"
    },
    "id": "5MBAowZXmnSK",
    "outputId": "006a420e-07fd-4bbc-d75a-3dfef2c071f2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Data Preprocessing\n",
    "# We should use both datasets (mnist_train.csv and mnist_test.csv).\n",
    "\n",
    "# read train data\n",
    "train_df = pd.read_csv('mnist_train.csv', header=None)\n",
    "test_df = pd.read_csv('mnist_test.csv', header=None)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCQ8TyW7rEAv"
   },
   "source": [
    "Reshape the NumPy array into a 3D array with shape such that it arranges the data into 28x28 matrices (likely images), with the number of such matrices being automatically determined.\n",
    "\n",
    "After that normalize the pixel values by dividing each value by 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTfor4JZruar"
   },
   "source": [
    "# Split images and labels\n",
    "\n",
    "labels = train_df[0].values\n",
    "\n",
    "images = train_df.drop(0, axis=1).values.reshape(-1, 28, 28) / 255\n",
    "\n",
    "### Perform the data augmentation\n",
    "Some of the examples of Image Augmentation could be to:\n",
    "1.   Flip the image horizontally\n",
    "2.   Rotate the image by up to 10 degrees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = train_df[0].values\n",
    "images = train_df.drop(0, axis=1).values\n",
    "\n",
    "print(f'Labels shape: {labels.shape}')\n",
    "print(f'Images shape before reshape: {images.shape}')\n",
    "\n",
    "images = images.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:33.291429Z",
     "iopub.status.busy": "2023-09-02T11:15:33.290600Z",
     "iopub.status.idle": "2023-09-02T11:15:33.580692Z",
     "shell.execute_reply": "2023-09-02T11:15:33.579635Z",
     "shell.execute_reply.started": "2023-09-02T11:15:33.291398Z"
    },
    "id": "AuZf6MvdmnSL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        #   Here you can add more augmentations.\n",
    "        #   See documentation: https://pytorch.org/vision/stable/transforms.html\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_labels = train_df[0].values\n",
    "train_images = train_df.drop(0, axis=1).values.reshape(-1, 28, 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Data Preprocessing\n",
    "\n",
    "In this task, you are required to:\n",
    "1. Load and preprocess the MNIST dataset.\n",
    "2. Convert data to tensors.\n",
    "3. Visualize images.\n",
    "\n",
    "**Expected Outcome:**\n",
    "- A DataFrame containing the loaded dataset.\n",
    "- A set of augmented images displayed using `matplotlib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert data to tensors\n",
    "train_images_tensor = torch.stack(...).float()\n",
    "train_labels_tensor = torch.tensor(...)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUdc2UvGsaME"
   },
   "source": [
    "### Plot the Images\n",
    "\n",
    "It is always helpful to plot the images in a dataset before creating and training the neural network. It can help with:\n",
    "\n",
    "1.  Checking Data Integrity\n",
    "      Ensuring that the images are loaded correctly without any corruption.\n",
    "2. Correct Labels\n",
    "      Verifying that the images correspond to the correct labels.\n",
    "3. Visual Inspection\n",
    "      Gaining an understanding of what the images look like and the variety within the dataset.\n",
    "4. Transformation Effects\n",
    "      Ensuring that the applied transformations (e.g., normalization, augmentation) are behaving as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:35.940012Z",
     "iopub.status.busy": "2023-09-02T11:15:35.939645Z",
     "iopub.status.idle": "2023-09-02T11:15:35.947997Z",
     "shell.execute_reply": "2023-09-02T11:15:35.947007Z",
     "shell.execute_reply.started": "2023-09-02T11:15:35.939982Z"
    },
    "id": "82DBOQjjmnSM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, captions=[], rows=2, columns=5, title=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Plots images with captions\n",
    "\n",
    "    :param images: list of images to plot\n",
    "    :param captions: captions of images:\n",
    "    :param rows: number of rows in figure\n",
    "    :param columns: number of columns:\n",
    "    :param title: super title of figure\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    for i, img in enumerate(images):\n",
    "        fig.add_subplot(rows, columns, i + 1)\n",
    "        plt.imshow(img, **kwargs)\n",
    "        if i < len(captions):\n",
    "            plt.title(captions[i])\n",
    "        plt.axis(\"off\")\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:35.949770Z",
     "iopub.status.busy": "2023-09-02T11:15:35.949444Z",
     "iopub.status.idle": "2023-09-02T11:15:36.640958Z",
     "shell.execute_reply": "2023-09-02T11:15:36.639602Z",
     "shell.execute_reply.started": "2023-09-02T11:15:35.949741Z"
    },
    "id": "sGnPaEjSmnSM",
    "outputId": "2e71226c-073f-464c-f6b0-1a454902928e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualise 10 images from the dataset\n",
    "plot_images(...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:36.642876Z",
     "iopub.status.busy": "2023-09-02T11:15:36.642457Z",
     "iopub.status.idle": "2023-09-02T11:15:36.660559Z",
     "shell.execute_reply": "2023-09-02T11:15:36.659160Z",
     "shell.execute_reply.started": "2023-09-02T11:15:36.642839Z"
    },
    "id": "cboAcpfGmnSM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "\n",
    "# set proportion and split dataset into train and validation parts\n",
    "proportion = ...\n",
    "train_size = ...\n",
    "val_size = ...\n",
    "\n",
    "train_dataset, val_dataset = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:36.663057Z",
     "iopub.status.busy": "2023-09-02T11:15:36.662499Z",
     "iopub.status.idle": "2023-09-02T11:15:36.669073Z",
     "shell.execute_reply": "2023-09-02T11:15:36.668234Z",
     "shell.execute_reply.started": "2023-09-02T11:15:36.663014Z"
    },
    "id": "gXqePHtzmnSM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Dataloaders for training\n",
    "# Dataloader is iterable object over dataset\n",
    "batch_size = ...\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a Neural Network\n",
    "\n",
    "Next, we will build a simple neural network using PyTorch to classify the images.\n",
    "\n",
    "### Exercise 2: Define the Model\n",
    "\n",
    "In this task, you are required to:\n",
    "1. Define a neural network model using PyTorch.\n",
    "2. Specify the optimizer and loss function.\n",
    "3. Set up TensorBoard for logging the training process.\n",
    "\n",
    "**Expected Outcome:**\n",
    "- A PyTorch model definition.\n",
    "- Optimizer and loss function initialization.\n",
    "- TensorBoard logging setup.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ4lBkw1mnSN"
   },
   "source": [
    "## Model\n",
    "We will implement MLP(multi-layer perceptron).\n",
    "An MLP is a class of feedforward artificial neural networks (ANNs) consisting of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each layer is fully connected to the next one in a feedforward manner.\n",
    "\n",
    "> if you want higher score implement any suitable model you know and like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:36.683024Z",
     "iopub.status.busy": "2023-09-02T11:15:36.682504Z",
     "iopub.status.idle": "2023-09-02T11:15:36.693346Z",
     "shell.execute_reply": "2023-09-02T11:15:36.692383Z",
     "shell.execute_reply.started": "2023-09-02T11:15:36.682995Z"
    },
    "id": "D59gH_UBmnSN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    MLP (multi-layer perceptron) based classification model for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        # Add fully connected layers to nn.Sequential to create MLP\n",
    "        # First layer should take 28x28 vector\n",
    "        # last layer should return vector of size num_classes\n",
    "        # do not forget to add activation function between layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            ...\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 3: Train the Model\n",
    "\n",
    "In this task, you are required to:\n",
    "1. Train the model using the training dataset.\n",
    "2. Log the training process to TensorBoard.\n",
    "3. Evaluate the model on the test dataset.\n",
    "\n",
    "**Expected Outcome:**\n",
    "- Model training with loss and accuracy logged to TensorBoard.\n",
    "- Evaluation results on the test dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJl4z9ErmnSN"
   },
   "source": [
    "## Training\n",
    "\n",
    "Here is the sample function for training procedure.\n",
    "We save the checkpoints with best accuracy score. For the inference you need to load it to the model.\n",
    "\n",
    "> You can add early stopping if you want for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:36.695182Z",
     "iopub.status.busy": "2023-09-02T11:15:36.694859Z",
     "iopub.status.idle": "2023-09-02T11:15:36.710267Z",
     "shell.execute_reply": "2023-09-02T11:15:36.709361Z",
     "shell.execute_reply.started": "2023-09-02T11:15:36.695154Z"
    },
    "id": "JDlAXeoQmnSN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    writer,\n",
    "    epochs=1,\n",
    "    device=\"cpu\",\n",
    "    ckpt_path=\"best.pt\",\n",
    "):\n",
    "    # best score for checkpointing\n",
    "    best = 0.0\n",
    "\n",
    "    # iterating over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # training loop description\n",
    "        train_loop = tqdm(\n",
    "            enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "        )\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        # iterate over dataset\n",
    "        for i, data in train_loop:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            ...\n",
    "\n",
    "            # forward pass and loss calculation\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(...)\n",
    "\n",
    "            # backward pass\n",
    "            ...\n",
    "\n",
    "            # optimizer run\n",
    "            ...\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_loop.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "        # write loss to tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", train_loss / len(train_loader), epoch)\n",
    "\n",
    "        # validation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()  # evaluation mode\n",
    "            val_loop = tqdm(enumerate(val_loader, 0), total=len(val_loader), desc=\"Val\")\n",
    "            for i, data in val_loop:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                # type code\n",
    "                _, predicted = ...\n",
    "                total += labels.size(0)\n",
    "                # type code\n",
    "                correct += ...\n",
    "\n",
    "                val_loop.set_postfix({\"acc\": correct / total})\n",
    "\n",
    "            if correct / total > best:\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "                # type code\n",
    "                best = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:36.712532Z",
     "iopub.status.busy": "2023-09-02T11:15:36.711673Z",
     "iopub.status.idle": "2023-09-02T11:15:36.730958Z",
     "shell.execute_reply": "2023-09-02T11:15:36.729698Z",
     "shell.execute_reply.started": "2023-09-02T11:15:36.712500Z"
    },
    "id": "Un5YkhIkmnSN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Type code\n",
    "model = ClassificationModel()\n",
    "optimizer = ...\n",
    "loss_fn = ...\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:36.733940Z",
     "iopub.status.busy": "2023-09-02T11:15:36.733466Z",
     "iopub.status.idle": "2023-09-02T11:15:40.623299Z",
     "shell.execute_reply": "2023-09-02T11:15:40.621808Z",
     "shell.execute_reply.started": "2023-09-02T11:15:36.733900Z"
    },
    "id": "TJDXoDlzmnSN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:40.625676Z",
     "iopub.status.busy": "2023-09-02T11:15:40.625219Z",
     "iopub.status.idle": "2023-09-02T11:15:40.632015Z",
     "shell.execute_reply": "2023-09-02T11:15:40.630502Z",
     "shell.execute_reply.started": "2023-09-02T11:15:40.625640Z"
    },
    "id": "5bp_AwTdmnSN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kaggle has no support of viewing tensorboard. Run this if you are using your machine\n",
    "# to see logs.\n",
    "# !tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 4: Evaluate the Model\n",
    "\n",
    "In this task, you are required to:\n",
    "1. Evaluate the trained model on the test dataset.\n",
    "2. Log the evaluation results to TensorBoard.\n",
    "3. Generate predictions and save them to `submission.csv`.\n",
    "\n",
    "**Expected Outcome:**\n",
    "- Evaluation results logged to TensorBoard.\n",
    "- `submission.csv` file containing the model's predictions on the test dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKqNa5LQmnSO"
   },
   "source": [
    "## Inference\n",
    "Here you need to perform inference of trained model on test data.\n",
    "\n",
    "Load the best checkpoint from training to the model and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:40.633759Z",
     "iopub.status.busy": "2023-09-02T11:15:40.633401Z",
     "iopub.status.idle": "2023-09-02T11:15:40.663863Z",
     "shell.execute_reply": "2023-09-02T11:15:40.662616Z",
     "shell.execute_reply.started": "2023-09-02T11:15:40.633732Z"
    },
    "id": "7dc1LBl4mnSO",
    "outputId": "d5f799ef-6afc-41c2-cb2c-b4ac397f2ff8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load best checkpoint to model\n",
    "model = ClassificationModel()\n",
    "ckpt = torch.load(\"best.pt\")\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:40.666672Z",
     "iopub.status.busy": "2023-09-02T11:15:40.666191Z",
     "iopub.status.idle": "2023-09-02T11:15:40.674437Z",
     "shell.execute_reply": "2023-09-02T11:15:40.673297Z",
     "shell.execute_reply.started": "2023-09-02T11:15:40.666631Z"
    },
    "id": "REFCOr58mnSO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Run model inference on test data\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        test_loop = tqdm(enumerate(test_loader, 0), total=len(test_loader), desc=\"Test\")\n",
    "        for i, inputs in test_loop:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Type code\n",
    "            _, predicted = ...\n",
    "            predictions.extend(predicted.tolist())\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:41.589593Z",
     "iopub.status.busy": "2023-09-02T11:15:41.589154Z",
     "iopub.status.idle": "2023-09-02T11:15:42.051471Z",
     "shell.execute_reply": "2023-09-02T11:15:42.050606Z",
     "shell.execute_reply.started": "2023-09-02T11:15:41.589554Z"
    },
    "id": "j23NzNnzmnSO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# process test data and run inference on it\n",
    "test_images = test_df.values.reshape(-1, 28, 28) / 255\n",
    "test_images_tensor = torch.stack([transform(image) for image in test_images]).float()\n",
    "\n",
    "test_loader = ...\n",
    "# generate predictions\n",
    "predictions = predict(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T11:15:42.053678Z",
     "iopub.status.busy": "2023-09-02T11:15:42.052715Z",
     "iopub.status.idle": "2023-09-02T11:15:42.097597Z",
     "shell.execute_reply": "2023-09-02T11:15:42.096093Z",
     "shell.execute_reply.started": "2023-09-02T11:15:42.053645Z"
    },
    "id": "ZZlKKDN8mnSO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# generate the submission file\n",
    "submission_df = pd.DataFrame({'ImageId': np.arange(1, len(predictions) + 1), 'Label': predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('submission.csv')\n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
