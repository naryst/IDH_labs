{"cells":[{"cell_type":"markdown","metadata":{},"source":["# NLP. Lesson 6. Parsing. Syntax\n","\n","## Parsing\n","\n","In the 3rd lesson we considered POS tagging and parsing basics. Today we are going to dive deeper in NLP parsing and observe its types. \n","\n","`Parsing` is the process of examining the `grammatical structure` and relationships inside a given sentence or text in natural language processing (NLP). It involves analyzing the text to determine the roles of specific words, such as nouns, verbs, and adjectives, as well as their interrelationships. This analysis produces a structured representation of the text, allowing NLP computers to understand how words in a phrase connect to one another. Parsers expose the structure of a sentence by constructing parse trees or dependency trees that illustrate the hierarchical and syntactic relationships between words.\n","\n","Natural languages follow certain rules of grammar. This helps the parser extract the structure. Formally, we can define parsing as:\n",">the process of determining whether a string of tokens can be generated by a grammar.\n","By extracting and representing this structure, we transform the original plain input into something more useful for many downstream NLP tasks.\n","\n","Typical parsing flow:\n","\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/ParsingFlow.png\" alt=\"Typical parsing flow\" width=\"800\"/>\n","\n","In a typical flow, input text goes into a lexical analyzer that produces individual tokens. These tokens are the input to a parser, which produces the syntactic structure at the output. When this structure is graphically represented as a tree, it's called a Parse Tree. A parse tree can be simplified into an intermediate representation called Abstract Syntax Tree (AST). Structure can be represented either as a phrase structure tree or in labelled bracketed notation.\n","\n","### Types\n","\n","- **Syntactic Parsing:** deals with a sentence’s `grammatical structure`. It involves looking at the sentence to determine parts of speech, sentence boundaries, and word relationships. The following sub-parts of Syntatic parsing were observed in the 3rd lesson:\n","  - **Constituency Parsing**: builds parse trees that break down a sentence into its constituents, such as noun phrases and verb phrases. It displays a sentence’s `hierarchical` structure, demonstrating how words are arranged into bigger grammatical units.\n","  - **Dependency Parsing**: depicts grammatical links between words by constructing a tree structure in which each word in the sentence is `dependent` on another. It is frequently used in tasks such as information extraction and machine translation because it focuses on word relationships such as subject-verb-object relations.\n","- **Semantic Parsing:** goes beyond syntactic structure to extract a sentence’s `meaning` or semantics. It attempts to understand the roles of words in the context of a certain task and how they interact with one another. It can be seen in:\n","  - Named Entity Recognition (NER): identifying and classifying entities such as names of people, organizations, locations, etc.\n","  - Semantic Role Labeling (SRL): determining the roles that different words play in a sentence.\n","  - Abstract Meaning Representation (AMR): creating a graph-based representation of the meaning of sentences.\n","\n","### Applications\n","\n","- Syntactic Analysis\n","- Named Entity Recognition (NER)\n","- Semantic Role Labeling (SRL)\n","- Machine Translation\n","- Question Answering\n","- Text Summarization\n","- Information Extraction\n","\n","### Difficulties: structural ambiguity and correct embedding\n","\n","Structural ambiguity is the potential of multiple interpretations for a piece of language because of the way words or phrases are organized. This can lead to several different parse trees produced from the same sentence or phrase. An example is \"I shot an elephant in my pajamas.\" Was I or was the elephant wearing my pajamas? Humans also use sarcasm, colloquial phrases, idioms, and metaphors. They may also communicate with grammatical or spelling errors.\n","\n","One more problem is to obtain the correct semantic relationships and understand the context of discussion. Word embeddings such as word2vec operate at word level. This work needs to be extended to phrases."]},{"cell_type":"markdown","metadata":{},"source":["### Example workflow\n","\n","1. POS tagging. Output - tags (determined parts of speech) for each word\n","2. Constituency parsing. Using POS tags to form a tree structure. Breaks down into noun phrases (NP) and verb phrases (VP).\n","3. Dependency parsing. Analyzes dependencies between words.\n","4. Shallow parsing. Identifies chunks using POS tags. Simplifies parsing by grouping chunks without deep hierarchical structure.\n","5. NER. Identifies entities.\n","6. Semantic parsing. Converts sentence into a meaningful representation, such as an intent and slots in a chatbot application."]},{"cell_type":"markdown","metadata":{},"source":["## Syntax tree\n","\n","A Syntax tree or a parse tree is a tree representation (hierarchical structure) of different syntactic categories of a sentence according to a given grammar. It helps us to understand the syntactical structure of a sentence. Parse trees may be generated for sentences in natural languages, as well as during processing of computer languages, such as programming languages.\n","\n","The standard way to represent the syntactic structure of a grammatical sentence. There are 2 types:\n","- Constituency-based parse tree: represents the sentence structure by breaking it down into sub-phrases or `constituents`, usually derived from a context-free grammar, shows the syntactic structure of a sentence.\n","- Dependency-based parse tree: represents the grammatical structure of a sentence by showing the `dependencies` between words, simpler on average than constituency-based parse trees because they contain fewer nodes.\n","\n","\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/ConstituencyParseTree.png\" alt=\"Constituency Parse Tree\" width=\"600\"/>\n","\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/DependencyParseTree.png\" alt=\"Dependency Parse Tree\" width=\"600\"/>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:17:43.037971Z","iopub.status.busy":"2024-02-22T12:17:43.037609Z","iopub.status.idle":"2024-02-22T12:17:44.467759Z","shell.execute_reply":"2024-02-22T12:17:44.466591Z","shell.execute_reply.started":"2024-02-22T12:17:43.037943Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/anastasia/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /home/anastasia/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: svgling in /home/anastasia/NLPcourse/.venv/lib/python3.11/site-packages (0.4.0)\n","Requirement already satisfied: svgwrite in /home/anastasia/NLPcourse/.venv/lib/python3.11/site-packages (from svgling) (1.4.3)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["import nltk\n","from nltk import pos_tag, word_tokenize, RegexpParser\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","!pip install svgling"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:17:46.440430Z","iopub.status.busy":"2024-02-22T12:17:46.439891Z","iopub.status.idle":"2024-02-22T12:17:46.448520Z","shell.execute_reply":"2024-02-22T12:17:46.446751Z","shell.execute_reply.started":"2024-02-22T12:17:46.440395Z"},"trusted":true},"outputs":[],"source":["def create_syntax_tree(sentence: str) -> nltk.tree.tree.Tree:\n","    \"\"\" Function for creating the nltk constituency-based syntax tree\n","    \n","    Args:\n","        sentence (str): a sentence that should be represented as a tree\n","\n","    Returns:\n","        syntax_tree(nltk.tree.tree.Tree): the tree\n","    \"\"\"\n","\n","    # Find all parts of speech in sentence\n","    tagged = pos_tag(word_tokenize(sentence))\n","\n","    # Extract all parts of speech from  sentence. Define the grammar\n","    chunker = RegexpParser(\n","        \"\"\"\n","    NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n","    P: {<IN>}            #To extract Prepositions\n","    V: {<V.*>}           #To extract Verbs\n","    PP: {<p> <NP>}       #To extract Prepositional Phrases\n","    VP: {<V> <NP|PP>*}   #To extract Verb Phrases\n","    \"\"\"\n","    )\n","\n","    # Parse the sentence using chunker\n","    syntax_tree = chunker.parse(tagged)\n","    return syntax_tree\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:17:48.883478Z","iopub.status.busy":"2024-02-22T12:17:48.883062Z","iopub.status.idle":"2024-02-22T12:17:49.049511Z","shell.execute_reply":"2024-02-22T12:17:49.048388Z","shell.execute_reply.started":"2024-02-22T12:17:48.883442Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  He/PRP\n","  (VP (V clustered/VBD) (NP the/DT data/NN))\n","  (P into/IN)\n","  (NP information/NN)\n","  granules/NNS)\n"]}],"source":["sentence = \"He clustered the data into information granules\"\n","syntax_tree = create_syntax_tree(sentence)\n","print(syntax_tree)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:17:51.291856Z","iopub.status.busy":"2024-02-22T12:17:51.290847Z","iopub.status.idle":"2024-02-22T12:17:51.301196Z","shell.execute_reply":"2024-02-22T12:17:51.299777Z","shell.execute_reply.started":"2024-02-22T12:17:51.291814Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["sh: line 1: Xvfb: command not found\n"]}],"source":["import os\n","\n","os.system(\n","    \"Xvfb :1 -screen 0 1600x1200x16  &\"\n",")  # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n","os.environ[\"DISPLAY\"] = \":1.0\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:17:54.734706Z","iopub.status.busy":"2024-02-22T12:17:54.734317Z","iopub.status.idle":"2024-02-22T12:17:55.385418Z","shell.execute_reply":"2024-02-22T12:17:55.384115Z","shell.execute_reply.started":"2024-02-22T12:17:54.734677Z"},"trusted":true},"outputs":[{"data":{"image/svg+xml":["<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,448.0,216.0\" width=\"448px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"8.92857%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">He</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.46429%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"39.2857%\" x=\"8.92857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">clustered</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">data</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.5714%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"10.7143%\" x=\"48.2143%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">P</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">into</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.5714%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"23.2143%\" x=\"58.9286%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">information</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.5357%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"17.8571%\" x=\"82.1429%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">granules</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.0714%\" y1=\"19.2px\" y2=\"48px\" /></svg>"],"text/plain":["Tree('S', [('He', 'PRP'), Tree('VP', [Tree('V', [('clustered', 'VBD')]), Tree('NP', [('the', 'DT'), ('data', 'NN')])]), Tree('P', [('into', 'IN')]), Tree('NP', [('information', 'NN')]), ('granules', 'NNS')])"]},"metadata":{},"output_type":"display_data"}],"source":["from IPython.display import display\n","\n","display(syntax_tree)"]},{"cell_type":"markdown","metadata":{},"source":["## Dependency parsing\n","\n","In dependency parsing, we try to use dependency-based grammars to analyze and infer both structure and semantic dependencies and relationships between tokens in a sentence.\n","\n","<img src=\"https://files.realpython.com/media/displacy_dependency_parse.de72f9b1d115.png\" alt=\"Typical parsing flow\" width=\"800\"/> \n","\n","Dependency Parsing used in shallow parsing and NER. A produced result contains root nodes and dependent nodes. The root nodes are usually Verbs, they are the main part in the sentence. "]},{"cell_type":"markdown","metadata":{},"source":["### Task 1.\n","Recall the building of Dependency Parsing using spaCy. "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:17:59.302251Z","iopub.status.busy":"2024-02-22T12:17:59.301886Z","iopub.status.idle":"2024-02-22T12:18:03.383565Z","shell.execute_reply":"2024-02-22T12:18:03.382335Z","shell.execute_reply.started":"2024-02-22T12:17:59.302223Z"},"trusted":true},"outputs":[{"data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5c3b37486c99409ea00c8c2560b13754-0\" class=\"displacy\" width=\"1260\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Innopolis</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">University</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">is</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">AUX</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">a</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">university</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">located</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">in</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">city</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">of</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">Innopolis.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">PROPN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L64,104.0 76,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-1\" stroke-width=\"2px\" d=\"M180,112.0 C180,57.0 265.0,57.0 265.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M180,114.0 L174,104.0 186,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-2\" stroke-width=\"2px\" d=\"M400,112.0 C400,57.0 485.0,57.0 485.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M400,114.0 L394,104.0 406,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-3\" stroke-width=\"2px\" d=\"M290,112.0 C290,2.0 490.0,2.0 490.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M490.0,114.0 L496.0,104.0 484.0,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-4\" stroke-width=\"2px\" d=\"M510,112.0 C510,57.0 595.0,57.0 595.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M595.0,114.0 L601.0,104.0 589.0,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-5\" stroke-width=\"2px\" d=\"M620,112.0 C620,57.0 705.0,57.0 705.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M705.0,114.0 L711.0,104.0 699.0,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-6\" stroke-width=\"2px\" d=\"M840,112.0 C840,57.0 925.0,57.0 925.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M840,114.0 L834,104.0 846,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-7\" stroke-width=\"2px\" d=\"M730,112.0 C730,2.0 930.0,2.0 930.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M930.0,114.0 L936.0,104.0 924.0,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-8\" stroke-width=\"2px\" d=\"M950,112.0 C950,57.0 1035.0,57.0 1035.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1035.0,114.0 L1041.0,104.0 1029.0,104.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-5c3b37486c99409ea00c8c2560b13754-0-9\" stroke-width=\"2px\" d=\"M1060,112.0 C1060,57.0 1145.0,57.0 1145.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-5c3b37486c99409ea00c8c2560b13754-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1145.0,114.0 L1151.0,104.0 1139.0,104.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import spacy\n","from spacy import displacy\n","\n","# Load the language\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Parse the sentence\n","sentence_output = nlp(\n","    \"Innopolis University is a university located in the city of Innopolis.\"\n",")\n","\n","# Display\n","displacy.render(\n","    sentence_output,\n","    jupyter=True,\n","    options={\"distance\": 110, \"arrow_stroke\": 2, \"arrow_width\": 8},\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.\n","Fill the gaps. Find the dependent words in sentences (direct dependencies and roots)."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import spacy\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","def find_direct_dependents(sentence, word):\n","    doc = nlp(sentence)\n","    dependents = [token.text for token in doc if token.head.text == word]\n","    return dependents\n","\n","# Test cases\n","sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n","word1 = \"jumps\"\n","sentence2 = \"She enjoys playing tennis.\"\n","word2 = \"enjoys\"\n","\n","# Expected output for test cases\n","expected_output1 = ['fox', 'jumps', 'over', '.']\n","expected_output2 = ['She', 'enjoys', 'playing', '.']\n","\n","# Asserts to check correctness\n","assert find_direct_dependents(sentence1, word1) == expected_output1, \"Test case 1 is failed\"\n","assert find_direct_dependents(sentence2, word2) == expected_output2, \"Test case 2 is failed\""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import spacy\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","def extract_root(sentence):\n","    doc = nlp(sentence)\n","    root = [token.text for token in doc if token.head == token][0]\n","    return root\n","\n","# Test cases\n","sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n","sentence2 = \"She enjoys playing tennis.\"\n","\n","# Expected output for test cases\n","expected_output1 = 'jumps'\n","expected_output2 = 'enjoys'\n","\n","# Asserts to check correctness\n","assert extract_root(sentence1) == expected_output1, \"Test case 1 is failed\"\n","assert extract_root(sentence2) == expected_output2, \"Test case 2 is failed\""]},{"cell_type":"markdown","metadata":{},"source":["## Constituency Parsing\n","\n","Constituent-based grammars are used to analyze and determine the constituents of a sentence. These grammars can be used to model or represent the internal structure of sentences in terms of a hierarchically ordered structure of their constituents. A constituency parser can be built based on such grammars/rules. The grammar has to be defined.\n","\n","Lets build the constituency parsing using benepar and spaCy libraries."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:18:06.874087Z","iopub.status.busy":"2024-02-22T12:18:06.873458Z","iopub.status.idle":"2024-02-22T12:18:43.081318Z","shell.execute_reply":"2024-02-22T12:18:43.079759Z","shell.execute_reply.started":"2024-02-22T12:18:06.874052Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install benepar\n","!python -m spacy download en_core_web_md\n","# In colab ⚠ Restart to reload dependencies"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:23:52.562359Z","iopub.status.busy":"2024-02-22T12:23:52.561885Z","iopub.status.idle":"2024-02-22T12:23:55.075803Z","shell.execute_reply":"2024-02-22T12:23:55.074808Z","shell.execute_reply.started":"2024-02-22T12:23:52.562323Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package benepar_en3 to\n","[nltk_data]     /home/anastasia/nltk_data...\n","[nltk_data]   Unzipping models/benepar_en3.zip.\n","/home/anastasia/NLPcourse/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/home/anastasia/NLPcourse/.venv/lib/python3.11/site-packages/torch/distributions/distribution.py:53: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  warnings.warn(\n"]}],"source":["import benepar, spacy\n","\n","nlp = spacy.load('en_core_web_md')\n","benepar.download('benepar_en3')\n","nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n","doc = nlp('The time for action is now. It is never too late to do something.')\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:23:55.078587Z","iopub.status.busy":"2024-02-22T12:23:55.077922Z","iopub.status.idle":"2024-02-22T12:23:55.384517Z","shell.execute_reply":"2024-02-22T12:23:55.383355Z","shell.execute_reply.started":"2024-02-22T12:23:55.078550Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(S (NP (NP (DT The) (NN time)) (PP (IN for) (NP (NN action)))) (VP (VBZ is) (ADVP (RB now))) (. .))\n","('S',)\n","The time for action\n"]}],"source":["sent = list(doc.sents)[0]\n","\n","print(sent._.parse_string)\n","# (S (NP (NP (DT The) (NN time)) (PP (IN for) (NP (NN action)))) (VP (VBZ is) (ADVP (RB now))) (. .))\n","\n","print(sent._.labels)\n","# ('S',)\n","\n","print(list(sent._.children)[0])"]},{"cell_type":"markdown","metadata":{},"source":["## Parsing Techniques\n","\n","### Top-Down parsing\n","Top-Down parsing starts from the highest-level rule (the start symbol, typically the sentence (S)) and works its way down to the input tokens by recursively breaking down the rules.\n","\n","Characteristics:\n","\n","- Starts from the root (S) and tries to rewrite it to match the input sentence.\n","- Can be recursive and uses backtracking.\n","- It tries to construct the parse tree from the top (start symbol) to the leaves (input tokens).\n","\n","Example of Top-Down Parsing:\n","\n","Sentence: the cat sees the dog. \n","\n","S -> NP VP (the cat (NP) sees the dog (VP))\n","\n","NP -> DT N (the (DT) cat (N))\n","\n","VP -> V NP (sees (V) the dog (NP))\n","\n","NP -> DT N (the (DT) dog (N))\n","\n","#### Backtracking case:\n","\n","Take the sentence: “John is playing game”. Grammar rules: S = Noun Phrase (NP)  + Verb Phrase (VP) + Preposition Phrase (PP). The first attempt to find the correct tree is to split the sentence on NP + VP.\n","\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/TopDown1.png\" alt=\"Top down parsing 1\" width=\"800\"/> \n","\n","Part of the speech (NP) does not match the input string, because there is no Determinator+Noun, backtrack to the node NP.\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/TopDown2.png\" alt=\"Top down parsing 2\" width=\"800\"/> \n","\n","Part of the speech verb does not match the input string, \"is\" isn't represented in the tree, backtrack to the node S, since PNoun is matched.\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/TopDown3.png\" alt=\"Top down parsing 3\" width=\"800\"/> \n","\n","- Simple to implement, clear and intuitive approach\n","- Can be inefficient due to backtracking, and not suitable for left-recursive grammars (which can lead to infinite loops)\n","\n","### Bottom-Up parsing\n","Bottom-Up parsing starts from the input tokens and works its way up to the start symbol by combining the tokens according to the grammar rules. Builds the parse tree by identifying sub-phrases and combining them. More systematic and often more efficient than top-down parsing.\n","- Can handle left-recursive grammars efficiently\n","- More complex, requires more memory for storing intermediate results\n","\n","#### Example\n","Consider the same sentence with John and the same grammar.\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/BottomUp1.png\" alt=\"Bottom Up parsing 1\" width=\"800\"/> \n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/BottomUp2.png\" alt=\"Bottom Up parsing 2\" width=\"800\"/> \n","\n","Lets consider the Top-Down variant of parsing and apply the Recursive Descent Parser (will be explaine in the next section). "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["('*', ('+', ('number', '3'), ('number', '5')), ('number', '2'))"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["class RecursiveDescentParser:\n","    \"\"\" Class for parsing mathematical expressions. \"\"\"\n","    def __init__(self, tokens):\n","        self.tokens = tokens\n","        self.position = 0\n","\n","    def parse(self):\n","        return self.E()\n","\n","    def match(self, expected_token):\n","        if self.position < len(self.tokens) and self.tokens[self.position] == expected_token:\n","            self.position += 1\n","            return True\n","        return False\n","\n","    def E(self):\n","        node = self.T()\n","        if self.match('+'):\n","            right = self.E()\n","            node = ('+', node, right)\n","        return node\n","\n","    def T(self):\n","        node = self.F()\n","        if self.match('*'):\n","            right = self.T()\n","            node = ('*', node, right)\n","        return node\n","\n","    def F(self):\n","        if self.match('('):\n","            node = self.E()\n","            if not self.match(')'):\n","                raise SyntaxError(\"Expected ')'\")\n","            return node\n","        elif self.position < len(self.tokens) and self.tokens[self.position].isdigit():\n","            node = ('number', self.tokens[self.position])\n","            self.position += 1\n","            return node\n","        else:\n","            raise SyntaxError(\"Expected number or '('\")\n","\n","# Example usage\n","expression = '( 3 + 5 ) * 2'\n","tokens = expression.split()\n","parser = RecursiveDescentParser(tokens)\n","parse_tree = parser.parse()\n","parse_tree"]},{"cell_type":"markdown","metadata":{},"source":["## Parsers Types\n","\n","Parsers search through the space of a variety of trees to find the best tree for the provided text. Let’s have a look at some of the accessible parsers below:\n","1. **Recursive Descent Parser:** a straightforward implementation of top-down parsing, uses a set of recursive functions to process the input. Iteratively breaks down the highest-level grammar rule into subrules is known as a recursive descent parser.\n","\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/RecDesParser.png\" alt=\"Recursive descent parsing\" width=\"800\"/>\n","\n","2. **Shift-Reduce Parser:** sort of bottom-up parser that starts with the input and builds a parse tree by performing a series of shift (transfer data to the stack) and reduction (apply grammar rules) operations. \n","\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/ShiftReduceParser.png\" alt=\"Recursive descent parsing\" width=\"600\"/>\n","\n","3. **RegExp Parser:** (regular expression) parser, is used to match patterns and extract text. It scans a larger text or document for substrings that match a specific regular expression pattern. Using regular expressions to identify substrings that match specific patterns, extracting meaningful units (tokens) from text based on patterns, extracting sub-parts of the matched strings using parentheses. Basic syntax:\n","<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab06/RegExpSyntax.png\" alt=\"Recursive descent parsing\" width=\"600\"/>\n","\n","    - You can find more [here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions/Cheatsheet)\n","\n","Lets observe how the RegExp parser finds email addresses:"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["['support@example.com', 'sales@example.org.']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","\n","# Example text\n","text = \"Please contact us at support@example.com or sales@example.org.\"\n","\n","# Regular expression for matching email addresses\n","email_pattern = r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+'\n","\n","# Find all email addresses\n","emails = re.findall(email_pattern, text)\n","\n","emails"]},{"cell_type":"markdown","metadata":{},"source":["### Task 3.\n","Write a Shift-Reduce parser for mathematical expressions in 'function' format. Here we suggest to apply expressions only with '*' and '+' signs but you can add subtraction, division, or parentheses. For optional operands you have to assign `i_added_subtraction_and_division` variable as True for th correct check. For following the mathematical rules (to take into account the priority of the operators) create the dictionary with priorities and 2 stacks: 1 is for operands and another is for operators.\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def shift_reduce_parser(expression: str):\n","    \"\"\" Fuction for parsing mathematical expressions\n","\n","    Args:\n","        expression (str): text representation of an expression\n","\n","    Returns:\n","        int: the result of expression\n","    \"\"\"\n","    tokens = expression.split()\n","    operand_stack = []\n","    operator_stack = []\n","    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n","\n","    def apply_operator():\n","        \"\"\" Inner function for computing expressions.\n","        Here you need to check if there are 2 or more operands in the stack, \n","        1 or more operators, extract them and compute the result \"\"\"\n","        if len(operand_stack) < 2 or not operator_stack:\n","            return\n","        b = operand_stack.pop()\n","        a = operand_stack.pop()\n","        op = operator_stack.pop()\n","        if op == '+':\n","            operand_stack.append(a + b)\n","        if op == '-':\n","            operand_stack.append(a - b)\n","        elif op == '*':\n","            operand_stack.append(a * b)\n","        elif op == '/':\n","            operand_stack.append(a / b)\n","\n","    for token in tokens:\n","        \"\"\" Here you need to iterate through the tokens, \n","        add them into corresponding stacks,\n","        or perform the operations using apply_operator().\n","        Don't forget about operators' priority.\n","        \"\"\"\n","        if token.isdigit():\n","            operand_stack.append(int(token))\n","        elif token in precedence:\n","            # handle the operators' priority\n","            while (operator_stack and precedence[operator_stack[-1]] >= precedence[token]):\n","                apply_operator()\n","            operator_stack.append(token)\n","\n","    while operator_stack:\n","        apply_operator()\n","\n","    return operand_stack[0] if operand_stack else None\n","\n","\n","# Test the function with expressions\n","expression1 = \"6 + 10 * 6\"\n","expression2 = \"2 * 3 + 15\"\n","\n","i_added_subtraction_and_division = True\n","expression3 = \"6 / 2 + 5 * 4 - 8\"\n","\n","result1 = shift_reduce_parser(expression1)\n","result2 = shift_reduce_parser(expression2) \n","\n","assert result1 == 66, 'Test case 1 is failed'\n","assert result2 == 21, 'Test case 1 is failed'\n","\n","if i_added_subtraction_and_division:\n","    result3 = shift_reduce_parser(expression3)\n","    assert result3 == 15, 'Optional test case3 is failed'\n"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","\n","In this lesson, we delved deeper into aspects of parsing in Natural Language Processing, exploring its various types, techniques, and practical applications. Parsing is a critical process in NLP that involves analyzing the syntactic structure of sentences to understand their grammatical organization and meaning.\n","\n","- **Syntactic Parsing:** focuses on the grammatical structure of sentences, producing parse trees that represent syntactic constructs. Semantic Parsing: goes beyond syntax to understand the meaning of sentences by converting them into logical forms or structured data.\n","- **Syntax Trees:** Constituency Parse Trees represent the hierarchical structure of sentences, breaking them down into nested constituents (phrases). Dependency Parse Trees represent the grammatical relationships between words in a sentence, showing dependencies directly between head words and their dependents.\n","- **Dependency Parsing and Constituency Parsing**\n","- **Parsing Techniques:** Top-Down Parsing begins with the start symbol and breaks down the rules to match the input sentence from the root to the leaves. Bottom-Up Parsing begins with the input tokens and builds up to the start symbol by combining tokens according to grammar rules.\n","- **Types of Parsers:** Regexp Parsers use regular expressions to match patterns in text, useful for simple pattern matching and text extraction tasks. Recursive Descent Parsers - top-down parsers that use a set of recursive functions to process the input, providing an intuitive but potentially inefficient approach. Shift-Reduce Parsers - type of bottom-up parsers that build the parse tree incrementally by shifting tokens onto a stack and reducing them using grammar rules, offering a systematic and efficient approach.\n","\n","Parsing is a powerful tool that enables deeper understanding and processing of natural language, forming the backbone of many advanced NLP applications."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7773684,"sourceId":71118,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
