{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b39da1bf-2807-4522-86ff-e580a9f6d566",
      "metadata": {
        "id": "b39da1bf-2807-4522-86ff-e580a9f6d566"
      },
      "source": [
        "# Natural Language Processing. Lesson 3. POS tagging and Parsing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0936b5",
      "metadata": {
        "id": "1d0936b5"
      },
      "source": [
        "In this lesson, we are going to dive into the deeper layers of text using two fundamental techniques: Part-of-Speech (POS) tagging and Named Entity Recognition (NER).\n",
        "\n",
        "The picture explains the whole process:\n",
        "\n",
        "![Preprocessing](https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab03/preprocessing.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9c4445-a7e8-4958-b6e9-ffa50d6225ad",
      "metadata": {
        "id": "9a9c4445-a7e8-4958-b6e9-ffa50d6225ad"
      },
      "source": [
        "## POS tagging\n",
        "\n",
        "One of the core tasks in NNLP is Parts-of-Speech (PoS) tagging, which is giving each word in a text a grammatical category, such as nouns, verbs, adjectives, and adverbs. Through improved comprehension of phrase structure and semantics, this technique makes it possible for machines to study and comprehend human language more accurately. There are corresponding abbreviations to each category: nouns - **NN**, verbs - **VB**, adjectives - **JJ**, adverbs - **RB**, pronouns - **PRP**, prepositions - **IN**, conjunctions - **CC**, **DT** - determiner.\n",
        "\n",
        "![Preprocessing](https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab03/POS-Tagging-800x400.jpg)\n",
        "\n",
        "For labels assignment we will use special models (tagsets, averaged_perceptron_tagger, conll2000) and download them with nltk.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7305f22a-f0e1-457e-92b5-19fd94a44c29",
      "metadata": {
        "id": "7305f22a-f0e1-457e-92b5-19fd94a44c29"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2a405752-436e-4b0d-9895-99fc84072011",
      "metadata": {
        "id": "2a405752-436e-4b0d-9895-99fc84072011"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "# to identify and classify named entities within text, such as people, locations, organizations, dates, etc.\n",
        "nltk.download(\"maxent_ne_chunker\", quiet=True)\n",
        "\n",
        "# to download the NLTK corpus of words, which is a large collection of English words\n",
        "nltk.download(\"words\", quiet=True)\n",
        "\n",
        "# sentence tokenizer model for splitting text\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "# to assign POS tags\n",
        "nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
        "\n",
        "# tagset definitions (NN, VB, etc)\n",
        "nltk.download(\"tagsets\", quiet=True)\n",
        "\n",
        "# collection of text data annotated with POS tags and potentially NER information\n",
        "nltk.download(\"conll2000\", quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eed883f2-0968-4e2a-9d2e-693138e36da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eed883f2-0968-4e2a-9d2e-693138e36da1",
        "outputId": "35fdb363-a2db-418d-93fc-cac15e59c6db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('allow', 'VB'),\n",
              " ('us', 'PRP'),\n",
              " ('to', 'TO'),\n",
              " ('add', 'VB'),\n",
              " ('lines', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('list', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('allow', 'JJ'),\n",
              " ('actions', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# split the text into word tokens and assign labels\n",
        "sentence = word_tokenize(\"allow us to add lines in list of allow actions\")\n",
        "nltk.pos_tag(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a70d0e29",
      "metadata": {
        "id": "a70d0e29"
      },
      "source": [
        "#### Task 1.\n",
        "Fill the gaps. Do not forget to apply lowercase to the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a6a9cda9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6a9cda9",
        "outputId": "8dffba13-3b3c-4288-d9fb-9d55251f322b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 'DT'), ('documentary', 'NN'), ('explored', 'VBD'), ('the', 'DT'), ('fascinating', 'JJ'), ('world', 'NN'), ('of', 'IN'), ('deep-sea', 'NN'), ('creatures', 'NNS')]\n"
          ]
        }
      ],
      "source": [
        "text = 'The documentary explored the fascinating world of deep-sea creatures'\n",
        "\n",
        "# split the text and assign POS tags\n",
        "sentence = word_tokenize(text.lower())\n",
        "words_with_tags = nltk.pos_tag(sentence)\n",
        "\n",
        "print(words_with_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "700ce70a",
      "metadata": {
        "id": "700ce70a"
      },
      "outputs": [],
      "source": [
        "assert len(words_with_tags[0]) == 2\n",
        "assert len(words_with_tags) == 9\n",
        "assert words_with_tags[1][1] == 'NN'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c554e409-db52-4ffd-b2c5-08b29cb16baa",
      "metadata": {
        "id": "c554e409-db52-4ffd-b2c5-08b29cb16baa"
      },
      "source": [
        "## Shallow Parsing or Chunking\n",
        "\n",
        "A process of extracting phrases from _unstructured_ text. Chunking groups adjacent tokens into phrases on the basis of their POS tags, extracts meaningful phrases or chunks from text. There are some standard well-known chunks such as noun phrases, verb phrases, and prepositional phrases.\n",
        "\n",
        "There are 5 major categories of phrases :\n",
        "\n",
        "- Noun phrase (NP) - noun+determiner+adjective: \"The quick brown fox\" (determiner + adjective + noun), \"A delicious cake\" (determiner + adjective + noun)\n",
        "- Adjective phrase (ADJP) - 1 or more adjectives: \"Very interesting\" (modifies the adjective \"interesting\"), \"Incredibly beautiful flowers\" (modifies the noun \"flowers\")\n",
        "- Verb phrase (VP) - verb + modal verbs/adverbs/nouns: \"Jumps over the fence\" (verb + prepositional phrase), \"Will sing a song\" (helping verb + verb + direct object)\n",
        "- Prepositional phrase (PP) - preposition+object: \"On the table\" (preposition + noun phrase), \"With great enthusiasm\" (preposition + adverb phrase)\n",
        "- Adverb phrase (ADVP) - adverbs + additional modifiers: \"Very quickly\" (modifies the adverb \"quickly\"), \"Ran across the street\" (modifies the verb \"ran\")\n",
        "\n",
        "Chunks consist of tokens and their tags:\n",
        "\n",
        "![Chunking](https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab03/chunk.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "38974f19-5d65-4535-92bd-d9f0d0fe51fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38974f19-5d65-4535-92bd-d9f0d0fe51fc",
        "outputId": "1f52a7f6-b9cc-4dd4-dd78-5424aaae82bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  Chancellor/NNP\n",
            "  (PP of/IN)\n",
            "  (NP the/DT Exchequer/NNP)\n",
            "  (NP Nigel/NNP Lawson/NNP)\n",
            "  (NP 's/POS restated/VBN commitment/NN)\n",
            "  (PP to/TO)\n",
            "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
            "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
            "  (NP a/DT freefall/NN)\n",
            "  (PP in/IN)\n",
            "  (NP sterling/NN)\n",
            "  (PP over/IN)\n",
            "  (NP the/DT past/JJ week/NN)\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "# import the dataset for dividing text into syntactically related non-overlapping groups of words\n",
        "from nltk.corpus import conll2000\n",
        "\n",
        "data = conll2000.chunked_sents()\n",
        "print(data[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d824f856",
      "metadata": {
        "id": "d824f856"
      },
      "source": [
        "The method conll2000.chunked_sents() retrieves all sentences from the corpus (large collection of text data) where each word is represented as a tuple containing the word itself and its POS tag, along with the sentence being further divided into phrase chunks. These chunks are represented as nested structures (trees) indicating the groupings of words based on their grammatical roles.\n",
        "\n",
        "The sentence was: Chancellor of the Exchequer Nigel Lawson's restated commitment to a firm monetary policy has helped to prevent a freefall in sterling over the past week.\n",
        "\n",
        "(S ... ) indicates the entire sentence itself. POS tags (word/tag): Chancellor/NNP where NNP - proper noun, commitment/NN where NN - noun. Chunking: the sentence is further divided into nested structures (chunks) based on the grammatical relationship of the words. (PP of/IN)represents a prepositional phrase (PP) with \"of\" as the preposition, (NP the/DT Exchequer/NNP) represents a noun phrase (NP) with \"the\" (determiner) and \"Exchequer\" (proper noun).\n",
        "\n",
        "![Chunking](https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab03/shallow.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a84ac13",
      "metadata": {
        "id": "3a84ac13"
      },
      "source": [
        "#### Task 2.\n",
        "\n",
        "Fill the gaps. Tokenize the text, assign the tags, and apply the chunking.\n",
        "\n",
        "Hint: use `nltk.RegexParser` module with grammar \"NP: {< DT>? < JJ>* < NN>+}\". You can find more grammars and rules (strip rule and split rule) [here](https://www.nltk.org/howto/chunk.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5fd01f98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fd01f98",
        "outputId": "8f7091f7-e799-456c-ea5c-282d9c8482b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The/DT documentary/NN)\n",
            "  explored/VBD\n",
            "  (NP the/DT fascinating/JJ world/NN)\n",
            "  of/IN\n",
            "  (NP deep-sea/NN)\n",
            "  creatures/NNS)\n"
          ]
        }
      ],
      "source": [
        "text = 'The documentary explored the fascinating world of deep-sea creatures'\n",
        "\n",
        "# tokenize and assign tags\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "# the grammar (pattern) that will be extracted as a chunk\n",
        "grammar = r\"NP: {<DT>? <JJ>* <NN>+}\"\n",
        "\n",
        "# create an instance of parser and use it\n",
        "parser = nltk.RegexpParser(grammar)\n",
        "chunks = parser.parse(tagged)\n",
        "\n",
        "print(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "569ebe26",
      "metadata": {
        "id": "569ebe26"
      },
      "outputs": [],
      "source": [
        "from nltk import Tree\n",
        "assert chunks[2:3] == [Tree('NP', [('the', 'DT'), ('fascinating', 'JJ'), ('world', 'NN')])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13dc2a2d-386f-49d0-be28-56930170ab30",
      "metadata": {
        "id": "13dc2a2d-386f-49d0-be28-56930170ab30"
      },
      "source": [
        "## 3. Constituency Parsing\n",
        "\n",
        "Constituent-based grammars are used to analyze and determine the constituents of a sentence. These grammars can be used to model or represent the internal structure of sentences in terms of a _hierarchically_ ordered structure of their constituents. A constituency parser can be built based on such grammars/rules. **The grammar has to be defined.**\n",
        "\n",
        "One of the popular Constituency Parsing implementation is from stanford. A **probabilistic context-free grammar parser**\n",
        "\n",
        "Tag information can be found [here](https://web.archive.org/web/20130517134339/http://bulba.sdsu.edu/jeanette/thesis/PennTags.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6ae149dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae149dc",
        "outputId": "37b9062b-918e-4fe9-e541-742c8613f8a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting benepar\n",
            "  Downloading benepar-0.2.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.10/dist-packages (from benepar) (3.8.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.10/dist-packages (from benepar) (3.7.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from benepar) (2.3.0+cu121)\n",
            "Collecting torch-struct>=0.5 (from benepar)\n",
            "  Downloading torch_struct-0.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.10/dist-packages (from benepar) (0.19.1)\n",
            "Requirement already satisfied: transformers[tokenizers,torch]>=4.2.2 in /usr/local/lib/python3.10/dist-packages (from benepar) (4.41.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from benepar) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from benepar) (0.1.99)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2->benepar) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2->benepar) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2->benepar) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2->benepar) (4.66.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (0.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.0.9->benepar) (1.25.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.9.4->benepar) (0.23.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->benepar) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->benepar) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->benepar) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->benepar) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->benepar) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->benepar)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->benepar) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->benepar)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (0.4.3)\n",
            "Collecting accelerate>=0.21.0 (from transformers[tokenizers,torch]>=4.2.2->benepar)\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[tokenizers,torch]>=4.2.2->benepar) (5.9.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.9->benepar) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.0.9->benepar) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.0.9->benepar) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.0.9->benepar) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->benepar) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.9->benepar) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.9->benepar) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.9->benepar) (0.1.2)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.2.0-py3-none-any.whl size=37625 sha256=4cec4fc12488d1c35c80aa4cf01ee27db4ee18f4a8fd1668677d876712cc63cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/4d/c1/a5af726368d5dbaaaa0b2dd36ed39b9da8cec46279a49bd6db\n",
            "Successfully built benepar\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-struct, accelerate, benepar\n",
            "Successfully installed accelerate-0.31.0 benepar-0.2.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-struct-0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install benepar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9433daf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9433daf3",
        "outputId": "1d07b393-506c-41dc-8f08-63718f08f82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md\n",
        "# In colab ⚠ Restart to reload dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "96dada19-fd47-400e-9fea-e543d96ae6b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96dada19-fd47-400e-9fea-e543d96ae6b1",
        "outputId": "86556524-6e79-4ca8-f953-d5bef61c376e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "import benepar, spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "benepar.download('benepar_en3')\n",
        "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
        "doc = nlp('The time for action is now. It is never too late to do something.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a8e2f789-2981-4ed0-a00b-98425f31d107",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8e2f789-2981-4ed0-a00b-98425f31d107",
        "outputId": "3ae5d8d4-0b2c-4634-9456-27ef895fd0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP (NP (DT The) (NN time)) (PP (IN for) (NP (NN action)))) (VP (VBZ is) (ADVP (RB now))) (. .))\n",
            "('S',)\n",
            "The time for action\n"
          ]
        }
      ],
      "source": [
        "sent = list(doc.sents)[0]\n",
        "\n",
        "print(sent._.parse_string)\n",
        "# (S (NP (NP (DT The) (NN time)) (PP (IN for) (NP (NN action)))) (VP (VBZ is) (ADVP (RB now))) (. .))\n",
        "\n",
        "print(sent._.labels)\n",
        "# ('S',)\n",
        "print(list(sent._.children)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2a79d5a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a79d5a4",
        "outputId": "febca56c-0195-4d34-e562-edf6d404d234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP (DT The) (NN cat)) (VP (VBD sat) (PP (IN on) (NP (DT the) (NN mat)))) (. .))\n"
          ]
        }
      ],
      "source": [
        "sentence = \"The cat sat on the mat.\"\n",
        "doc = nlp(sentence)\n",
        "sent = list(doc.sents)[0]\n",
        "print(sent._.parse_string)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a48659fc",
      "metadata": {
        "id": "a48659fc"
      },
      "source": [
        "#### Task 3.\n",
        "\n",
        "Fill the gaps. Use the parser from the previous task (RegexpParser) and display the hierarchical structure."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqsH2shAzatS",
        "outputId": "91e92206-fea4-4099-85a3-2c566f691930"
      },
      "id": "aqsH2shAzatS",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting svgling\n",
            "  Downloading svgling-0.4.0-py3-none-any.whl (23 kB)\n",
            "Collecting svgwrite (from svgling)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.4.0 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "aed6fd4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "aed6fd4b",
        "outputId": "49bbccca-a86b-4430-b98c-3f5b88d24873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [('last', 'JJ'), ('night', 'NN')]), Tree('NP', [('i', 'NN')]), ('saw', 'VBD'), Tree('NP', [('a', 'DT'), ('black', 'JJ'), ('dog', 'NN')]), Tree('NP', [('barking', 'NN')]), ('at', 'IN'), Tree('NP', [('a', 'DT'), ('kid', 'NN')])])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,480.0,168.0\" width=\"480px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"21.6667%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"46.1538%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">last</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.0769%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"53.8462%\" x=\"46.1538%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">night</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.0769%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.8333%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.66667%\" x=\"21.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">i</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.33333%\" x=\"28.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">saw</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.5%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"26.6667%\" x=\"36.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.5%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"43.75%\" x=\"25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">black</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.875%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"31.25%\" x=\"68.75%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dog</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.375%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"15%\" x=\"63.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">barking</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.66667%\" x=\"78.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">at</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.6667%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"15%\" x=\"85%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"44.4444%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.2222%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"55.5556%\" x=\"44.4444%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">kid</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.2222%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.5%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# define the grammar (noun phrase)\n",
        "grammar = (\"NP: {<DT>?<JJ>*<NN>}\")\n",
        "\n",
        "sent = \"last night i saw a black dog barking at a kid\"\n",
        "\n",
        "tokens = nltk.word_tokenize(sent)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "# parse the text\n",
        "parser = nltk.RegexpParser(grammar)\n",
        "tree = parser.parse(tagged)\n",
        "tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "726fe8da",
      "metadata": {
        "id": "726fe8da"
      },
      "outputs": [],
      "source": [
        "assert len(tree) == 7\n",
        "assert tree[3:4] == [Tree('NP', [('a', 'DT'), ('black', 'JJ'), ('dog', 'NN')])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ef574e0-55eb-441f-8853-8e80defc843b",
      "metadata": {
        "id": "7ef574e0-55eb-441f-8853-8e80defc843b"
      },
      "source": [
        "## Dependency Parsing\n",
        "\n",
        "In dependency parsing, we try to use dependency-based grammars to analyze and infer both structure and semantic dependencies and relationships between tokens in a sentence. It focuses on identifying the relationships between words within a sentence and how they depend on each other to convey meaning.\n",
        "\n",
        "![](https://files.realpython.com/media/displacy_dependency_parse.de72f9b1d115.png)\n",
        "\n",
        "Dependency Parsing is used in shallow parsing and named entity recognition.\n",
        "\n",
        "What it Does:\n",
        "\n",
        "- Dependency parsing breaks down a sentence into its constituent parts (words) and analyzes the grammatical relationships between them.\n",
        "- It creates a dependency tree or dependency graph that visually represents these relationships.\n",
        "- Unlike constituency parsing that focuses on phrases and clauses, dependency parsing concentrates on the relationships between individual words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0fef8ba2-d943-4d80-93c2-c0818b7e1ce5",
      "metadata": {
        "id": "0fef8ba2-d943-4d80-93c2-c0818b7e1ce5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6b36c19f-4fe3-457f-b5ec-958cc1f4f8f6",
      "metadata": {
        "id": "6b36c19f-4fe3-457f-b5ec-958cc1f4f8f6"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# download the pipeline\n",
        "text_processing_pipeline = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# process the sentence\n",
        "processed_sentence = text_processing_pipeline(\n",
        "    \"Innopolis University is a university located in the city of Innopolis.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a5e02165-05e6-4482-b750-0eb5d7372c2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "a5e02165-05e6-4482-b750-0eb5d7372c2c",
        "outputId": "6d4fc47c-6125-413c-bf8d-89668b5e5e35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"71534b68a31c45b791e998b2bf001584-0\" class=\"displacy\" width=\"1260\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Innopolis</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">University</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">university</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">located</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">city</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">Innopolis.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L64,104.0 76,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-1\" stroke-width=\"2px\" d=\"M180,112.0 C180,57.0 265.0,57.0 265.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,114.0 L174,104.0 186,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-2\" stroke-width=\"2px\" d=\"M400,112.0 C400,57.0 485.0,57.0 485.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,114.0 L394,104.0 406,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-3\" stroke-width=\"2px\" d=\"M290,112.0 C290,2.0 490.0,2.0 490.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M490.0,114.0 L496.0,104.0 484.0,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-4\" stroke-width=\"2px\" d=\"M510,112.0 C510,57.0 595.0,57.0 595.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595.0,114.0 L601.0,104.0 589.0,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-5\" stroke-width=\"2px\" d=\"M620,112.0 C620,57.0 705.0,57.0 705.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M705.0,114.0 L711.0,104.0 699.0,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-6\" stroke-width=\"2px\" d=\"M840,112.0 C840,57.0 925.0,57.0 925.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M840,114.0 L834,104.0 846,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-7\" stroke-width=\"2px\" d=\"M730,112.0 C730,2.0 930.0,2.0 930.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M930.0,114.0 L936.0,104.0 924.0,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-8\" stroke-width=\"2px\" d=\"M950,112.0 C950,57.0 1035.0,57.0 1035.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1035.0,114.0 L1041.0,104.0 1029.0,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-71534b68a31c45b791e998b2bf001584-0-9\" stroke-width=\"2px\" d=\"M1060,112.0 C1060,57.0 1145.0,57.0 1145.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-71534b68a31c45b791e998b2bf001584-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1145.0,114.0 L1151.0,104.0 1139.0,104.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(\n",
        "    processed_sentence,\n",
        "    jupyter=True,\n",
        "    options={\"distance\": 110, \"arrow_stroke\": 2, \"arrow_width\": 8},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "965dac1a",
      "metadata": {
        "id": "965dac1a"
      },
      "source": [
        "#### Task 4.\n",
        "Fill the gaps. Lets try the French language. Load it using spacy.load() with the parameter 'fr_core_news_sm'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "20a3214a",
      "metadata": {
        "id": "20a3214a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "78326047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78326047",
        "outputId": "fd0dc2de-9a23-4b0a-e91c-1a4084c0a498"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Le super chef test le menu fixe pour le web."
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# download the pipeline with a new language\n",
        "pipeline = spacy.load(\"fr_core_news_sm\")\n",
        "sentence = \"Le super chef test le menu fixe pour le web.\"\n",
        "\n",
        "# process the sentence\n",
        "processed_sentence = pipeline(sentence)\n",
        "processed_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f8546dbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "f8546dbb",
        "outputId": "52f66a57-8b4c-407f-eb04-4523937a57be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"1fe87d3504b3425cbe8657eca24eac70-0\" class=\"displacy\" width=\"1150\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Le</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">super</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">chef</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">test</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">le</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">menu</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">fixe</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">pour</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">le</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">web.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L65,160.0 75,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-1\" stroke-width=\"2px\" d=\"M180,167.0 C180,57.0 375.0,57.0 375.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L175,160.0 185,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-2\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L285,160.0 295,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-3\" stroke-width=\"2px\" d=\"M510,167.0 C510,112.0 590.0,112.0 590.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M510,169.0 L505,160.0 515,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-4\" stroke-width=\"2px\" d=\"M400,167.0 C400,57.0 595.0,57.0 595.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595.0,169.0 L600.0,160.0 590.0,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-5\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M700.0,169.0 L705.0,160.0 695.0,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,57.0 1035.0,57.0 1035.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L835,160.0 845,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-7\" stroke-width=\"2px\" d=\"M950,167.0 C950,112.0 1030.0,112.0 1030.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M950,169.0 L945,160.0 955,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1fe87d3504b3425cbe8657eca24eac70-0-8\" stroke-width=\"2px\" d=\"M400,167.0 C400,2.0 1040.0,2.0 1040.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1fe87d3504b3425cbe8657eca24eac70-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1040.0,169.0 L1045.0,160.0 1035.0,160.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "# display the dependency\n",
        "displacy.render(\n",
        "    processed_sentence,\n",
        "    jupyter=True,\n",
        "    options={\"distance\": 110, \"arrow_stroke\": 2, \"arrow_width\": 7},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "29b83150",
      "metadata": {
        "id": "29b83150"
      },
      "outputs": [],
      "source": [
        "assert len(processed_sentence[1]) == 5\n",
        "assert (processed_sentence[1].pos_) == 'NOUN'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf688188-2ee3-46c2-ba55-5a5b2377978a",
      "metadata": {
        "id": "bf688188-2ee3-46c2-ba55-5a5b2377978a"
      },
      "source": [
        "## 5. Named Entity Recognition\n",
        "\n",
        "Named Entity Recognition (NER) is the process of locating named entities in unstructured text and then classifying them into pre-defined categories, such as person names, organizations, locations, monetary values, percentages, time expressions, and so on.\n",
        "\n",
        "Application:\n",
        "- Information extraction: NER helps extract structured information from unstructured text, making it easier to process and analyze large amounts of data\n",
        "- Machine translation: NER improves the accuracy of machine translation by identifying and translating named entities correctly, preserving context and _meaning_\n",
        "\n",
        "Common named entity types: person, location, time, date, product, money, percent, quantity, work_of_art, event, facility, gpe, ordinal, cardinal, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c6055f26-0b73-497c-a2ed-57b665da756a",
      "metadata": {
        "id": "c6055f26-0b73-497c-a2ed-57b665da756a"
      },
      "outputs": [],
      "source": [
        "sentence = \"European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c060bf-979f-4800-ae80-7ee311e6484e",
      "metadata": {
        "id": "f2c060bf-979f-4800-ae80-7ee311e6484e"
      },
      "source": [
        "#### NER with spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c2bebd6e-f29c-4b2e-be4f-da621a174153",
      "metadata": {
        "id": "c2bebd6e-f29c-4b2e-be4f-da621a174153"
      },
      "outputs": [],
      "source": [
        "import en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "358424b8-7c78-4e93-9858-6b738f4aa440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "358424b8-7c78-4e93-9858-6b738f4aa440",
        "outputId": "d8870997-4da9-441e-a714-594157b542c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('European', 'NORP'), ('Google', 'ORG'), ('$5.1 billion', 'MONEY'), ('Wednesday', 'DATE')]\n"
          ]
        }
      ],
      "source": [
        "# download the pipeline\n",
        "text_processing_pipeline = en_core_web_sm.load()\n",
        "\n",
        "# parse the text\n",
        "doc = text_processing_pipeline(sentence)\n",
        "\n",
        "# check the results\n",
        "print([(X.text, X.label_) for X in doc.ents])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3b9f2c87-647f-4807-8dcb-89df12b5d034",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3b9f2c87-647f-4807-8dcb-89df12b5d034",
        "outputId": "ca741c89-990e-47d4-8273-c48623595d82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    European\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " authorities fined \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " a record \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $5.1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Wednesday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " for abusing its power in the mobile phone market and ordered the company to alter its practices</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b7a7b9f",
      "metadata": {
        "id": "6b7a7b9f"
      },
      "source": [
        "#### Task 5.\n",
        "\n",
        "Fill the gaps. There are some predefined labels: person(per), nationalities, religious or political groups(norp), facility(fac), organization(org), location(loc), etc. Let's try to use NER to extract as much labels as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8d196cc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d196cc9",
        "outputId": "4ef79b73-17df-4514-8fa2-3e8b3e2df699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Yesterday', 'DATE'), ('Barack Obama', 'PERSON'), ('the Democratic Party', 'ORG'), ('the Eiffel Tower', 'FAC'), ('Paris', 'GPE'), ('France', 'GPE'), ('Angela Merkel', 'PERSON'), ('Germany', 'GPE'), ('$10 billion', 'MONEY'), ('2030', 'DATE'), ('the New York Times', 'ORG'), ('BBC', 'ORG'), ('French', 'NORP'), ('Montmartre', 'GPE'), ('Parisian', 'NORP')]\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "\n",
        "sentence = 'Yesterday, President Barack Obama, leader of the Democratic Party, visited the Eiffel Tower in Paris, \\\n",
        "France.  While there, he spoke about the importance of international cooperation on climate change and announced a \\\n",
        "new initiative with Chancellor Angela Merkel of Germany to invest $10 billion in renewable energy research by 2030. \\\n",
        "Reporters from all over the world were present, including journalists from the New York Times and BBC. The President \\\n",
        "then enjoyed a traditional French dinner at a quaint restaurant in Montmartre, a famous Parisian neighborhood known for \\\n",
        "its art scene.'\n",
        "\n",
        "pipeline = en_core_web_sm.load()\n",
        "doc = pipeline(sentence)\n",
        "print([(X.text, X.label_) for X in doc.ents])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "77e1e9a4",
      "metadata": {
        "id": "77e1e9a4"
      },
      "outputs": [],
      "source": [
        "assert len(doc.ents) == 15"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347903f3-cde2-40ba-9ca0-e62fdc4858a6",
      "metadata": {
        "id": "347903f3-cde2-40ba-9ca0-e62fdc4858a6"
      },
      "source": [
        "## Task\n",
        "\n",
        "[Competition](https://www.kaggle.com/t/9e6b9b00b0094375a888823b8ecf78d7)\n",
        "\n",
        "Your goal is to perform NER on recipe ingridients. For more details go to the competition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7ad77f5",
      "metadata": {
        "id": "c7ad77f5"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "999891e8",
      "metadata": {
        "id": "999891e8"
      },
      "source": [
        "Text analysis is a crucial aspect of Natural Language Processing (NLP), and various techniques exist to extract meaning from written language. This exploration has examined several key approaches: Part-of-Speech (POS) tagging, Named Entity Recognition (NER), shallow parsing (including constituency parsing), and dependency parsing.\n",
        "\n",
        "- POS tagging lays the foundation by identifying the grammatical function of each word (e.g., noun, verb, adjective). NER goes a step further by recognizing and classifying named entities within the text, providing valuable insights into people, locations, organizations, and other relevant entities.\n",
        "\n",
        "- Shallow parsing techniques, like constituency parsing, delve deeper into sentence structure by identifying phrases and clauses. This helps understand how words group together to form larger syntactic units. Dependency parsing, on the other hand, focuses on the direct relationships between individual words in a sentence, providing a more granular view of the grammatical structure.\n",
        "\n",
        "- Choosing the appropriate technique depends on the specific NLP task. POS tagging and NER are foundational for many tasks, while shallow parsing and dependency parsing offer deeper syntactic analysis for tasks like machine translation, question answering, and sentiment analysis.\n",
        "\n",
        "By understanding these techniques and their applications, we can unlock the power of text analysis and leverage its capabilities in various NLP applications."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUS8oqaNzlHP"
      },
      "id": "VUS8oqaNzlHP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}