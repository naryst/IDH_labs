{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2316fb23",
      "metadata": {
        "id": "2316fb23",
        "papermill": {
          "duration": 0.011951,
          "end_time": "2024-02-28T16:34:49.288717",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.276766",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# NLP. Lesson 7. Embeddings\n",
        "\n",
        "**Embedding** - is an important term that is used for **representing words for text analysis in the form of real-valued vectors**. It is considered one of the most significant breakthroughs of deep learning for solving challenging natural language processing problems.\n",
        "\n",
        "In this approach, words and documents are represented in the form of numeric vectors allowing similar words to have similar vector representations. The extracted features are fed into a machine learning model so as to work with text data and preserve the semantic and syntactic information. It can approximate meaning and represent a word in a lower dimensional space. For instance, a word embedding with 50 values holds the capability of representing 50 unique features. Many people choose pre-trained word embedding models like Flair, fastText, SpaCy, and others.\n",
        "\n",
        "Word embedding techniques:\n",
        "- Word2Vec(CBOW and Skip-gram)\n",
        "- fastText\n",
        "- GloVe (Global Vectors for Word Representation)\n",
        "- BERT (Bidirectional Encoder Representations from Transformers), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27145122",
      "metadata": {
        "id": "27145122",
        "papermill": {
          "duration": 0.01216,
          "end_time": "2024-02-28T16:34:49.312782",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.300622",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Distributional semantics\n",
        "\n",
        "Distributional semantics is a theory in linguistics and natural language processing that posits that the meaning of words can be inferred from the contexts in which they appear. According to this theory, words that occur in similar contexts are likely to have similar meanings: \"a word is characterized by the company it keeps\".\n",
        "\n",
        "The distributional hypothesis suggests that the more semantically similar two words are, the more distributionally similar they will be in turn, and thus the more that they will tend to occur in similar linguistic contexts.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/DistributionalSemantics.png\" alt=\"Distributional Semantics\" width=\"400\"/>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/relationship.png\" alt=\"Distributional Semantics\" width=\"587\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "905171f0",
      "metadata": {
        "id": "905171f0",
        "papermill": {
          "duration": 0.011878,
          "end_time": "2024-02-28T16:34:49.336587",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.324709",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Models for computing word representations. Word2Vec algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b0ed47",
      "metadata": {
        "id": "12b0ed47"
      },
      "source": [
        "The main idea of Word2Vec is that we need to put information about meanings into word vectors. But how? Learn word vectors by teaching them to predict contexts. As you remember from the distributional hypothesis, if vectors \"know\" about contexts, they \"know\" word meaning. Word2Vec is an iterative method. Its main idea is as follows:\n",
        "\n",
        "- take a huge text corpus\n",
        "- go over the text with a sliding window, moving one word at a time. At each step, there is a central word and context words (other words in this window)\n",
        "- for the central word, compute probabilities of context words\n",
        "- adjust the vectors to increase these probabilities.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/DistrSem1.png\" alt=\"Distributional Semantics\" width=\"600\"/>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/DistrSem2.png\" alt=\"Distributional Semantics\" width=\"600\"/>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/DistrSem3.png\" alt=\"Distributional Semantics\" width=\"600\"/>\n",
        "\n",
        "For each position in a text corpus Word2Vec predicts context within an m-sized window given a central word $w_t$\n",
        "\n",
        "**Likelihood:** $L(\\theta) = \\prod_{t=1}^{T} \\prod_{-m<=j<=m, j!=0>}P(w_{t+j}|w_t, \\theta)$, where $\\theta$ are all variables to be optimized\n",
        "\n",
        "**Objective function: Average Negative Log-Likelihood:** $J(\\theta) =$ $-{1}\\over{T}$ $log L(\\theta) =$ ${-1}\\over{T}$ $\\sum_{t=1}^{T}\\sum_{-m<=j<=m, j!=0} logP(w_{t+j}|w_t, \\theta)$\n",
        "\n",
        "$P(w_{t+j}|w_t, \\theta)$: for each word we have 2 vectors: $v_w$ - central word - and $u_w$ - context word. Then for the central word(c) and context word (o) probability of the context word is: $P(o|c) = \\frac{exp(u_o^T*v_c)}{\\sum_{w∈V}exp(u_w^T*v_c)}$ (based on the softmax function!)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/prob1.png\" alt=\"Probability computation\" width=\"600\"/>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/prob2.png\" alt=\"Probability computation\" width=\"600\"/>\n",
        "\n",
        "**Training:** $\\theta^{new} = \\theta^{old} - \\alpha ∇_{\\theta}J(\\theta)$ - gradient descent. Update 1 word at a time - each update is for a single pair of a center word and one of its context words.\n",
        "\n",
        "Lets consider a sentence from teh pictures: I saw a cute gray cat playing in the garden. Choose a word 'cat' and a context window of size 2: 'cute gray playing in' - context words.\n",
        "\n",
        "Loss: $J_{t,j}(\\theta) = -logP(cute|cat) = -log \\frac{exp(u_{cute}^T*v_{cat})}{\\sum_{w∈V}exp(u_w^T*v_{cat})} = -u_{cute}^T*v_{cat} + log \\sum_{w∈V} exp(u_w^T*v_{cat})$\n",
        "\n",
        "By making an update to minimize $J_{t,j}(\\theta)$, we force the parameters to increase similarity (dot product) of $v_{cat}$ and $u_{cute}$ and, at the same time, to decrease similarity between $v_{cat}$ and $u_{w}$ for all other words $w$ in the vocabulary. But, since we make updates for each context word (and for all central words in your text), on average over all updates our vectors will learn the distribution of the possible contexts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d010dc",
      "metadata": {
        "id": "01d010dc",
        "papermill": {
          "duration": 0.010891,
          "end_time": "2024-02-28T16:34:49.358866",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.347975",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Continuous Bag of Words (CBOW)\n",
        "A bag of words is one of the popular word embedding techniques of text where each value in the vector would represent the count of words in a document/sentence. In other words, it extracts features from the text. We also refer to it as vectorization.\n",
        "\n",
        "In the CBOW model, the goal is to predict a `target word` based on its surrounding context words within a fixed window size. The model takes as input a `context window` (a sequence of surrounding words) and predicts the target word.\n",
        "\n",
        ">Encoding: One Hot Vector - 1 bit '1' and all others are '0'. Vector length - number of words in language. Prediction of a _center_ word from a context window\n",
        "\n",
        "Example: [video](https://www.youtube.com/watch?app=desktop&v=UqRCEmrv1gQ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "152790db",
      "metadata": {
        "id": "152790db",
        "papermill": {
          "duration": 0.011221,
          "end_time": "2024-02-28T16:34:49.381554",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.370333",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Skip-gram\n",
        "\n",
        "In contrast to CBOW, the Skip-gram model aims to predict the `surrounding context` words given a target word. The model takes as input a target word and predicts the context words within a fixed window size around the target word.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b70e1f05",
      "metadata": {
        "id": "b70e1f05",
        "papermill": {
          "duration": 0.010629,
          "end_time": "2024-02-28T16:34:49.403268",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.392639",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Comparison:\n",
        "\n",
        "- CBOW:\n",
        "  - Pros: Faster training time, better performance for frequent words.\n",
        "  - Cons: Poor performance for infrequent words, ignores word order.\n",
        "- Skip-gram:\n",
        "  - Pros: Captures fine-grained semantic information, performs well for infrequent words, preserves word order.\n",
        "  - Cons: Slower training time, requires more data.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/CBOWandSkipGram.png\" alt=\"Comparison\" width=\"600\"/>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/CBOWandSkipGram2.png\" alt=\"Comparison\" width=\"614\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c1adab9",
      "metadata": {
        "id": "3c1adab9",
        "papermill": {
          "duration": 0.011681,
          "end_time": "2024-02-28T16:34:49.447654",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.435973",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Other word embeddings techniques\n",
        "\n",
        "- **fastText Embeddings**: fastText is an extension of word2vec that incorporates subword information into the embedding learning process. While Word2Vec treats eaach word as the smallest entity, fasttext represents words as the sum of the embeddings of their constituent character n-grams, allowing it to handle out-of-vocabulary words and capture morphological information. For the word \"jumping\", the subword n-grams could be [\"jum\", \"ump\", \"mpi\", \"pin\", \"ing\"].\n",
        "\n",
        "\n",
        "- **GloVe (Global Vectors for Word Representation) Embeddings**: GloVe is a word embedding model that learns word vectors by factorizing the co-occurrence matrix of words in a corpus (built from the entire corpus). It leverages global statistical information to capture word semantics and has been shown to perform well on various NLP tasks. The goal is to find word vectors such that their dot product equals the log of the probability of their co-occurrence. Example for the words \"king\", \"queen\", \"man\", and \"woman\": the relationship \"king - man + woman ≈ queen\" can be captured in the vector space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09089b46",
      "metadata": {
        "id": "09089b46",
        "papermill": {
          "duration": 0.01058,
          "end_time": "2024-02-28T16:34:49.469132",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.458552",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## fastText\n",
        "\n",
        "In Word2Vec, an embedding is created for each word. As such, it can’t handle any words it has not encountered during its training. For example, words such as “tensor” and “flow” are present in the vocabulary of Word2Vec. But if you try to get embedding for the compound word “tensorflow”, you will get an out of vocabulary error. For words with same radicals such as “eat” and “eaten”, Word2Vec doesn’t do any parameter sharing. Each word is learned uniquely based on the context it appears in.\n",
        "\n",
        "More about fastText training [here](https://amitness.com/posts/fasttext-embeddings), get familiar with modifications to the skip-gram method in fastText.\n",
        "\n",
        "\n",
        "#### Example of usage of a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ec9bc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-28T16:34:49.493516Z",
          "iopub.status.busy": "2024-02-28T16:34:49.493023Z",
          "iopub.status.idle": "2024-02-28T16:36:37.664847Z",
          "shell.execute_reply": "2024-02-28T16:36:37.663070Z"
        },
        "id": "46ec9bc7",
        "outputId": "398f4ac6-cff8-4a6b-bec6-dc13c3cea94c",
        "papermill": {
          "duration": 115.65747,
          "end_time": "2024-02-28T16:36:45.137686",
          "exception": false,
          "start_time": "2024-02-28T16:34:49.480216",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-09-11 23:03:10--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.79, 18.165.83.91, 18.165.83.35, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz     10%[=>                  ] 465.25M  80.4MB/s    eta 35s    "
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz && gzip -dv cc.en.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1b63dd",
      "metadata": {
        "id": "2e1b63dd"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49aecc92",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:36:45.412269Z",
          "iopub.status.busy": "2024-02-28T16:36:45.411522Z",
          "iopub.status.idle": "2024-02-28T16:36:57.047870Z",
          "shell.execute_reply": "2024-02-28T16:36:57.046489Z"
        },
        "id": "49aecc92",
        "papermill": {
          "duration": 11.845315,
          "end_time": "2024-02-28T16:36:57.051252",
          "exception": false,
          "start_time": "2024-02-28T16:36:45.205937",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.load_model(\"cc.en.300.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf6992a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:36:57.097649Z",
          "iopub.status.busy": "2024-02-28T16:36:57.097228Z",
          "iopub.status.idle": "2024-02-28T16:36:57.104718Z",
          "shell.execute_reply": "2024-02-28T16:36:57.103209Z"
        },
        "id": "1cf6992a",
        "papermill": {
          "duration": 0.034048,
          "end_time": "2024-02-28T16:36:57.107342",
          "exception": false,
          "start_time": "2024-02-28T16:36:57.073294",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "vector = model.get_word_vector(\"hello\")\n",
        "print(vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6a7737",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:36:57.154212Z",
          "iopub.status.busy": "2024-02-28T16:36:57.153781Z",
          "iopub.status.idle": "2024-02-28T16:37:17.853056Z",
          "shell.execute_reply": "2024-02-28T16:37:17.851595Z"
        },
        "id": "3b6a7737",
        "papermill": {
          "duration": 20.7266,
          "end_time": "2024-02-28T16:37:17.855869",
          "exception": false,
          "start_time": "2024-02-28T16:36:57.129269",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "nearest_neighbors = model.get_nearest_neighbors(\"hello\")\n",
        "print(nearest_neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a90fee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:37:17.901271Z",
          "iopub.status.busy": "2024-02-28T16:37:17.900710Z",
          "iopub.status.idle": "2024-02-28T16:37:18.908030Z",
          "shell.execute_reply": "2024-02-28T16:37:18.906496Z"
        },
        "id": "e5a90fee",
        "papermill": {
          "duration": 1.033183,
          "end_time": "2024-02-28T16:37:18.910862",
          "exception": false,
          "start_time": "2024-02-28T16:37:17.877679",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "analogy_result = model.get_analogies(\"king\", \"man\", \"woman\", k=1)\n",
        "print(\"Analogy relationship: king - man + woman =\", analogy_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11aa26c3",
      "metadata": {
        "id": "11aa26c3",
        "papermill": {
          "duration": 0.021546,
          "end_time": "2024-02-28T16:37:18.955143",
          "exception": false,
          "start_time": "2024-02-28T16:37:18.933597",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The analogy relationship is typically explored through vector arithmetic, where the difference between word vectors captures the semantic relationship between words. By using subword information, fastText can generate embeddings for words not seen during training, reducing the problem of OOV (out of vocabulary) words.\n",
        "\n",
        "Similar to Word2Vec, fastText can be trained using either the CBOW or Skip-gram models. The main difference is that the input words are represented by their subword vectors.\n",
        "\n",
        "FastText is highly efficient for text classification tasks, providing state-of-the-art performance with minimal tuning. Example applications include sentiment analysis, spam detection, and topic classification. FastText’s subword approach makes it robust to rare words and those not seen during training.\n",
        "\n",
        "\n",
        "\n",
        "You can train the fasttext by yourself using your own training data. Here is the example of training using skipgram, but you can use 'cbow' as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d7e766",
      "metadata": {
        "id": "d0d7e766"
      },
      "outputs": [],
      "source": [
        "# Get the embedding vector for a word\n",
        "word_vector = model.get_word_vector('hello')\n",
        "print(word_vector)\n",
        "\n",
        "# Find similar words\n",
        "similar_words = model.get_nearest_neighbors('jumping')\n",
        "similar_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9bdfe8",
      "metadata": {
        "id": "6a9bdfe8"
      },
      "source": [
        "### Task 1\n",
        "Find 20 the nearest neighbors for the words \"science\", \"art\", and \"business\". Cluster these nearest neighbors based on their cosine similarity. Explain the result.\n",
        "\n",
        ">Reminder: Cosine Similarity:\n",
        "\n",
        "**Cosine similarity** is a mathematical metric used to measure the similarity between two vectors in a multi-dimensional space, particularly in high-dimensional spaces, by calculating the **cosine of the angle** between them. This measure returns a value between -1 and 1; a value closer to 1 indicates greater similarity.\n",
        "\n",
        "Suppose we have three words: apple, house, and flat. Their corresponding embedding vectors are: [1,5,2], [5,3,4], and [4,2,4]\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/cosine.png\" alt=\"3 Vectors\" width=\"500\"/>\n",
        "\n",
        "Here you can notice that the angle between apple ([1,5,2]) and house ([5,3,4]) is bigger than between flat ([4,2,4]) and house ([5,3,4]) (house and flat cosine is 0.9899). Thus, words, embedded as [5,3,4] and [4,2,4] (house and flat) will be more similar semantically, than words embedded as [5,3,4] and [1,5,2] (house and apple).\n",
        "\n",
        "Why cosine similarity? For example, if two documents have the same words but in different frequencies, Euclidean distance might consider them quite different due to the differences in magnitude (frequency). Cosine similarity, however, would capture their similarity more effectively because it is less sensitive to the frequency of the words and more focused on their presence or absence in the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc349c1",
      "metadata": {
        "id": "1bc349c1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "words = [\"science\", \"art\", \"business\"]\n",
        "results = {}\n",
        "\n",
        "# Retrieve nearest neighbors\n",
        "for word in words:\n",
        "    nearest_neighbors = # YOUR CODE (k = 20)\n",
        "    results[word] = # YOUR CODE\n",
        "\n",
        "# Flatten the list and get embeddings\n",
        "all_words = list(set([word for sublist in results.values() for word in sublist]))\n",
        "word_vectors = # YOUR CODE\n",
        "\n",
        "# Compute similarity matrix\n",
        "similarity_matrix = # YOUR CODE\n",
        "\n",
        "# Perform KMeans clustering\n",
        "kmeans = # YOUR CODE\n",
        "\n",
        "# Map words to their clusters\n",
        "word_to_cluster = # YOUR CODE\n",
        "\n",
        "# Assertions\n",
        "# Check if specific words are in the expected clusters\n",
        "assert word_to_cluster[\"sceince\"] == word_to_cluster[\"science.\"], \"Expected 'biology' and 'science' to be in the same cluster\"\n",
        "assert word_to_cluster[\"artwork\"] == word_to_cluster[\"artworks\"], \"Expected 'painting' and 'art' to be in the same cluster\"\n",
        "\n",
        "# Additional validation can be done manually by examining cluster labels\n",
        "print(\"Cluster assignments:\")\n",
        "for word, cluster in word_to_cluster.items():\n",
        "    print(f\"Word: {word}, Cluster: {cluster}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81e3202",
      "metadata": {
        "id": "c81e3202",
        "papermill": {
          "duration": 0.02173,
          "end_time": "2024-02-28T16:37:18.999229",
          "exception": false,
          "start_time": "2024-02-28T16:37:18.977499",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## GloVe\n",
        "GloVe differs from other methods like Word2Vec by leveraging global word co-occurrence statistics `(matrix)` from a corpus to generate word embeddings.\n",
        "> Each element in this matrix X represents how often word j appears in the context of word i.\n",
        "\n",
        "GloVe's objective is to learn word high-dimensional (50, 100, 200 dimensions) **vectors such that their dot product equals the logarithm of the probability of their co-occurrence**. Similar words are located closer together in this vector space, allowing for semantic relationships to be captured effectively.\n",
        "\n",
        "What is especially interesting, is the way GloVe controls the influence of rare and frequent words: loss for each pair (w, c) is weighted in a way that:\n",
        "- rare events are penalized,\n",
        "- very frequent events are not over-weighted\n",
        "\n",
        "Applications:\n",
        "- Evaluating similarity between words and concepts based on vector distance\n",
        "- Solving analogies\n",
        "- NER\n",
        "- Improving the classification of text documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708aca6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:37:19.045996Z",
          "iopub.status.busy": "2024-02-28T16:37:19.045567Z",
          "iopub.status.idle": "2024-02-28T16:38:42.843460Z",
          "shell.execute_reply": "2024-02-28T16:38:42.841223Z"
        },
        "id": "708aca6b",
        "papermill": {
          "duration": 85.424204,
          "end_time": "2024-02-28T16:38:44.446284",
          "exception": false,
          "start_time": "2024-02-28T16:37:19.022080",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load the pre-trained GloVe model\n",
        "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "\n",
        "# Find similarity between two words\n",
        "similarity = glove_model.similarity(\"cat\", \"dog\")\n",
        "print(\"Similarity between 'cat' and 'dog':\", similarity)\n",
        "\n",
        "# Find analogy relationship\n",
        "analogy = glove_model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])\n",
        "print(\"Analogy relationship: king - man + woman =\", analogy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc350b2",
      "metadata": {
        "id": "1fc350b2"
      },
      "source": [
        "### Task 2\n",
        "Using fasttext model build vectors from the given words. With the PCA model reduce the dimensionality to 2D and plot the results.\n",
        "\n",
        "> Reminder: [PCA model](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9085c87a",
      "metadata": {
        "id": "9085c87a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Select a subset of words for visualization\n",
        "words = ['king', 'queen', 'man', 'woman', 'apple', 'orange']\n",
        "vectors = np.array([model[word] for word in words])\n",
        "\n",
        "assert len(vectors) == len(words), \"Number of vectors does not match number of words\"\n",
        "\n",
        "# Reduce dimensions to 2D\n",
        "pca = # YOUR CODE\n",
        "result = # YOUR CODE\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, word in enumerate(words):\n",
        "    plt.scatter(result[i, 0], result[i, 1])\n",
        "    plt.text(result[i, 0], result[i, 1], word, fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4760805d",
      "metadata": {
        "id": "4760805d",
        "papermill": {
          "duration": 1.690171,
          "end_time": "2024-02-28T16:38:47.794038",
          "exception": false,
          "start_time": "2024-02-28T16:38:46.103867",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Vector databases\n",
        "\n",
        "A vector database is a specialized database that stores and efficiently queries high-dimensional vectors, such as word or sentence embeddings. These databases enable fast similarity search and retrieval of similar vectors based on distance metrics such as cosine similarity or Euclidean distance.\n",
        "\n",
        "## Examples\n",
        "### FAISS (Facebook AI Similarity Search)\n",
        "FAISS is a library developed by Facebook AI Research for efficient similarity search and clustering of dense vectors. It is optimized for both CPU and GPU, making it suitable for large-scale vector searches.\n",
        "#### Applications:\n",
        "- **Image Retrieval**: Finding similar images in a large database based on their feature vectors.\n",
        "- **Recommendation Systems**: Suggesting products or content based on vector representations of user preferences and items.\n",
        "- **Document Search**: Retrieving documents that are similar to a given query document.\n",
        "\n",
        "### Annoy (Approximate Nearest Neighbors Oh Yeah)\n",
        "Annoy is a library developed by Spotify for performing approximate nearest neighbor search. It uses random projections and is optimized for fast read-only queries. \\\n",
        "Applications:\n",
        "- **Music Recommendation**: Finding similar tracks based on audio embeddings or user behavior.\n",
        "- **Content-Based Search**: Recommending articles, videos, or other content based on vector embeddings.\n",
        "Spotify uses Annoy to recommend songs to users by finding similar tracks based on audio features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "030ff9eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:38:50.981245Z",
          "iopub.status.busy": "2024-02-28T16:38:50.980769Z",
          "iopub.status.idle": "2024-02-28T16:39:33.682607Z",
          "shell.execute_reply": "2024-02-28T16:39:33.680832Z"
        },
        "id": "030ff9eb",
        "papermill": {
          "duration": 44.254135,
          "end_time": "2024-02-28T16:39:33.686099",
          "exception": false,
          "start_time": "2024-02-28T16:38:49.431964",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742d08f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:39:36.884844Z",
          "iopub.status.busy": "2024-02-28T16:39:36.883873Z",
          "iopub.status.idle": "2024-02-28T16:39:38.172117Z",
          "shell.execute_reply": "2024-02-28T16:39:38.170874Z"
        },
        "id": "742d08f1",
        "papermill": {
          "duration": 2.840007,
          "end_time": "2024-02-28T16:39:38.174880",
          "exception": false,
          "start_time": "2024-02-28T16:39:35.334873",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "chroma_client = chromadb.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1ff23a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:39:41.479252Z",
          "iopub.status.busy": "2024-02-28T16:39:41.478816Z",
          "iopub.status.idle": "2024-02-28T16:39:41.511711Z",
          "shell.execute_reply": "2024-02-28T16:39:41.510649Z"
        },
        "id": "fb1ff23a",
        "papermill": {
          "duration": 1.702599,
          "end_time": "2024-02-28T16:39:41.514703",
          "exception": false,
          "start_time": "2024-02-28T16:39:39.812104",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "collection = chroma_client.create_collection(name=\"test_collection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b69c7929",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:39:44.840512Z",
          "iopub.status.busy": "2024-02-28T16:39:44.839919Z",
          "iopub.status.idle": "2024-02-28T16:39:50.006715Z",
          "shell.execute_reply": "2024-02-28T16:39:50.005495Z"
        },
        "id": "b69c7929",
        "papermill": {
          "duration": 6.87323,
          "end_time": "2024-02-28T16:39:50.009578",
          "exception": false,
          "start_time": "2024-02-28T16:39:43.136348",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"The latest iPhone model comes with impressive features and a powerful camera.\",\n",
        "    \"Exploring the beautiful beaches and vibrant culture of Bali is a dream for many travelers.\",\n",
        "    \"Einstein's theory of relativity revolutionized our understanding of space and time.\",\n",
        "    \"Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.\",\n",
        "    \"The American Revolution had a profound impact on the birth of the United States as a nation.\",\n",
        "    \"Regular exercise and a balanced diet are essential for maintaining good physical health.\",\n",
        "    \"Leonardo da Vinci's Mona Lisa is considered one of the most iconic paintings in art history.\",\n",
        "    \"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
        "    \"Startup companies often face challenges in securing funding and scaling their operations.\",\n",
        "    \"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\",\n",
        "]\n",
        "\n",
        "genres = [\n",
        "    \"technology\",\n",
        "    \"travel\",\n",
        "    \"science\",\n",
        "    \"food\",\n",
        "    \"history\",\n",
        "    \"fitness\",\n",
        "    \"art\",\n",
        "    \"climate change\",\n",
        "    \"business\",\n",
        "    \"music\",\n",
        "]\n",
        "\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    ids=[f\"id{i}\" for i in range(len(documents))],\n",
        "    metadatas=[{\"genre\": g} for g in genres],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39a1cda",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:39:53.405762Z",
          "iopub.status.busy": "2024-02-28T16:39:53.404951Z",
          "iopub.status.idle": "2024-02-28T16:39:53.485581Z",
          "shell.execute_reply": "2024-02-28T16:39:53.484246Z"
        },
        "id": "b39a1cda",
        "papermill": {
          "duration": 1.786563,
          "end_time": "2024-02-28T16:39:53.488406",
          "exception": false,
          "start_time": "2024-02-28T16:39:51.701843",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "results = collection.query(query_texts=[\"I'm hungry\"], n_results=1)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf32805",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-28T16:39:56.754914Z",
          "iopub.status.busy": "2024-02-28T16:39:56.754060Z",
          "iopub.status.idle": "2024-02-28T16:39:56.835383Z",
          "shell.execute_reply": "2024-02-28T16:39:56.833978Z"
        },
        "id": "3cf32805",
        "papermill": {
          "duration": 1.766959,
          "end_time": "2024-02-28T16:39:56.838452",
          "exception": false,
          "start_time": "2024-02-28T16:39:55.071493",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "results = collection.query(query_texts=[\"sport\"], n_results=1)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed29c83",
      "metadata": {
        "id": "0ed29c83"
      },
      "source": [
        "## Contextual Embeddings\n",
        "\n",
        "In this lab, you've learned about two popular techniques for creating word embeddings: Continuous Bag of Words (CBOW) and Skip-Gram. These techniques are used in word2vec, a popular algorithm for generating word embeddings, GloVe, and fastText.\n",
        "However, there's another powerful technique that has revolutionized the field of NLP in recent years: BERT (Bidirectional Encoder Representations from Transformers). Developed by Google, BERT is a pre-trained language model that has achieved state-of-the-art results in a wide range of NLP tasks, such as question answering, sentiment analysis, and text classification.\n",
        "\n",
        "BERT uses a different approach to generate embeddings, **which we'll explore in more detail in Lab 12**. For now, let's just say that BERT's embeddings are contextualized, meaning that they take into account the context in which a word is used, rather than relying on a fixed vector representation. Don't worry if you don't fully understand BERT just yet – we'll dive deeper into its architecture and applications later in the course.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Dnau15/LabImages/main/images/lab07/bert.jpg\" alt=\"3 Vectors\" width=\"700\"/>\n",
        "\n",
        "\n",
        "Contextual Embeddings models:\n",
        "- **ELMo** (Embeddings from Language Models): Uses deep, bi-directional LSTM networks to capture context.\n",
        "- **BERT** (Bidirectional Encoder Representations from Transformers): Uses transformer models to provide context-aware embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de6fcc94",
      "metadata": {
        "id": "de6fcc94"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb25b2e",
      "metadata": {
        "id": "0bb25b2e"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45c2813",
      "metadata": {
        "id": "e45c2813"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('imdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce435d46",
      "metadata": {
        "id": "ce435d46"
      },
      "outputs": [],
      "source": [
        "print(\"Training set:\")\n",
        "print(dataset['train'][0])\n",
        "print(\"Number of training examples:\", len(dataset['train']))\n",
        "print(\"Number of test examples:\", len(dataset['test']))\n",
        "\n",
        "# Check the label distribution\n",
        "labels = [example['label'] for example in dataset['train']]\n",
        "label_counts = {label: labels.count(label) for label in set(labels)}\n",
        "print(\"Label distribution:\", label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6dcd507",
      "metadata": {
        "id": "a6dcd507"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "def get_sampled_dataset(dataset, num_samples=1000):\n",
        "    # Create a dictionary to hold the sampled splits\n",
        "    sampled_dataset_dict = {}\n",
        "    for split in ['train', 'test']:\n",
        "        # Shuffle and select a subset of the data\n",
        "        sampled_data = dataset[split].shuffle(seed=42).select(range(num_samples))\n",
        "        # Add the sampled data to the dictionary\n",
        "        sampled_dataset_dict[split] = sampled_data\n",
        "\n",
        "    # Return as a DatasetDict\n",
        "    return DatasetDict(sampled_dataset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1330eaa1",
      "metadata": {
        "id": "1330eaa1"
      },
      "outputs": [],
      "source": [
        "num_samples = 1000\n",
        "\n",
        "# Get the sampled dataset\n",
        "dataset = get_sampled_dataset(dataset, num_samples=num_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c255a0d",
      "metadata": {
        "id": "4c255a0d"
      },
      "source": [
        "### Task 3\n",
        " Train a BERT model for sentiment classification on the IMDB dataset, explore the dataset, understand training parameters, and compare baseline and optimized pipelines.\n",
        " Which metric is more appropriate for this task? Why? Try to achieve accuracy 0.86 and F1 0.85."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de3bba0",
      "metadata": {
        "id": "2de3bba0"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = # YOUR CODE\n",
        "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b64d82",
      "metadata": {
        "id": "79b64d82"
      },
      "source": [
        "#### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "defb44d4",
      "metadata": {
        "id": "defb44d4"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import default_data_collator\n",
        "from datasets import load_dataset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions = # YOUR CODE\n",
        "    accuracy = # YOUR CODE\n",
        "    f1 = f1_score(p.label_ids, predictions, average='weighted')\n",
        "    return {\n",
        "        'accuracy': # YOUR CODE\n",
        "        'f1': # YOUR CODE\n",
        "    }\n",
        "\n",
        "# Define the Trainer for evaluation\n",
        "training_args = TrainingArguments(\n",
        "    per_device_eval_batch_size=8,\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=# YOUR CODE,\n",
        "    args=# YOUR CODE,\n",
        "    eval_dataset=# YOUR CODE,\n",
        "    data_collator=# YOUR CODE,\n",
        "    compute_metrics=# YOUR CODE,\n",
        ")\n",
        "\n",
        "# Evaluate the pre-trained model\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Initial Evaluation Results:\", eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece120fc",
      "metadata": {
        "id": "ece120fc"
      },
      "source": [
        "### Task 3. Continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3c1cf8",
      "metadata": {
        "id": "fa3c1cf8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "import torch\n",
        "\n",
        "# Define metrics\n",
        "metric = load_metric('accuracy')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    # YOUR CODE\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1d18fe",
      "metadata": {
        "id": "cc1d18fe"
      },
      "source": [
        "## What about Images? How do they relate to the text?\n",
        "### Relationship Between Image and Text Embeddings:\n",
        "\n",
        "- Multimodal Learning: To bridge the gap between image and text data, multimodal learning approaches are employed. These approaches aim to create shared representations where both image and text data can be compared and analyzed in a unified space.\n",
        "- Joint Embedding Spaces: In a joint embedding space, both image and text embeddings are mapped to a common vector space. This allows for comparisons between text and images, enabling tasks like image captioning, visual question answering, and cross-modal retrieval.\n",
        "- Cross-Modal Retrieval: This involves retrieving relevant images given a text query or vice versa. For example, a model might return images related to a textual description or generate a textual description for a given image by comparing their embeddings in the joint space.\n",
        "- Attention Mechanisms: Modern models like transformers use attention mechanisms to align and relate image and text embeddings effectively. For instance, the Vision-Language Pre-trained (VLP) models leverage attention to create rich, contextually aware representations of both modalities.\n",
        "\n",
        "### Applications:\n",
        "\n",
        "- Image Captioning: Generating textual descriptions for images by understanding and interpreting the visual content.\n",
        "- Visual Question Answering (VQA): Answering questions about an image by interpreting both the visual content and the textual question.\n",
        "- Cross-Modal Retrieval: Finding relevant images based on textual queries or generating text descriptions for images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j8NjOsJLM81j",
      "metadata": {
        "id": "j8NjOsJLM81j"
      },
      "source": [
        "## What is CLIP?\n",
        "\n",
        "CLIP (Contrastive Language-Image Pre-training) is a deep learning model that combines computer vision and natural language processing (NLP) to learn a joint representation of images and text.\n",
        "\n",
        "Developed by OpenAI, CLIP is a type of multimodal model that can be fine-tuned for various downstream tasks, such as:\n",
        "\n",
        "- Image-text matching: Given an image and a text description, CLIP can predict whether the text accurately describes the image.\n",
        "- Image classification: CLIP can be used for image classification tasks, such as object detection, scene understanding, and image captioning.\n",
        "- Text-to-image synthesis: CLIP can be used to generate images from text descriptions.\n",
        "\n",
        "CLIP is trained on a massive dataset of images and text pairs, using a contrastive learning objective. The model learns to predict whether a given text description matches an image, by contrasting the similarity between the text and image embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cda1f228",
      "metadata": {
        "id": "cda1f228"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, CLIPModel, AutoProcessor\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "inputs = tokenizer([\"a photo of a cat\", \"a photo of a dog\"], padding=True, return_tensors=\"pt\")\n",
        "\n",
        "text_embeds = model.get_text_features(**inputs)\n",
        "text_embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b702449c",
      "metadata": {
        "id": "b702449c"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8784ec5f",
      "metadata": {
        "id": "8784ec5f"
      },
      "source": [
        "### Task 4\n",
        "Extract  image features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca19352",
      "metadata": {
        "id": "eca19352"
      },
      "outputs": [],
      "source": [
        "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "inputs = # YOUR CODE\n",
        "\n",
        "image_features = # YOUR CODE\n",
        "image_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b9b5ece",
      "metadata": {
        "id": "4b9b5ece"
      },
      "source": [
        "### Task 5\n",
        "Use 'magic' to understand what is shown in the picture. Hint: you can use cosine similarity, higher results correspond to higher probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6280c1ba",
      "metadata": {
        "id": "6280c1ba"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.matmul(text_embeds, image_features.t())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c0da45",
      "metadata": {
        "id": "e5c0da45"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(embedding1, embedding2):\n",
        "    # YOUR CODE\n",
        "\n",
        "similarity = cosine_similarity(image_features, text_embeds)\n",
        "print(f\"Cosine similarity between image and text: {similarity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1HWbFwyaEldi",
      "metadata": {
        "id": "1HWbFwyaEldi"
      },
      "source": [
        "# Word2Vec training\n",
        "\n",
        "Your task is to train a Word2Vec model on the Simpsons dialog dataset to obtain word embeddings, and then use these embeddings to find similar words and words that do not match.\n",
        "\n",
        "You will dive into the world of America's favorite animated family - The Simpsons! You'll be working with a unique dataset that contains a vast collection of Simpsons dialogs, spanning over 600 episodes, from 1989 to present.\n",
        "\n",
        "In this task, you will be asked to:\n",
        "\n",
        "- Preprocess the dataset to prepare it for analysis\n",
        "- Apply NLP techniques to extract insights from the dialogues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PQZonXDIEown",
      "metadata": {
        "id": "PQZonXDIEown"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from collections import defaultdict\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49NirM1EErcQ",
      "metadata": {
        "id": "49NirM1EErcQ"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!wget https://raw.githubusercontent.com/Dnau15/LabImages/main/data/txt_data/simpsons_dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "onJpdqVJEreN",
      "metadata": {
        "id": "onJpdqVJEreN"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('simpsons_dataset.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uoQhOnl6ErgH",
      "metadata": {
        "id": "uoQhOnl6ErgH"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "idiVaFqfErh9",
      "metadata": {
        "id": "idiVaFqfErh9"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UpteEi6xErjx",
      "metadata": {
        "id": "UpteEi6xErjx"
      },
      "outputs": [],
      "source": [
        "df = df.dropna().reset_index(drop=True)\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yMc0O4DcF-uH",
      "metadata": {
        "id": "yMc0O4DcF-uH"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9LhKyMKpErl0",
      "metadata": {
        "id": "9LhKyMKpErl0"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G0CSIdLiErni",
      "metadata": {
        "id": "G0CSIdLiErni"
      },
      "outputs": [],
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VITI2tzKErq-",
      "metadata": {
        "id": "VITI2tzKErq-"
      },
      "outputs": [],
      "source": [
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CYra7ijDFDj6",
      "metadata": {
        "id": "CYra7ijDFDj6"
      },
      "outputs": [],
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cSXDnh6N8XX",
      "metadata": {
        "id": "1cSXDnh6N8XX"
      },
      "source": [
        "We are using Gensim Phrases package to automatically detect common phrases (bigrams) from a list of sentences. https://radimrehurek.com/gensim/models/phrases.html\n",
        "\n",
        "The main reason we do this is to catch words like \"mr_burns\" or \"bart_simpson\" !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oojIafp4FDmf",
      "metadata": {
        "id": "oojIafp4FDmf"
      },
      "outputs": [],
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "\n",
        "sent = [row.split() for row in df_clean['clean']]\n",
        "phrases = Phrases(sent, min_count=30, progress_per=10000)\n",
        "bigram = Phraser(phrases)\n",
        "sentences = bigram[sent]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YsIP6Wz-TQSo",
      "metadata": {
        "id": "YsIP6Wz-TQSo"
      },
      "source": [
        "# Task 6\n",
        "Find frequency of each word and then find top-10 most frequence words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NU7pfQaQFDop",
      "metadata": {
        "id": "NU7pfQaQFDop"
      },
      "outputs": [],
      "source": [
        "word_freq = defaultdict(int)\n",
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_PQ9dx31FDq3",
      "metadata": {
        "id": "_PQ9dx31FDq3"
      },
      "outputs": [],
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EN82jtqwTZ_6",
      "metadata": {
        "id": "EN82jtqwTZ_6"
      },
      "source": [
        "# Task 7\n",
        "\n",
        "Train Word2Vec model and then complete subtasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LppapneeFDuK",
      "metadata": {
        "id": "LppapneeFDuK"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     sample=6e-5,\n",
        "                     alpha=0.03,\n",
        "                     min_alpha=0.0007,\n",
        "                     negative=20,\n",
        "                     vector_size=300,\n",
        "                     workers=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cK5dsU5FOQY",
      "metadata": {
        "id": "2cK5dsU5FOQY"
      },
      "outputs": [],
      "source": [
        "w2v_model.build_vocab(sentences, progress_per=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wVTNTf85FOTG",
      "metadata": {
        "id": "wVTNTf85FOTG"
      },
      "outputs": [],
      "source": [
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GWcg2SqWFT8j",
      "metadata": {
        "id": "GWcg2SqWFT8j"
      },
      "outputs": [],
      "source": [
        "w2v_model.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ien-_tUiC3",
      "metadata": {
        "id": "b8ien-_tUiC3"
      },
      "source": [
        "Analyse and try to understand the difference between synonyms between \"homer\" and \"home simpson\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68WUKO1iFT-o",
      "metadata": {
        "id": "68WUKO1iFT-o"
      },
      "outputs": [],
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XDYTYBxwFUCE",
      "metadata": {
        "id": "XDYTYBxwFUCE"
      },
      "outputs": [],
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eMutvDnsFOWD",
      "metadata": {
        "id": "eMutvDnsFOWD"
      },
      "outputs": [],
      "source": [
        "w2v_model.wv.most_similar(positive=[\"marge\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yYV09eMXFYe7",
      "metadata": {
        "id": "yYV09eMXFYe7"
      },
      "outputs": [],
      "source": [
        "w2v_model.wv.most_similar(positive=[\"bart\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jljl98uGSrDb",
      "metadata": {
        "id": "jljl98uGSrDb"
      },
      "source": [
        "Which word is to woman as homer is to marge? Is your answer meaningful? Try to proof\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Is1TXRDyS1WC",
      "metadata": {
        "id": "Is1TXRDyS1WC"
      },
      "outputs": [],
      "source": [
        "w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7a0791",
      "metadata": {
        "id": "0e7a0791"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Throughout this lesson, we've delved into the world of word embeddings and their applications in Natural Language Processing. We've explored various techniques, each offering unique advantages and insights into how computers understand and process human language.\n",
        "\n",
        "- Embedding. Word embeddings are foundational in NLP, transforming words into dense vectors that capture semantic relationships. These embeddings enable machines to grasp meanings and contexts, enhancing tasks like language modeling, sentiment analysis, and information retrieval.\n",
        "- Distributional Semantics. Theory positing that words with similar meanings occur in similar contexts. This concept underpins the creation of embeddings by leveraging large corpora to learn associations between words.\n",
        "- Word2Vec. We explored both Continuous Bag of Words (CBOW) and Skip-gram models, each tailored to predict context from a target word or vice versa, thereby capturing intricate semantic nuances.\n",
        "- fasttext. Extends Word2Vec by incorporating subword information. This innovation is particularly effective for handling morphologically rich languages and rare words, enhancing accuracy in tasks like named entity recognition and text classification.\n",
        "- GloVe. Stanford's algorithm employs global word co-occurrence statistics to generate embeddings. By focusing on the probabilities of word pairs appearing together, GloVe creates embeddings that reflect deeper semantic relationships, useful for tasks requiring nuanced understanding of language.\n",
        "- ChromaDB. Vector databases facilitate efficient storage and retrieval of embeddings. They support tasks such as similarity searches and clustering, crucial for applications ranging from personalized recommendations to large-scale data analytics.\n",
        "- The further learning of embedding includes contextual embeddings (BERT and transformers), multinomial embedding (integrating embeddings from text, images, and other data).\n",
        "\n",
        "In conclusion, the study of embeddings and their underlying techniques represents a pivotal advancement in NLP, driving innovations that redefine how we interact with and interpret human language.\n",
        "\n",
        "\n",
        "References:\n",
        "- https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vMqgOFgcTFvk",
      "metadata": {
        "id": "vMqgOFgcTFvk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 7819277,
          "sourceId": 71512,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 698.551223,
      "end_time": "2024-02-28T16:46:24.778747",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-28T16:34:46.227524",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
