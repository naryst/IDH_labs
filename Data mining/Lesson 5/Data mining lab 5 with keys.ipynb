{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzSZcvASEQX-"
   },
   "source": [
    "# Data mining\n",
    "\n",
    "# Lesson 5\n",
    "\n",
    "# Forecasting Trends and Seasonality in Time Series Data\n",
    "\n",
    "### **Objectives:**\n",
    "- Understand the components of time series data: trend, seasonality, and noise.\n",
    "- Perform decomposition to analyze these components.\n",
    "- Apply methods like moving averages and exponential smoothing for forecasting.\n",
    "- Use models like ARIMA or Prophet to predict future values.\n",
    "\n",
    "### **Description**\n",
    "\n",
    "Time series analysis is a powerful method for understanding data that evolves over time. In this lab, we will focus on identifying trends, seasonality, and noise in time series data. Using methods like moving averages, decomposition, and forecasting models, students will learn to make predictions about future values.\n",
    "\n",
    "We will simulate synthetic time series data with trends, seasonality, and random noise, allowing students to explore different forecasting techniques effectively.\n",
    "\n",
    "\n",
    "### Libraries that we use:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) - a library for working with tabular data, which will help us in the data preparation phase.\n",
    "- [Matplotlib](https://matplotlib.org/) and [Seaborn](https://seaborn.pydata.org/) - for data visualization and identifying interesting patterns.\n",
    "- [Numpy](https://numpy.org/) - a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "- [statsmodels](https://www.statsmodels.org/stable/index.html) -  for decomposition and ARIMA.\n",
    "- [fbprophet](https://github.com/facebook/prophet) - for advanced time series forecasting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMabQkd90DVa"
   },
   "source": [
    "#### Structure: time series data.\n",
    "\n",
    "- Time series data containing:\n",
    "1) A linear trend.\n",
    "2) Seasonality with a sinusoidal pattern.\n",
    "3) Random noise to simulate variability.\n",
    "\n",
    "Value = trend + seasonalty + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "id": "S5d91on31Gu4",
    "outputId": "dcf94f27-2e68-490a-bb74-75b7f7ec6f19"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a time range\n",
    "n_periods = 1000  # Number of time steps\n",
    "time = pd.date_range(start='2020-01-01', periods=n_periods, freq='D')  # Daily frequency\n",
    "\n",
    "# Create components of time series\n",
    "trend = np.linspace(10, 50, n_periods)  # Linear trend\n",
    "seasonality = 10 * np.sin(2 * np.pi * time.dayofyear / 30)  # Monthly seasonality\n",
    "noise = np.random.normal(0, 2, n_periods)  # Random noise\n",
    "\n",
    "# Combine components to form the time series\n",
    "data = trend + seasonality + noise\n",
    "\n",
    "# Create a DataFrame\n",
    "time_series = pd.DataFrame({'Date': time, 'Value': data})\n",
    "time_series.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Synthetic Time Series')\n",
    "plt.title('Synthetic Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3jbRK7L13Bs"
   },
   "source": [
    "## **Exercise 1:** Decompose Time Series into Components\n",
    "- Use additive decomposition to separate the time series into trend, seasonality, and residual components.\n",
    "- Visualize the decomposition results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Perform decomposition (additive model)\n",
    "decomposition = seasonal_decompose(time_series, model='additive', period=30)\n",
    "\n",
    "# Plot decomposition results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(time_series, label='Original')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(decomposition.trend, label='Trend')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(decomposition.seasonal, label='Seasonality')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(decomposition.resid, label='Residuals')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk0xQNEY2dYb"
   },
   "source": [
    "## **Exercise 2:** Apply Moving Average Smoothing\n",
    "\n",
    "- Use moving averages to smooth the time series data.\n",
    "- Compare different window sizes for smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owc5lQdf7if5"
   },
   "outputs": [],
   "source": [
    "# Apply moving averages with different window sizes\n",
    "time_series['MA_7'] = time_series['Value'].rolling(window=7).mean()\n",
    "time_series['MA_30'] = time_series['Value'].rolling(window=30).mean()\n",
    "\n",
    "# Plot original time series and smoothed versions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series['Value'], label='Original', alpha=0.5)\n",
    "plt.plot(time_series['MA_7'], label='7-Day Moving Average', color='red')\n",
    "plt.plot(time_series['MA_30'], label='30-Day Moving Average', color='green')\n",
    "plt.title('Moving Average Smoothing')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3:** Forecasting Using Exponential Smoothing\n",
    "- Apply Exponential Smoothing to forecast the next 30 days.\n",
    "- Plot the forecast results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Apply Holt-Winters Exponential Smoothing\n",
    "model = ExponentialSmoothing(time_series['Value'], trend='add', seasonal='add', seasonal_periods=30)\n",
    "fit_model = model.fit()\n",
    "\n",
    "# Forecast next 30 days\n",
    "forecast = fit_model.forecast(steps=30)\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series['Value'], label='Original', alpha=0.5)\n",
    "plt.plot(forecast, label='Forecast', color='red')\n",
    "plt.title('Forecasting with Exponential Smoothing')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 4:** Forecasting Using ARIMA\n",
    "- Apply the ARIMA model to forecast future values.\n",
    "- Compare the performance of ARIMA with Exponential Smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit ARIMA model\n",
    "arima_model = ARIMA(time_series['Value'], order=(2, 1, 2))  # ARIMA(p, d, q)\n",
    "arima_fit = arima_model.fit()\n",
    "\n",
    "# Forecast next 30 days\n",
    "arima_forecast = arima_fit.forecast(steps=30)\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series['Value'], label='Original', alpha=0.5)\n",
    "plt.plot(arima_forecast, label='ARIMA Forecast', color='orange')\n",
    "plt.title('Forecasting with ARIMA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 5:** Analyze and Compare Forecasting Results\n",
    "- Compare the forecasts obtained from:\n",
    "1) Exponential Smoothing.\n",
    "2) ARIMA.\n",
    "- Evaluate forecast accuracy using:\n",
    "1) Mean Absolute Error (MAE).\n",
    "2) Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Actual future values (simulate for comparison)\n",
    "actual_values = trend[-30:] + seasonality[-30:] + noise[-30:]\n",
    "\n",
    "# Calculate MAE and RMSE for Exponential Smoothing\n",
    "mae_exp = mean_absolute_error(actual_values, forecast)\n",
    "rmse_exp = np.sqrt(mean_squared_error(actual_values, forecast))\n",
    "\n",
    "# Calculate MAE and RMSE for ARIMA\n",
    "mae_arima = mean_absolute_error(actual_values, arima_forecast)\n",
    "rmse_arima = np.sqrt(mean_squared_error(actual_values, arima_forecast))\n",
    "\n",
    "# Print results\n",
    "print(f\"Exponential Smoothing - MAE: {mae_exp:.2f}, RMSE: {rmse_exp:.2f}\")\n",
    "print(f\"ARIMA - MAE: {mae_arima:.2f}, RMSE: {rmse_arima:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consclusion:\n",
    "\n",
    "We learned: \n",
    "\n",
    "- Understand the components of time series data: trend, seasonality, and noise.\n",
    "- Perform decomposition to analyze these components.\n",
    "- Apply methods like moving averages and exponential smoothing for forecasting.\n",
    "- Use models like ARIMA or Prophet to predict future values.\n",
    "\n",
    "This lab introduces students to time series decomposition, smoothing, and forecasting, providing them with practical skills to analyze trends and seasonality in time-dependent data.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Data mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
