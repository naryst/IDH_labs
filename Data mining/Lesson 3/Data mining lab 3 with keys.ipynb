{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzSZcvASEQX-"
   },
   "source": [
    "# Data mining\n",
    "\n",
    "# Lesson 3\n",
    "\n",
    "# Data Analysis Using Factor Analysis, PCA, and SVD\n",
    "\n",
    "### **Objective:**\n",
    "Learn to apply dimensionality reduction methods, such as Factor Analysis, PCA, and SVD, to analyze high-dimensional data. Understand how these methods uncover hidden structures and simplify data for better analysis and modeling.\n",
    "\n",
    "### **Description**\n",
    "\n",
    "Dimensionality reduction methods such as Factor Analysis, Principal Component Analysis (PCA), and Singular Value Decomposition (SVD) are essential in data analysis, especially when working with high-dimensional data. These methods help reduce the number of variables while preserving most of the information, making data easier to visualize and process. This lab focuses on implementing and understanding these techniques in practice.\n",
    "\n",
    "### What we will learn:\n",
    "- Applying PCA to reduce dimensionality and interpret components.\n",
    "- Using Factor Analysis to identify hidden factors in the data.\n",
    "- Applying SVD for data decomposition and analysis.\n",
    "- Evaluating the impact of dimensionality reduction on data and model performance.\n",
    "\n",
    "### Libraries that we use:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) - a library for working with tabular data, which will help us in the data preparation phase.\n",
    "- [Matplotlib](https://matplotlib.org/) - for data visualization and identifying interesting patterns.\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/) - machine learning library for building and evaluating models.\n",
    "- [Numpy](https://numpy.org/) - a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMabQkd90DVa"
   },
   "source": [
    "### Structure of the laboratory work:\n",
    "\n",
    "- We have sales data and want to predict which customers are most likely to make a purchase in the next month.\n",
    "\n",
    "Our **data.csv** with columns:\n",
    "\n",
    "    \"Age (integer between 18 and 65)\",\n",
    "    \"Annual Income (integer between 15,000 and 120,000)\",\n",
    "    \"Customer Satisfaction (integer between 1 and 10)\",\n",
    "    \"Purchase Frequency (integer between 1 and 30)\",\n",
    "    \"Customer Loyalty (integer between 1 and 10)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "id": "S5d91on31Gu4",
    "outputId": "dcf94f27-2e68-490a-bb74-75b7f7ec6f19"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download data\n",
    "data = pd.read_csv('data.csv')\n",
    "df = pd.DataFrame(data)\n",
    "# Description\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3jbRK7L13Bs"
   },
   "source": [
    "## **Exercise 1:** Principal Component Analysis (PCA)\n",
    "- Standardize the dataset before applying PCA using StandardScaler.\n",
    "- Apply PCA to reduce dimensionality to 2 components.\n",
    "- Output the explained variance ratio for each component.\n",
    "- Visualize the data after dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Apply PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance Ratio: {explained_variance}\")\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=['PCA1', 'PCA2'])\n",
    "\n",
    "# Visualize PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', data=pca_df, alpha=0.6)\n",
    "plt.title('PCA: Dimensionality Reduction to 2 Components')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk0xQNEY2dYb"
   },
   "source": [
    "## **Exercise 2:** Factor Analysis\n",
    "- Apply Factor Analysis to identify 2 hidden factors.\n",
    "- Analyze how the original features load onto these factors.\n",
    "- Visualize the factor analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owc5lQdf7if5"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# Apply Factor Analysis with 2 factors\n",
    "fa = FactorAnalysis(n_components=2, random_state=42)\n",
    "factors = fa.fit_transform(scaled_data)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "fa_df = pd.DataFrame(data=factors, columns=['Factor1', 'Factor2'])\n",
    "\n",
    "# Visualize factors\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Factor1', y='Factor2', data=fa_df, alpha=0.6)\n",
    "plt.title('Factor Analysis: Identifying 2 Hidden Factors')\n",
    "plt.show()\n",
    "\n",
    "# Factor loadings\n",
    "print(\"Factor Loadings:\")\n",
    "print(pd.DataFrame(fa.components_, columns=df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3:** Singular Value Decomposition (SVD)\n",
    "- Apply Singular Value Decomposition (SVD) to the dataset using numpy.\n",
    "- Identify the three most significant singular values and analyze their contribution.\n",
    "- Visualize the projections of data onto the first two singular vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply SVD\n",
    "U, S, Vt = np.linalg.svd(scaled_data, full_matrices=False)\n",
    "\n",
    "# Print the three most significant singular values\n",
    "print(f\"Top 3 Singular Values: {S[:3]}\")\n",
    "\n",
    "# Create a DataFrame for visualizing projections onto the first two singular vectors\n",
    "svd_df = pd.DataFrame(data=U[:, :2], columns=['SVD1', 'SVD2'])\n",
    "\n",
    "# Visualize SVD results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='SVD1', y='SVD2', data=svd_df, alpha=0.6)\n",
    "plt.title('SVD: Projections onto First Two Singular Vectors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 4:** Comparing Methods\n",
    "- Compare the results obtained using PCA, Factor Analysis, and SVD.\n",
    "- Discuss which method works best for your dataset and why.\n",
    "- Visualize the differences between PCA, Factor Analysis, and SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA, Factor Analysis, and SVD results side by side\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# PCA scatter plot\n",
    "sns.scatterplot(x='PCA1', y='PCA2', data=pca_df, ax=ax[0], alpha=0.6)\n",
    "ax[0].set_title('PCA')\n",
    "\n",
    "# Factor Analysis scatter plot\n",
    "sns.scatterplot(x='Factor1', y='Factor2', data=fa_df, ax=ax[1], alpha=0.6)\n",
    "ax[1].set_title('Factor Analysis')\n",
    "\n",
    "# SVD scatter plot\n",
    "sns.scatterplot(x='SVD1', y='SVD2', data=svd_df, ax=ax[2], alpha=0.6)\n",
    "ax[2].set_title('SVD')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consclusion:\n",
    "\n",
    "We learned: \n",
    "\n",
    "- Applying PCA to reduce dimensionality and interpret components.\n",
    "- Using Factor Analysis to identify hidden factors in the data.\n",
    "- Applying SVD for data decomposition and analysis.\n",
    "- Evaluating the impact of dimensionality reduction on data and model performance.\n",
    "\n",
    "This lab focuses on understanding and applying dimensionality reduction techniques to uncover hidden structures in high-dimensional data while preserving critical information.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Data mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
