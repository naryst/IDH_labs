{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zELdqj80YjAD"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ih_PEc7TS0G"
      },
      "source": [
        "# Lesson 3: Agents in Artificial Intelligence\n",
        "\n",
        "\n",
        "\n",
        "In this lab, we will explore the concept of agents in artificial intelligence (AI).  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u1k4y1BE6SQ"
      },
      "source": [
        "- What is an Agent?\n",
        "- Types of Agents\n",
        "- practical examples to illustrate the types of Agents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction:"
      ],
      "metadata": {
        "id": "6u7yD98MYYOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is an AI Agent?"
      ],
      "metadata": {
        "id": "0kCIeeY2YcvF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxIfDdP2TS0H"
      },
      "source": [
        "\n",
        "In artificial intelligence, an agent is a computer program or system that is designed to perceive its environment, make decisions and take actions to achieve a specific goal or set of goals. The agent operates autonomously, meaning it is not directly controlled by a human operator [[1](https://www.geeksforgeeks.org/agents-artificial-intelligence/)].\n",
        "\n",
        "Agents can be classified into different types based on their characteristics, such as whether they are reactive or proactive, whether they have a fixed or dynamic environment, and whether they are single or multi-agent systems.\n",
        "\n",
        "Artificial intelligence is defined as the study of rational agents. A rational agent could be anything that makes decisions, such as a person, firm, machine, or software. It carries out an action with the best outcome after considering past and current percepts(agent’s perceptual inputs at a given instance). An AI system is composed of an agent and its environment. The agents act in their environment. The environment may contain other agents.\n",
        "\n",
        "An agent is anything that can be viewed as:\n",
        "\n",
        "    Perceiving its environment through sensors and\n",
        "    \n",
        "    Acting upon that environment through actuators\n",
        "\n",
        "\n",
        "The agent function maps percepts to actions and can be described mathematically as:\n",
        "\n",
        "$$ f: P^* \\rightarrow A $$\n",
        "\n",
        "Where:\n",
        "- $P$ is the set of percepts.\n",
        "- $A$ is the set of actions.\n",
        "- $P^*$ is the sequence of percepts received to date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI0lwoF4TS0H"
      },
      "source": [
        "### Structure of Intelligent Agents\n",
        "\n",
        "An intelligent agent typically consists of four main components:\n",
        "1. **Sensors**: Devices or methods to perceive the environment.\n",
        "2. **Actuators**: Mechanisms to perform actions in the environment.\n",
        "3. **Perception**: The agent’s ability to gather information from the environment.\n",
        "4. **Actuation**: The agent’s ability to affect the environment.\n",
        "\n",
        "\n",
        "![link text](https://static.javatpoint.com/tutorial/ai/images/agent-environment-in-ai.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeQSD2T9E6SR"
      },
      "source": [
        "### **Rationality**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rationality** depends on:\n",
        "\n",
        "- the performance measure defining the success criterion\n",
        "\n",
        "- the agent’s prior knowledge of the environment\n",
        "\n",
        "- the actions that the agent can perform\n",
        "\n",
        "- the agent’s percept sequence to date\n",
        "\n",
        "**Rational action:** whichever action maximizes the expected value of the performance measure given the percept sequence to date and built-in knowledge\n",
        "\n",
        "**Rational agent:** for each possible percept sequence, selects an action that is expected to maximize its performance measure\n",
        "\n",
        " Rational != omniscient\n",
        "\n",
        " Rational != clairvoyant\n",
        "\n",
        " Rational != successful\n"
      ],
      "metadata": {
        "id": "0gb85ozNdtQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Omniscience, Learning, and Autonomy**\n",
        "Rational != omniscient\n",
        "- airplane flattens person crossing street example\n",
        "\n",
        "- rationality maximizes expected performance, depending on knowledge to\n",
        "date; perfection maximizes actual performance\n",
        "\n",
        "- crossing without looking is not rational because lacks information gathering (doing actions to modify future percepts, exploration)\n",
        "\n",
        "**Rational agents should also**\n",
        "- learn from percepts (to augment or modify prior knowledge)\n",
        "- learn to be autonomous (rely on percepts rather than prior – often partial\n",
        "and/or incorrect – knowledge)\n",
        "\n",
        "\n",
        "Rational ⇒ exploration, learning, autonomy"
      ],
      "metadata": {
        "id": "R203E6WifbA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Agents and Environments**"
      ],
      "metadata": {
        "id": "zELdqj80YjAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " - Agents include humans, robots, softbots, thermostats, etc.\n",
        "\n",
        " - Example 1 : Humans\n",
        "- **Environments:** ( Home, School, Work)\n",
        "- **Sensors:** (Eyes,, Ears, Mouth, Nose, Skin)\n",
        "- **Actuators:** (Hands, Feet, Speech)\n",
        "\n",
        "- Example 2: Self-Driving Car\n",
        "  - **Percepts:** Video, sonar, speedometer, odometer, engine sensors, keyboard input,\n",
        "microphone, GPS, ...\n",
        "  - **Actions:** Steer, accelerate, brake, horn, speak/display, ...\n",
        "  -  **Goals:** Maintain safety, reach destination, maximize profits (fuel, tire wear),\n",
        "obey laws, provide passenger comfort, ...\n",
        "  - **Environment:** U.S. urban streets, freeways, traffic, pedestrians, weather,\n",
        "customers, ..."
      ],
      "metadata": {
        "id": "-MsDd2_lYNOW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRRLOjwKTS0N"
      },
      "source": [
        "### Types of Agents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. **Simple Reflex Agents:**\n",
        "\n",
        "Simple reflex agents ignore the rest of the percept history and act only on the basis of the current percept. Percept history is the history of all that an agent has perceived to date. The agent function is based on the condition-action rule. A condition-action rule is a rule that maps a state i.e., a condition to an action. If the condition is true, then the action is taken, else not. This agent function only succeeds when the environment is fully observable. For simple reflex agents operating in partially observable environments, infinite loops are often unavoidable. It may be possible to escape from infinite loops if the agent can randomize its actions.\n",
        "\n",
        "**Problems with Simple reflex agents are** :\n",
        "\n",
        "- Very limited intelligence.\n",
        "- No knowledge of non-perceptual parts of the state.\n",
        "- Usually too big to generate and store.\n",
        "- If there occurs any change in the environment, then the collection of rules needs to be updated.\n",
        "\n",
        "![link text](https://media.geeksforgeeks.org/wp-content/cdn-uploads/ai3-1.png)"
      ],
      "metadata": {
        "id": "P6ZY2fZvgDCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Vacuum Cleaner**\n",
        "\n",
        "Imagine a vacuum cleaner robot that can sense its immediate surroundings and decide what action to take based on simple rules.\n",
        "\n",
        "Here’s how could be implement it :\n",
        "\n",
        "- Percept: For the vacuum cleaner, percepts could be \"Dirt,\" \"Obstacle on the left,\" \"Obstacle on the right,\" or \"Clean.\"\n",
        "\n",
        "- Action: The actions could be \"Move Right,\" \"Move Left,\" \"Clean,\" or \"Stay.\"\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - If the vacuum cleaner senses dirt, it will clean it.\n",
        "  - If it senses an obstacle on the left, it will move right.\n",
        "  - If it senses an obstacle on the right, it will move left.\n",
        "  -If there is nothing special to do, it will stay in its place."
      ],
      "metadata": {
        "id": "ijIwX7oWltOR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22QioRY1TS0N"
      },
      "source": [
        "class SimpleReflexAgent:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_action(self, percept):\n",
        "        if percept == \"Obstacle on the left\":\n",
        "            return \"Move Right\"\n",
        "        elif percept == \"Obstacle on the right\":\n",
        "            return \"Move Left\"\n",
        "        elif percept == \"Dirt\":\n",
        "            return \"Clean\"\n",
        "        else:\n",
        "            return \"Stay\"\n",
        "\n",
        "# Example\n",
        "agent = SimpleReflexAgent()\n",
        "percepts = [\"Dirt\", \"Obstacle on the left\", \"Obstacle on the right\", \"Clean\"]\n",
        "actions = [agent.get_action(p) for p in percepts]\n",
        "for percept, action in zip(percepts, actions):\n",
        "    print(f\"Percept: {percept} -> Action: {action}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise 1:\n",
        "complete the following code.Modify the SimpleReflexAgent to handle a new percept \"Obstacle in front\".\n",
        "\n"
      ],
      "metadata": {
        "id": "5Ll_0SY-44x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleReflexAgent:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_action(self, percept):\n",
        "        if percept == \"Obstacle on the left\":\n",
        "            return \"Move Right\"\n",
        "        elif percept == \"Obstacle on the right\":\n",
        "            return \"Move Left\"\n",
        "        elif percept == \"Dirt\":\n",
        "            return \"Clean\"\n",
        "              # your code is here\n",
        "            return \"Stay\"\n",
        "\n",
        "# Example usage\n",
        "agent = SimpleReflexAgent()\n",
        "percepts = ............# your code is here...............\n",
        "actions = [agent.get_action(p) for p in percepts]\n",
        "for percept, action in zip(percepts, actions):\n",
        "    print(f\"Percept: {percept} -> Action: {action}\")\n"
      ],
      "metadata": {
        "id": "dxrA2lar5FCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert statements to validate the functionality\n",
        "expected_actions = [\"Clean\", \"Move Right\", \"Move Left\", \"Turn Around\", \"Stay\"] # Define the expected actions\n",
        "for percept, action, expected in zip(percepts, actions, expected_actions):\n",
        "    assert action == expected, f\"Failed for percept {percept}: expected {expected}, got {action}\"\n",
        "print(\"All assertions passed for SimpleReflexAgent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ghlWYpZgFVd",
        "outputId": "e0b0e3a9-40f6-4412-9511-de180ea691c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All assertions passed for SimpleReflexAgent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6L2yY3DTS0O"
      },
      "source": [
        "####2. **Model-Based Reflex Agents**\n",
        "\n",
        "It works by finding a rule whose condition matches the current situation. A model-based agent can handle partially observable environments by the use of a model about the world. The agent has to keep track of the internal state which is adjusted by each percept and that depends on the percept history. The current state is stored inside the agent which maintains some kind of structure describing the part of the world which cannot be seen.\n",
        "\n",
        "Updating the state requires information about:\n",
        "\n",
        "How the world evolves independently from the agent?\n",
        "How do the agent’s actions affect the world?.\n",
        "\n",
        "![Model-Based Reflex Agent](https://media.geeksforgeeks.org/wp-content/uploads/art1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:** let's countinue with Vacuum Cleaner example\n",
        "\n",
        "- Internal State: The agent maintains an internal state (a dictionary in this case) that maps locations to percepts.\n",
        "\n",
        "- Update State: The agent updates its internal state based on new percepts.\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - The agent uses the internal state to determine actions.\n",
        "  - If it finds dirt in a location, it cleans.\n",
        "  - If it finds an obstacle, it moves in the opposite direction."
      ],
      "metadata": {
        "id": "zrDM2fBqrFvw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIqWYDcCTS0O"
      },
      "source": [
        "class ModelBasedReflexAgent:\n",
        "    def __init__(self):\n",
        "        self.state = {}\n",
        "\n",
        "    def update_state(self, percept, location):\n",
        "        self.state[location] = percept\n",
        "\n",
        "    def get_action(self, location):\n",
        "        percept = self.state.get(location, \"Clean\")\n",
        "        if percept == \"Dirt\":\n",
        "            return \"Clean\"\n",
        "        elif percept == \"Obstacle on the left\":\n",
        "            return \"Move Right\"\n",
        "        elif percept == \"Obstacle on the right\":\n",
        "            return \"Move Left\"\n",
        "        else:\n",
        "            return \"Move Forward\"\n",
        "\n",
        "# Example:\n",
        "agent = ModelBasedReflexAgent()\n",
        "# Assume we have a 2x2 grid and the agent starts at (0,0)\n",
        "agent.update_state(\"Dirt\", (0, 0))\n",
        "agent.update_state(\"Obstacle on the left\", (0, 1))\n",
        "\n",
        "locations = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "actions = [agent.get_action(loc) for loc in locations]\n",
        "for loc, action in zip(locations, actions):\n",
        "    print(f\"Location: {loc} -> Action: {action}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise 2:\n",
        "complete the following code.Implement a ModelBasedReflexAgent that keeps track of the last percept.\n",
        "\n",
        "- Modify the ModelBasedReflexAgent class to store the last percept.\n",
        "- Implement logic to decide actions based on the current and previous percepts..\n",
        "\n"
      ],
      "metadata": {
        "id": "v22TmKvi5T1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBasedReflexAgent:\n",
        "    def __init__(self):\n",
        "        self.last_percept = None\n",
        "\n",
        "    def update_state(self, percept):\n",
        "        # your code is here\n",
        "\n",
        "    def get_action(self, percept):\n",
        "        self.update_state(percept)\n",
        "        if self.last_percept == \"Dirt\" and percept == \"Obstacle on the left\":\n",
        "            return \"Clean and Move Right\"\n",
        "        elif percept == \"Obstacle on the left\":\n",
        "            return \"Move Right\"\n",
        "        elif percept == \"Obstacle on the right\":\n",
        "            return \"Move Left\"\n",
        "        elif percept == \"Dirt\":\n",
        "            return \"Clean\"\n",
        "        else:\n",
        "            return \"Stay\"\n",
        "\n",
        "# Example usage\n",
        "agent = ModelBasedReflexAgent()\n",
        "percepts = [\"Dirt\", \"Obstacle on the left\", \"Dirt\", \"Obstacle on the right\", \"Clean\"]\n",
        "actions = # your code is here\n",
        "for percept, action in zip(percepts, actions):\n",
        "    print(f\"Percept: {percept} -> Action: {action}\")\n"
      ],
      "metadata": {
        "id": "f4Bl3Jse5hBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1yIaC1bTS0O"
      },
      "source": [
        "####3. **Goal-Based Agents**\n",
        "\n",
        "These kinds of agents take decisions based on how far they are currently from their goal(description of desirable situations). Their every action is intended to reduce their distance from the goal. This allows the agent a way to choose among multiple possibilities, selecting the one which reaches a goal state. The knowledge that supports its decisions is represented explicitly and can be modified, which makes these agents more flexible. They usually require search and planning. The goal-based agent’s behavior can easily be changed.\n",
        "\n",
        "![Goal-Based Agent](https://media.geeksforgeeks.org/wp-content/uploads/art2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: vaccum cleaner**\n",
        "\n",
        "- Goal: The agent has a goal to achieve, such as cleaning all rooms.\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - The agent checks if the current state matches the goal.\n",
        "  - If the goal is reached, it stops or moves to a new goal.\n",
        "  - Otherwise, it continues to take actions to achieve the goal."
      ],
      "metadata": {
        "id": "XwWIRvSwuEOd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrRuDgskTS0O"
      },
      "source": [
        "class GoalBasedAgent:\n",
        "    def __init__(self, goal):\n",
        "        self.goal = goal\n",
        "\n",
        "    def get_action(self, state):\n",
        "        if state == self.goal:\n",
        "            return \"Goal Reached\"\n",
        "        else:\n",
        "            return \"Move Towards Goal\"\n",
        "\n",
        "# Example usage\n",
        "agent = GoalBasedAgent(goal=\"Clean all rooms\")\n",
        "state = \"Rooms partially cleaned\"\n",
        "action = agent.get_action(state)\n",
        "print(f\"State: {state} -> Action: {action}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise 3:\n",
        "complete the following code.Design a GoalBasedAgent that tries to reach a specific position on a grid.\n",
        "\n",
        "- Create a GoalBasedAgent class with a goal state.\n",
        "- Implement a method to determine the action based on the current state and goal state."
      ],
      "metadata": {
        "id": "Yqk7FuWJ6Ibv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoalBasedAgent:\n",
        "    def __init__(self, goal):\n",
        "        # your code is here\n",
        "\n",
        "    def get_action(self, state):\n",
        "        if state == self.goal:\n",
        "            return \"Goal Reached\"\n",
        "        elif state[0] < self.goal[0]:\n",
        "            return \"Move Down\"\n",
        "        elif state[0] > self.goal[0]:\n",
        "            return \"Move Up\"\n",
        "        elif state[1] < self.goal[1]:\n",
        "            return \"Move Right\"\n",
        "        elif state[1] > self.goal[1]:\n",
        "            return \"Move Left\"\n",
        "\n",
        "# Example usage\n",
        "agent = # your code is here\n",
        "states = [(0, 0), (1, 0), (1, 1), (2, 1), (2, 2)]\n",
        "actions = [agent.get_action(s) for s in states]\n",
        "for state, action in zip(states, actions):\n",
        "    print(f\"State: {state} -> Action: {action}\")\n"
      ],
      "metadata": {
        "id": "BI9s0IzS6Rol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmATaxRoTS0O"
      },
      "source": [
        "####4. **Utility-Based Agents**\n",
        "The agents which are developed having their end uses as building blocks are called utility-based agents. When there are multiple possible alternatives, then to decide which one is best, utility-based agents are used. They choose actions based on a preference (utility) for each state. Sometimes achieving the desired goal is not enough. We may look for a quicker, safer, cheaper trip to reach a destination. Agent happiness should be taken into consideration. Utility describes how “happy” the agent is. Because of the uncertainty in the world, a utility agent chooses the action that maximizes the expected utility. A utility function maps a state onto a real number which describes the associated degree of happiness.\n",
        "\n",
        "![Utility-Based Agent](https://media.geeksforgeeks.org/wp-content/uploads/art3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Vacuum Cleaner**\n",
        "- Utility Function: A function that assigns a utility value to each state.\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - The agent evaluates the utility of the current state.\n",
        "  - It chooses an action that maximizes utility."
      ],
      "metadata": {
        "id": "KMetaG7ivP3R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFTxGX4UTS0O"
      },
      "source": [
        "class UtilityBasedAgent:\n",
        "    def __init__(self, utility_function):\n",
        "        self.utility_function = utility_function\n",
        "\n",
        "    def get_action(self, state):\n",
        "        utility = self.utility_function(state)\n",
        "        if utility > 0.8:\n",
        "            return \"High Utility Action\"\n",
        "        else:\n",
        "            return \"Low Utility Action\"\n",
        "\n",
        "# Example utility function\n",
        "def utility_function(state):\n",
        "    return 0.9 if state == \"All rooms clean\" else 0.1\n",
        "\n",
        "# Example usage\n",
        "agent = UtilityBasedAgent(utility_function)\n",
        "state = \"Rooms partially cleaned\"\n",
        "action = agent.get_action(state)\n",
        "print(f\"State: {state} -> Action: {action}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise 4:\n",
        "complete the following code. Create a UtilityBasedAgent with a custom utility function for a different scenario.\n",
        "\n",
        "\n",
        "- Define a custom utility function that returns a utility value for different states.\n",
        "- Implement a UtilityBasedAgent that uses this utility function to decide actions."
      ],
      "metadata": {
        "id": "CnwKhxdi6qQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UtilityBasedAgent:\n",
        "    def __init__(self, utility_function):\n",
        "        self.utility_function = utility_function\n",
        "\n",
        "    def get_action(self, state):\n",
        "        utility = self.utility_function(state)\n",
        "        if utility > 0.8:\n",
        "            return \"High Utility Action\"\n",
        "        else:\n",
        "            return \"Low Utility Action\"\n",
        "\n",
        "# Example custom utility function\n",
        " ........ #your code is here........\n",
        "\n",
        "# Example usage\n",
        "agent = UtilityBasedAgent(custom_utility_function)\n",
        "states = [\"Rooms partially cleaned\", \"All rooms clean\"]\n",
        "actions = [agent.get_action(s) for s in states]\n",
        "for state, action in zip(states, actions):\n",
        "    print(f\"State: {state} -> Action: {action}\")\n"
      ],
      "metadata": {
        "id": "nKYuAbXf602b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated expected actions for UtilityBasedAgent\n",
        "expected_actions = [\"Low Utility Action\", \"High Utility Action\"]  # Adjust based on expected behavior\n",
        "\n",
        "# Assert statements to validate the functionality\n",
        "for state, action, expected in zip(states, actions, expected_actions):\n",
        "    assert action == expected, f\"Failed for state {state}: expected {expected}, got {action}\"\n",
        "print(\"All assertions passed for UtilityBasedAgent.\")"
      ],
      "metadata": {
        "id": "vMAfcWAxlhfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVp9xFq8TS0O"
      },
      "source": [
        "####5.  **Learning Agents**\n",
        "A learning agent in AI is the type of agent that can learn from its past experiences or it has learning capabilities. It starts to act with basic knowledge and then is able to act and adapt automatically through learning. A learning agent has mainly four conceptual components, which are:\n",
        "\n",
        "Learning element: It is responsible for making improvements by learning from the environment.\n",
        "Critic: The learning element takes feedback from critics which describes how well the agent is doing with respect to a fixed performance standard.\n",
        "Performance element: It is responsible for selecting external action.\n",
        "Problem Generator: This component is responsible for suggesting actions that will lead to new and informative experiences.\n",
        "\n",
        "  ![Learning Agent](https://media.geeksforgeeks.org/wp-content/uploads/20190704232940/learning-agent.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Vacuum Cleaner**\n",
        "- Knowledge Base: The agent maintains a knowledge base of experiences.\n",
        "\n",
        "- Learning: The agent learns from new experiences and updates its knowledge base.\n",
        "\n",
        "- Behavior:\n",
        "\n",
        "  - If the state is known, it takes a predefined action.\n",
        "  - If the state is new, it explores and learns the best action."
      ],
      "metadata": {
        "id": "4FDxpa35v5JA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvX3_fBzTS0O"
      },
      "source": [
        "class LearningAgent:\n",
        "    def __init__(self):\n",
        "        self.knowledge_base = []\n",
        "\n",
        "    def learn(self, experience):\n",
        "        self.knowledge_base.append(experience)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        if state in self.knowledge_base:\n",
        "            return \"Known State Action\"\n",
        "        else:\n",
        "            self.learn(state)\n",
        "            return \"Explore Action\"\n",
        "\n",
        "# Example usage\n",
        "agent = LearningAgent()\n",
        "state = \"New room with dirt\"\n",
        "action = agent.get_action(state)\n",
        "print(f\"State: {state} -> Action: {action}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqciZvvgTS0P"
      },
      "source": [
        "\n",
        "#### **Exercise 5**:\n",
        "complete the following code. Develop a LearningAgent that can remember and act upon multiple states.\n",
        "\n",
        "\n",
        "- Implement a LearningAgent class that maintains a knowledge base of known states.\n",
        "- Add learning functionality to update the knowledge base with new experiences.\n",
        "- Implement logic to choose actions based on known or new states.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningAgent:\n",
        "    # your code is here\n",
        "\n",
        "# Example usage\n",
        "agent = LearningAgent()\n",
        "states = ...........# your code is here........\n",
        "actions = [agent.get_action(s) for s in states]\n",
        "for state, action in zip(states, actions):\n",
        "    print(f\"State: {state} -> Action: {action}\")\n"
      ],
      "metadata": {
        "id": "f-hZsLZPd_gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert statements to validate the functionality\n",
        "for state, action, expected in zip(states, actions, expected_actions):\n",
        "    assert action == expected, f\"Failed for state {state}: expected {expected}, got {action}\"\n",
        "print(\"All assertions passed for LearningAgent.\")"
      ],
      "metadata": {
        "id": "p-hDswMxlqua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyeXDKJkTS0P"
      },
      "source": [
        "## Conclusion :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, we explored the concept of AI agents, their types, and architectures. We also implemented a variety of agents including simple reflex, model-based reflex, goal-based, utility-based, and learning agents. These exercises provide a foundation for developing more complex AI systems that can interact effectively with their environments."
      ],
      "metadata": {
        "id": "2-P4Y_JJpMvK"
      }
    }
  ]
}